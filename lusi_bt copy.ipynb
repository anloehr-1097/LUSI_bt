{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03574cb7-e4b5-4229-b5fa-7ca7cee3794a",
   "metadata": {},
   "source": [
    "# Learning Using Statistical Invariants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9383a3b-d3fd-4706-979e-705f326590a5",
   "metadata": {},
   "source": [
    "author: Andreas Loehr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28af1c59-f538-40f4-b0b4-334e16e33634",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b74297-4729-4f3b-b8e9-7d4f71fb4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35cc17c-9082-4792-93f3-f01c4ddb4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafa4497-2879-4ad5-92e6-8906d91e5491",
   "metadata": {},
   "source": [
    "## Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9e254b-34a0-4a02-9e92-a4a64ba68b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d0f298-924b-4a5e-b11c-752732541ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Illustrate some MNIST samples in grid structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0631dbc-bab9-4486-a17b-a479ff4ca0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19b5ab610>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[14])\n",
    "# shape: (28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d66f63-8027-4241-b679-82046039df05",
   "metadata": {},
   "source": [
    "## A simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1c932824-d46b-41e7-8fad-0fa91a02bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network with one hidden layer and one output layer\n",
    "nn_simple = keras.Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=(28,28), name=\"flatten_input\"),  # declare shape of one input beforehand\n",
    "        layers.Dense(500, activation=\"relu\", name=\"hidden_layer_01\"),\n",
    "        # layers.Dense(10, name=\"output_layer\"),\n",
    "        layers.Dense(10, name=\"output_layer\"),\n",
    "    ]\n",
    ")\n",
    "# Call model on a test input\n",
    "x = tf.ones((2,28,28))\n",
    "y = nn_simple(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3a87ce13-9282-40df-ad7f-d7ed0dcde74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_input (Flatten)     (None, 784)               0         \n",
      "                                                                 \n",
      " hidden_layer_01 (Dense)     (None, 500)               392500    \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 397,510\n",
      "Trainable params: 397,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7080d44a-9da1-4ee6-a4a0-41c115faa134",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_simple.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    # loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0845f03-ea0c-463d-9f5e-f6d46cf33604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c74939e-888e-41d2-badb-4afb74d741a8",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7db192-c4d4-440b-a528-490d3e05953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (these are NumPy arrays)\n",
    "# x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "# x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "09f49c80-e0bf-428c-a2d2-526dec47963e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "No gradient defined for operation'IteratorGetNext' (op type: IteratorGetNext). In general every operation must have an associated `@tf.RegisterGradient` for correct autodiff, which this op is lacking. If you want to pretend this operation is a constant in your program, you may insert `tf.stop_gradient`. This can be useful to silence the error in cases where you know gradients are not needed, e.g. the forward pass of tf.custom_gradient. Please see more details in https://www.tensorflow.org/api_docs/python/tf/custom_gradient.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [186]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m g:\n\u001b[1;32m      3\u001b[0m     g\u001b[38;5;241m.\u001b[39mwatch(x)\n\u001b[0;32m----> 4\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mnn_simple\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m dy_dx \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mgradient(y, nn_simple\u001b[38;5;241m.\u001b[39mweights)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(dy_dx)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/ops/gradients_util.py:626\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    624\u001b[0m       grad_fn \u001b[38;5;241m=\u001b[39m func_call\u001b[38;5;241m.\u001b[39mpython_grad_func\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 626\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(\n\u001b[1;32m    627\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradient defined for operation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    628\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (op type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    629\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn general every operation must have an associated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    630\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@tf.RegisterGradient` for correct autodiff, which this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    631\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mop is lacking. If you want to pretend this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moperation is a constant in your program, you may insert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    633\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.stop_gradient`. This can be useful to silence the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    634\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in cases where you know gradients are not needed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    635\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me.g. the forward pass of tf.custom_gradient. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    636\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see more details in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    637\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/api_docs/python/tf/custom_gradient.\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop_state:\n\u001b[1;32m    639\u001b[0m   loop_state\u001b[38;5;241m.\u001b[39mEnterGradWhileContext(op, before\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mLookupError\u001b[0m: No gradient defined for operation'IteratorGetNext' (op type: IteratorGetNext). In general every operation must have an associated `@tf.RegisterGradient` for correct autodiff, which this op is lacking. If you want to pretend this operation is a constant in your program, you may insert `tf.stop_gradient`. This can be useful to silence the error in cases where you know gradients are not needed, e.g. the forward pass of tf.custom_gradient. Please see more details in https://www.tensorflow.org/api_docs/python/tf/custom_gradient."
     ]
    }
   ],
   "source": [
    "x = tf.constant(x_train)\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    y = nn_simple.predict(x_train)\n",
    "dy_dx = g.gradient(y, nn_simple.weights)\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e3963fe2-13bf-4d5c-8751-4792a819f178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.3038 - sparse_categorical_accuracy: 0.1025\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2838 - sparse_categorical_accuracy: 0.1041\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.2714 - sparse_categorical_accuracy: 0.1052\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.2609 - sparse_categorical_accuracy: 0.1032\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.2506 - sparse_categorical_accuracy: 0.1044\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2389 - sparse_categorical_accuracy: 0.0996\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2308 - sparse_categorical_accuracy: 0.0975\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2199 - sparse_categorical_accuracy: 0.0958\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2127 - sparse_categorical_accuracy: 0.0942\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2064 - sparse_categorical_accuracy: 0.0921\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1987 - sparse_categorical_accuracy: 0.0928\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1933 - sparse_categorical_accuracy: 0.0915\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1872 - sparse_categorical_accuracy: 0.0982\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 4s 4ms/step - loss: 0.1803 - sparse_categorical_accuracy: 0.0963\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1756 - sparse_categorical_accuracy: 0.0980\n"
     ]
    }
   ],
   "source": [
    "hist_nn_simple = nn_simple.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15\n",
    "    #validation_data=(x_val, y_val)  add argument\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f956a033-ddd8-4339-960b-7022324c7355",
   "metadata": {},
   "source": [
    "### Modifying loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394bda1-3140-4543-9496-0f5486660f38",
   "metadata": {},
   "source": [
    "custom loss function: https://www.tensorflow.org/guide/keras/train_and_evaluate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a8928d4e-00fc-4169-b670-6ca76be9dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LusiMSE(keras.losses.Loss):\n",
    "    def __init__(self, alpha, beta, predicate_x, name=\"erm_lusi_mse\"):\n",
    "        super()._init__(name=name)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.predicate_x = predicate_x\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        lusi_loss = tf.math.reduce_mean(predicate_x * (y_true - y_pred))\n",
    "        \n",
    "        return self.alpha * mse + self.beta * lusi_loss\n",
    "\n",
    "# Does not make sense to pass predicate values like this, as this requires to pass predicate values upon compilation of model.\n",
    "# Should only pass values once model is fitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53222a25-14e5-47a6-a79d-7666b2902780",
   "metadata": {},
   "source": [
    "## Visualizing Statistical Invariants\n",
    "invariants to consider:\n",
    "- vertical symmetry\n",
    "- horizontal symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b8ab6cea-2fdc-4e8c-9faf-21313ce7bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = x_train[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "141f7325-144f-4ed7-b0ec-18731faa2653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1aaed7280>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.fliplr(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9b0a8650-6789-4ef8-a453-ff58dc08e808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1aae92170>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "14b0ac04-3c16-4ee8-8af0-677ea440dffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f73c28ad-10d1-42ee-9e7f-f3cd8b97c2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e7726210-96d4-43ed-ad12-7160e1b4e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ar = np.arange(16).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e464f986-9ef5-404f-92ff-bced30e04976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b8d4e09b-08cb-4158-89e4-5c8d3ad43eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  2,  1,  0],\n",
       "       [ 7,  6,  5,  4],\n",
       "       [11, 10,  9,  8],\n",
       "       [15, 14, 13, 12]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fliplr(t_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dbcd18ee-562e-444f-bf35-90d01fbea089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetry(img, axis=\"vertical\"):\n",
    "    \"\"\"Calculate a vertical symmetry score for normalized pictures.\n",
    "    \n",
    "    Parameters:\n",
    "    img :: np.array\n",
    "        Numpy array representing image. Pixel values in range [0,1]\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    sym_score :: float \n",
    "        Value representing symmetrie score between 0 (not symmetric) and 1 (symmetric).\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    if axis == \"vertical\":\n",
    "        flipped_img = np.fliplr(img)\n",
    "\n",
    "    elif axis == \"horizontal\":\n",
    "        flipped_img = np.flipud(img)\n",
    "    \n",
    "    else:\n",
    "        # diagonal\n",
    "        flipped_img = np.flipud(np.fliplr(img))\n",
    "    \n",
    "\n",
    "    sym_score = 1 - np.mean(np.abs(img - flipped_img))\n",
    "    \n",
    "    \n",
    "    return sym_score\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5fa5c83d-a47f-44c4-8e43-a7911dd00175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8168767392635345"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetry(test_img, \"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d7d365a4-905f-47cd-a6cc-d506a79c8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_indices = np.where(y_train==8)\n",
    "four_indices =  np.where(y_train==4)\n",
    "six_indices =  np.where(y_train==4)\n",
    "eight_training_samples = x_train[eight_indices]\n",
    "four_training_samples = x_train[four_indices]\n",
    "six_training_samples = x_train[six_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "53401f6d-dfdd-4c17-9484-9e0aaee12f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetry(imgs, axis=\"both\"):\n",
    "    \"\"\"Calculate a symmetry score for normalized pictures.\n",
    "    \n",
    "    Parameters:\n",
    "    img :: np.array\n",
    "        Numpy array representing images. Pixel values in range [0,1]\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    sym_score :: float \n",
    "        Value representing symmetrie score between 0 (not symmetric) and 1 (symmetric).\n",
    "    \"\"\"\n",
    "    \n",
    "    # crop image to area of non-zero pixels only\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    if len(imgs.shape) < 3:\n",
    "        # only single image passed -> expand dims\n",
    "        imgs = np.expand_dims(imgs, axis=0)\n",
    "    \n",
    "    if len(imgs.shape) < 4:\n",
    "        # no channel for images -> add channel dim\n",
    "        imgs = np.expand_dims(imgs, axis=3)\n",
    "    \n",
    "    # print(imgs.shape)\n",
    "    if axis == \"vertical\":\n",
    "        # print(\"vertical\")\n",
    "        flipped_imgs = tf.image.flip_left_right(imgs)\n",
    "\n",
    "    elif axis == \"horizontal\":\n",
    "        # print(\"horizontal\")\n",
    "        flipped_imgs = tf.image.flip_up_down(imgs)\n",
    "    \n",
    "    else:\n",
    "        # diagonal\n",
    "        # print(\"both v. and h.\")\n",
    "        flipped_imgs = tf.image.flip_up_down(tf.image.flip_left_right(imgs))\n",
    "    \n",
    "    # print(tf.reduce_mean(tf.abs(flipped_imgs - imgs), axis=[1, 2, 3]).shape)\n",
    "    sym_score = tf.reduce_mean(1 - tf.reduce_mean(tf.abs(flipped_imgs - imgs), axis=[1, 2, 3]))\n",
    "    \n",
    "    return sym_score\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "cdcac2ed-80c2-44c6-96de-6c4bc921423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4859, 28, 28, 1)\n",
      "vertical\n",
      "(4859,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.87357384>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetry(six_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "4b6d2e75-3015-4eee-b690-ef9c4776f68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4842, 28, 28, 1)\n",
      "vertical\n",
      "(4842,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8471952>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetry(eight_training_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfdedb6-df12-47a4-b218-bf5eceb94944",
   "metadata": {},
   "source": [
    "### Intermediate Results 02.04.2022\n",
    "- Symmetry is highly senesitive to small translations of images, thus not really reliable in the way it is implemented.\n",
    "- the concept of symmetry is hard though, so not really a way to improve on above-mentioned issue though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e18c1-f60b-4e37-a785-edd7ccdb5b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3699173d-06fa-48e5-9e75-a6fd44368cdb",
   "metadata": {},
   "source": [
    "## Session 14.04.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e3e47b42-e7a9-4183-83c3-e47a8dc10ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_box(img):\n",
    "    \"\"\"Determine non-black area of image.\n",
    "    \n",
    "    Provide coordinates for cropping images to area which is filled.\n",
    "    \n",
    "    Parameters: \n",
    "    \n",
    "    img :: np.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    hc = np.where(img!=0)[0]\n",
    "    wc = np.where(img!=0)[1]\n",
    "    ul = (np.min(hc), np.min(wc))\n",
    "    lr = (np.max(hc), np.max(wc))\n",
    "    cropped_img = img[ul[0]:lr[0], ul[1]:lr[1]]\n",
    "    \n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a60ad208-e3b2-42aa-973c-702ef8ebe0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71b11718-0cb0-44df-8f51-e9c72f4fc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_box(imgs):\n",
    "    \"\"\"Determine non-black area of image.\n",
    "    \n",
    "    Provide coordinates for cropping images to area which is filled.\n",
    "    \n",
    "    Parameters: \n",
    "    \n",
    "    img :: np.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    if not len(imgs.shape) == 3:\n",
    "        raise Exception(\"Check dimensions.\")\n",
    "    \n",
    "    cropped_imgs = []\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i, :, :]\n",
    "        hc = np.where(img!=0)[0]\n",
    "        wc = np.where(img!=0)[1]\n",
    "        ul = (np.min(hc),np.min(wc))\n",
    "        lr = (np.max(hc), np.max(wc))\n",
    "        cropped_imgs.append(np.expand_dims(img[ul[0]:lr[0], ul[1]:lr[1]], axis=(0,3)))\n",
    "    return cropped_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5838591a-ca80-4361-9a12-9a46d7f75471",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = determine_box(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7686c84-b305-4947-928b-3d5520033be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "excerpt = temp[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e29782a-e85c-401e-92e8-7bec8c3ae838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 19:08:18.809572: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't convert non-rectangular Python sequence to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflip_left_right\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcerpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
     ]
    }
   ],
   "source": [
    "tf.image.flip_left_right(excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1cc9dcf-c4fc-4f96-9a1d-6f39be32bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "el = []\n",
    "for i in range(10):\n",
    "    el.append(np.ones(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c46acad-16f4-4012-a9f8-718ccc7b2d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([], dtype=float64), array([1.]), array([1., 1.]),\n",
       "       array([1., 1., 1.]), array([1., 1., 1., 1.]),\n",
       "       array([1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1.]),\n",
       "       array([1., 1., 1., 1., 1., 1., 1.]),\n",
       "       array([1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "       array([1., 1., 1., 1., 1., 1., 1., 1., 1.])], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(el, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc2e94-6dda-4f0a-92f7-bad99dc74f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fdc714ac-3cea-4590-8f3f-6631d1da774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59999, 27, 28)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_box(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d3690d9c-a06c-4b69-b989-daee31cc719e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8994156, 3])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.where(x_train != 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ca13e511-6127-4285-8506-8fe61335deb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4c07d-6554-4adf-bae0-2e77161a5468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a571fd00>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a9b148db-b4ae-4a63-a958-a88bc90901c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a5793100>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(determine_box(x_train[55]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e069c26c-dfeb-4298-8e62-c4bb711ac376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tangent distance might be a solution to determine symmetry. Use it over the std. euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0644a3c2-1245-4c7e-9cd8-a77bfb06c874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 19, 17, 1)\n",
      "vertical\n",
      "(1,)\n",
      "Symmetry:  tf.Tensor(0.5933709706792933, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Symmetry: \", symmetry(determine_box(x_train[55]/255).astype(\"float\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f5a892d9-8e31-4781-b6bf-7a52aa22725e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 19, 4, 1)\n",
      "vertical\n",
      "(1,)\n",
      "Symmetry:  tf.Tensor(0.1944272445820432, shape=(), dtype=float64)\n",
      "(1, 19, 4, 1)\n",
      "horizontal\n",
      "(1,)\n",
      "Symmetry:  tf.Tensor(0.8518059855521156, shape=(), dtype=float64)\n",
      "(1, 19, 4, 1)\n",
      "both v. and h.\n",
      "(1,)\n",
      "Symmetry:  tf.Tensor(0.18658410732714126, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Symmetry: \", symmetry(determine_box(one/255).astype(\"float\"), axis=\"vertical\"))\n",
    "print(\"Symmetry: \", symmetry(determine_box(one/255).astype(\"float\"), axis=\"horizontal\"))\n",
    "print(\"Symmetry: \", symmetry(determine_box(one/255).astype(\"float\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fbb1373b-267c-4b46-8783-4f8f67f19808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 19, 17, 1)\n",
      "vertical\n",
      "(1,)\n",
      "Symmetry:  tf.Tensor(0.5933709706792933, shape=(), dtype=float64)\n",
      "(1, 19, 17, 1)\n",
      "horizontal\n",
      "(1,)\n",
      "Symmetry:  tf.Tensor(0.5651065379712257, shape=(), dtype=float64)\n",
      "(1, 19, 17, 1)\n",
      "both v. and h.\n",
      "(1,)\n",
      "Symmetry:  tf.Tensor(0.6717537789109452, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Symmetry: \", symmetry(determine_box(x_train[55]/255).astype(\"float\"), axis=\"vertical\"))\n",
    "print(\"Symmetry: \", symmetry(determine_box(x_train[55]/255).astype(\"float\"), axis=\"horizontal\"))\n",
    "print(\"Symmetry: \", symmetry(determine_box(x_train[55]/255).astype(\"float\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6904ac64-1afc-4d44-887f-ece83b2bd0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13, 19, 1)\n",
      "vertical\n",
      "(1,)\n",
      "Symmetry:  tf.Tensor(0.6274668571882195, shape=(), dtype=float64)\n",
      "(1, 13, 19, 1)\n",
      "horizontal\n",
      "(1,)\n",
      "Symmetry:  tf.Tensor(0.6374057315233785, shape=(), dtype=float64)\n",
      "(1, 13, 19, 1)\n",
      "both v. and h.\n",
      "(1,)\n",
      "Symmetry:  tf.Tensor(0.7679765023418275, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Symmetry: \", symmetry(determine_box(x_train[11]/255).astype(\"float\"), axis=\"vertical\"))\n",
    "print(\"Symmetry: \", symmetry(determine_box(x_train[11]/255).astype(\"float\"), axis=\"horizontal\"))\n",
    "print(\"Symmetry: \", symmetry(determine_box(x_train[11]/255).astype(\"float\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c15e4-01f4-4d65-b300-454bcf9f4be4",
   "metadata": {},
   "source": [
    "### Status 15.04.2022:\n",
    "- Die Box Methode scheint einen verlässlicheren Score zu geben, allerdings ist sie nicht einfach andwendbar auf batches, da jedes Bild individuell eine Größe hat. DAmit ist die Handhabung in Batches nicht möglich. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82555ecf-2308-4fc6-b32c-193059a24465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000,), dtype=uint8, numpy=array([35, 39, 24, ..., 28, 26, 26], dtype=uint8)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(x_train, axis=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49a1b914-79be-4ada-a554-276db47ea65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pixel_intensity(img_tensor, batch_mean=False):\n",
    "    \"\"\"Calculate avg. pixel intensity.\n",
    "    \n",
    "    img_tensor :: array of 3 dim, pixel value between 0 and 1.\n",
    "    \"\"\"\n",
    "    if batch_mean: \n",
    "        return tf.reduce_mean(tf.reduce_mean(img_tensor, axis=[1,2]), axis=0)\n",
    "        \n",
    "    \n",
    "    return tf.reduce_mean(img_tensor, axis=[1,2])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45f6f103-28ac-497e-9ed6-f81756fd5132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000,), dtype=float64, numpy=\n",
       "array([0.13768007, 0.15553721, 0.0972539 , ..., 0.11070428, 0.10218087,\n",
       "       0.10464186])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pixel_intensity(x_train/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0335cdf9-001b-4611-9ac9-2df2933851fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = x_train[y_train==1]\n",
    "twos = x_train[y_train==2]\n",
    "threes = x_train[y_train==3]\n",
    "fours = x_train[y_train==4]\n",
    "fives = x_train[y_train==5]\n",
    "sixes = x_train[y_train==6]\n",
    "sevens = x_train[y_train==7]\n",
    "eights = x_train[y_train==8]\n",
    "nines = x_train[y_train==9]\n",
    "zeroes = x_train[y_train==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831193bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "305ffdb3-d7e7-4969-a1ee-322460b6b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ones = y_train[y_train==1]\n",
    "y_twos = y_train[y_train==2]\n",
    "y_threes = y_train[y_train==3]\n",
    "y_fours = y_train[y_train==4]\n",
    "y_fives = y_train[y_train==5]\n",
    "y_sixes = y_train[y_train==6]\n",
    "y_sevens = y_train[y_train==7]\n",
    "y_eights = y_train[y_train==8]\n",
    "y_nines = y_train[y_train==9]\n",
    "y_zeroes = y_train[y_train==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a869a76-2197-4f59-acb0-00aefbd231c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.1306604762738429>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pixel_intensity(x_train/255, batch_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1ece68b-b6d5-4181-a4ca-aaad4a912563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.17339932511920858, shape=(), dtype=float64)\n",
      "tf.Tensor(0.07599864255996082, shape=(), dtype=float64)\n",
      "tf.Tensor(0.14897512882292896, shape=(), dtype=float64)\n",
      "tf.Tensor(0.14153014329202565, shape=(), dtype=float64)\n",
      "tf.Tensor(0.12136559091284581, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1287493940575677, shape=(), dtype=float64)\n",
      "tf.Tensor(0.13730177522174802, shape=(), dtype=float64)\n",
      "tf.Tensor(0.11452769775108769, shape=(), dtype=float64)\n",
      "tf.Tensor(0.15015598189369747, shape=(), dtype=float64)\n",
      "tf.Tensor(0.12258994285224596, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(avg_pixel_intensity(zeroes/255, batch_mean=True))\n",
    "print(avg_pixel_intensity(ones/255, batch_mean=True))\n",
    "print(avg_pixel_intensity(twos/255, batch_mean=True))\n",
    "print(avg_pixel_intensity(threes/255, batch_mean=True))\n",
    "print(avg_pixel_intensity(fours/255, batch_mean=True))\n",
    "print(avg_pixel_intensity(fives/255, batch_mean=True))\n",
    "print(avg_pixel_intensity(sixes/255, batch_mean=True))\n",
    "print(avg_pixel_intensity(sevens/255, batch_mean=True))\n",
    "print(avg_pixel_intensity(eights/255, batch_mean=True))\n",
    "print(avg_pixel_intensity(nines/255, batch_mean=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc84991a-851f-49f1-9649-dc25790c6a82",
   "metadata": {},
   "source": [
    "Mögliche weitere Prädikate sind:\n",
    "- 'lokale' Pixelintensität in einem Bereich\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42ed1c8a-3ed5-41d1-b97b-d686457e262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - random functions\n",
    "# - Erwartungswerte abh. von funktio f(x,u) übr Verteilung von u durch Monte Carlo approximieren als Auswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0ed3f-dad4-444c-bdf6-facd0c0db065",
   "metadata": {},
   "source": [
    "### 20.04.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "98bc4571-2e27-49e6-bf55-92d46024fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetry_boxed(imgs):\n",
    "    # Asumme [0,1]-valued pixels\n",
    "    cropped_imgs = determine_box(imgs)\n",
    "    sym_scores = np.zeros(len(cropped_imgs))\n",
    "    for j in range(len(imgs)):\n",
    "        sym_scores[j] = symmetry(cropped_imgs[j])\n",
    "    return sym_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9f23e224-ef52-4cd6-80bd-6903c59c70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_zeroes = symmetry_boxed(zeroes/255)\n",
    "sym_ones = symmetry_boxed(ones/255)\n",
    "sym_twos = symmetry_boxed(twos/255)\n",
    "sym_threes = symmetry_boxed(threes/255)\n",
    "sym_fours = symmetry_boxed(fours/255)\n",
    "sym_fives = symmetry_boxed(fives/255)\n",
    "sym_sixes = symmetry_boxed(sixes/255)\n",
    "sym_sevens = symmetry_boxed(sevens/255)\n",
    "sym_eights = symmetry_boxed(eights/255)\n",
    "sym_nines = symmetry_boxed(nines/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "78c244b7-47b6-4c58-8370-558f167fae92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(20, 20))\n",
    "axs[0, 0].hist(sym_zeroes, bins=50)\n",
    "axs[0,0].title.set_text(\"Symmetry 0 \")\n",
    "axs[1, 0].hist(sym_ones, bins=50)\n",
    "axs[1, 0].title.set_text(\"Symmetry 1 \")\n",
    "axs[0, 1].hist(sym_twos, bins=50)\n",
    "axs[0, 1].title.set_text(\"Symmetry 2 \")\n",
    "axs[1, 1].hist(sym_threes, bins=50)\n",
    "axs[1, 1].title.set_text(\"Symmetry 3 \")\n",
    "axs[0, 2].hist(sym_fours, bins=50)\n",
    "axs[0, 2].title.set_text(\"Symmetry 4 \")\n",
    "axs[1, 2].hist(sym_fives, bins=50)\n",
    "axs[1, 2].title.set_text(\"Symmetry 5 \")\n",
    "axs[0, 3].hist(sym_sixes, bins=50)\n",
    "axs[0, 3].title.set_text(\"Symmetry 6 \")\n",
    "axs[1, 3].hist(sym_sevens, bins=50)\n",
    "axs[1, 3].title.set_text(\"Symmetry 7 \")\n",
    "axs[0, 4].hist(sym_eights, bins=50)\n",
    "axs[0, 4].title.set_text(\"Symmetry 8 \")\n",
    "axs[1, 4].hist(sym_nines, bins=50)\n",
    "axs[1, 4].axvline(np.mean(sym_nines), 0, 1.0, c='red')\n",
    "axs[1, 4].title.set_text(\"Symmetry 9 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "74a59ae4-a48c-4e7b-a0b0-79cf5df69894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006017600296697623"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(abs(b - sym_ones))sym_threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a1a77-7c69-4975-96ea-9e8389ed2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "twos_cropped = determine_box(twos/255)\n",
    "sym_twos = np.zeros(len(twos_cropped))\n",
    "for j in range(len(twos_cropped)):\n",
    "    sym_twos[j] = symmetry(twos_cropped[j].astype('float16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "22b1ca0a-e1ee-467c-96b9-99be4ef3b0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,   1.,   1.,   6.,   3.,   7.,   8.,  17.,  29.,  35.,  51.,\n",
       "         69.,  78., 112., 130., 179., 181., 249., 272., 324., 311., 372.,\n",
       "        343., 403., 361., 343., 306., 256., 232., 196., 177., 162., 140.,\n",
       "         99.,  89.,  73.,  72.,  64.,  53.,  40.,  27.,  22.,  19.,  13.,\n",
       "         15.,   4.,   5.,   3.,   2.,   1.]),\n",
       " array([0.31298828, 0.32483398, 0.33667969, 0.34852539, 0.36037109,\n",
       "        0.3722168 , 0.3840625 , 0.3959082 , 0.40775391, 0.41959961,\n",
       "        0.43144531, 0.44329102, 0.45513672, 0.46698242, 0.47882813,\n",
       "        0.49067383, 0.50251953, 0.51436523, 0.52621094, 0.53805664,\n",
       "        0.54990234, 0.56174805, 0.57359375, 0.58543945, 0.59728516,\n",
       "        0.60913086, 0.62097656, 0.63282227, 0.64466797, 0.65651367,\n",
       "        0.66835938, 0.68020508, 0.69205078, 0.70389648, 0.71574219,\n",
       "        0.72758789, 0.73943359, 0.7512793 , 0.763125  , 0.7749707 ,\n",
       "        0.78681641, 0.79866211, 0.81050781, 0.82235352, 0.83419922,\n",
       "        0.84604492, 0.85789063, 0.86973633, 0.88158203, 0.89342773,\n",
       "        0.90527344]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sym_twos, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fbf3711e-d575-4816-a76d-2249a5e29170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(x_train[768]/255, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ab5a0c0-bd9f-4b97-9f01-c03f4ded735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_cropped = determine_box(ones/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9aa871c9-80c3-415f-bc20-4b2d53c7f2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19, 13, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_cropped[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d0b8e4f1-d22e-48ba-8fb8-e68e19bc04e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_ones = np.zeros(len(ones_cropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8a70a329-a042-4d8c-8c0d-5b497410f804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   1.,   3.,   5.,  11.,  16.,  10.,  19.,  25.,  31.,  40.,\n",
       "         44.,  51.,  56.,  81.,  83.,  91., 105., 118., 130., 118., 150.,\n",
       "        146., 152., 163., 211., 201., 216., 244., 231., 243., 256., 261.,\n",
       "        247., 280., 254., 212., 283., 249., 206., 206., 207., 215., 191.,\n",
       "        202., 180., 164.,  74.,  49.,  10.]),\n",
       " array([0.12744141, 0.14430664, 0.16117187, 0.17803711, 0.19490234,\n",
       "        0.21176758, 0.22863281, 0.24549805, 0.26236328, 0.27922852,\n",
       "        0.29609375, 0.31295898, 0.32982422, 0.34668945, 0.36355469,\n",
       "        0.38041992, 0.39728516, 0.41415039, 0.43101563, 0.44788086,\n",
       "        0.46474609, 0.48161133, 0.49847656, 0.5153418 , 0.53220703,\n",
       "        0.54907227, 0.5659375 , 0.58280273, 0.59966797, 0.6165332 ,\n",
       "        0.63339844, 0.65026367, 0.66712891, 0.68399414, 0.70085937,\n",
       "        0.71772461, 0.73458984, 0.75145508, 0.76832031, 0.78518555,\n",
       "        0.80205078, 0.81891602, 0.83578125, 0.85264648, 0.86951172,\n",
       "        0.88637695, 0.90324219, 0.92010742, 0.93697266, 0.95383789,\n",
       "        0.97070312]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sym_ones, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d97a6fc0-8fdd-4ddc-9dae-10c84e19c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(ones_cropped)):\n",
    "    sym_ones[j] = symmetry(ones_cropped[j].astype('float16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "113e3e01-65ec-46b7-8239-de6adc80ff3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0854ee61-7446-4e34-91ee-54a4cc951720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in tf.data.Dataset.from_tensor_slices(x_train):\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f87026a-fd88-4de5-8e56-6a06061e1cc2",
   "metadata": {},
   "source": [
    "## 22.04.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60318e-0933-48d7-842c-9775f2a8e195",
   "metadata": {},
   "source": [
    "TF docu implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83826963-48f1-4dcc-abfc-5db012dd4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss(model, x, y, training):\n",
    "  # training=training is needed only if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "    y_ = model(x, training=training)\n",
    "\n",
    "    return loss_object(y_true=y, y_pred=y_)\n",
    "\n",
    "l = loss(model, features, labels, training=False)\n",
    "print(\"Loss test: {}\".format(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c20803-e5c2-488b-9d4b-047bb34ba374",
   "metadata": {},
   "source": [
    "Der LUSI Loss $S(\\theta, \\mathcal{D}_n)$ ist wie folgt gegeben, falls nur faktorisierende Prädikate $\\phi(x) \\odot \\tau(y)$ betrachtet werden:\n",
    "$$ \\begin{align*}\n",
    "    S(\\theta, \\mathcal{D}_n) = \\left \\lVert\\frac{1}{n}\\sum_{j=1}^{n}\\phi(x_j) \\odot [\\tau(y_j) - \\tau(f_{\\theta}(x_j)]\\right \\rVert_W^{2}.\n",
    "    \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d1768-3a26-4f25-b5de-a6c2e333604e",
   "metadata": {},
   "source": [
    "Ein Schätzer von $\\nabla_{\\theta}S(\\theta, \\mathcal{D}_n)$ basierend auf Batches $J, J \\prime$ der Größe $B, B\\prime$ ist gegeben durch:\n",
    "$$\\begin{align*}\n",
    "       \\left [\\frac{1}{B} \\sum_{j \\in J} \\phi(x_j) \\odot \\frac{\\partial \\tau(f_{\\theta}(x_j))}{\\partial \\theta}\\right ]^T \\cdot \\left [W +            W^T \\right ] \\cdot \\left [\\frac{1}{B \\prime} \\sum_{j\\prime \\in J\\prime}^n \\phi(x_{j\\prime})\\odot[\\tau(f_{\\theta}(x_{j\\prime})) -              \\tau(y_{j\\prime})]\\right ] \\text{.}\n",
    "    \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cddeb43-8349-4ba2-8090-74164902f0c1",
   "metadata": {},
   "source": [
    "Insbesondere lassen sich die Werte $\\phi(x_j)$ vorberechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28fb8cad-193e-4092-9c50-84d36e8fe15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(a,b,W):\n",
    "    \"\"\"Calculate a^T W b.\"\"\"\n",
    "    return np.dot(a, np.matmul(W, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1c0010dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d6eeef31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[20.]])>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_1 = tf.constant([1,2,3], dtype=tf.float64, shape=[1,3])\n",
    "v_2 = tf.constant([2,3,4], dtype=tf.float64, shape=[3,1])\n",
    "# tf.tensordot(v_1, v_2, 1)\n",
    "w_matrix = tf.constant(np.diag([1,1,1]), dtype=tf.float64)\n",
    "tf.tensordot(v_1, tf.matmul(w_matrix, v_2), 1)\n",
    "\n",
    "#tf.multiply(tf.convert_to_tensor(np.array([1,2,3])), tf.transpose(np.array([2,3,4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ccd884d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(v_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8535e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(a, b, W):\n",
    "    \"\"\"Calculate dot product between a, b using W as weight matrix.\n",
    "    \n",
    "    \n",
    "    a :: tensor of dtype tf.float64\n",
    "    transposed vector\n",
    "    b :: tensor of dtype tf.float64\n",
    "    non-transposed vector\n",
    "    W :: tensor of dtype tf.float64\n",
    "    matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.tensordot(a, tf.matmul(W, b), 1)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "75f4d8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[20.]])>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot(v_1, v_2, w_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c929d14a-1567-4d6f-9b1b-3a1789705c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LusiLossBasic(tf.losses.Loss):\n",
    "    # for now, let tau = id\n",
    "    def __init__(self, phi, W):\n",
    "        \n",
    "        \"\"\"Initialize Loss object given predicates and weight matrix.\n",
    "        \n",
    "        Parameters:\n",
    "            phi :: array of dim batch_size x (no. of predicates each mapping to R)\n",
    "            The part of the predicate acting on X, already evaluated\n",
    "            \n",
    "            tau :: array of dim batch_size x (no. of predicates each mapping to R)\n",
    "            The part of the predicate acting on Y, as functions\n",
    "            \n",
    "            W :: weight matrix of adequate dimensions.\n",
    "            \n",
    "        \"\"\"\n",
    "        # Assume that predicates are factorizing, that is of form phi(x)tau(y)\n",
    "        super.__init__()\n",
    "        self.phi = phi\n",
    "        self.W = W\n",
    "        \n",
    "    def call(self, y_pred, y_true):\n",
    "        return dot(self.phi * (y - y_pred), self.W, self.phi * (y - y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224566a7-a908-4e5b-8199-306f90e02d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 16:20:11.908883: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define a simple neural network with one hidden layer and one output layer\n",
    "nn_bin_class = keras.Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=(28,28), name=\"flatten_input\"),  # declare shape of one input beforehand\n",
    "        layers.Dense(500, activation=\"relu\", name=\"hidden_layer_01\"),\n",
    "        layers.Dense(1, name=\"output_layer\", activation=\"sigmoid\"), # interpret output as prob. for class 1\n",
    "    ]\n",
    ")\n",
    "# Call model on a test input\n",
    "x = tf.ones((2,28,28))\n",
    "\n",
    "y = nn_bin_class(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3130d36c-825c-4f18-8ce9-88b963e19a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.4028263],\n",
       "       [0.4028263]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae26bbd-5765-4e10-829b-1bebd8f2155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn_bin_class.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851705d4-bed2-498b-bb9e-6b02e325a8a4",
   "metadata": {},
   "source": [
    "### Learnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86ac9e-b725-4764-b96f-a4677c0e9d17",
   "metadata": {},
   "source": [
    "Die Loss Funktion kann nicht von den Prädikaten abhängen in diesem einfachen Sinne, wie für LusiLossBasic definiert.\n",
    "Wenn ich neue Daten habe, kann ich diese ja nicht nachträglich mit in den Loss schieben....\n",
    "\n",
    "-> Ich muss also rein theoretisch die Prädikate mit in die Klasse aufnehmen als Funktionen.\n",
    "Problem: Dann muss ich auch die zu den Labels gehörenden X-Daten mit aufnehmen. NIcht plausibel, siehe **LusiLossBasic2nd\n",
    "\n",
    "-> From scratch Implementierung in tensorflow notwendig?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "16709c7c-5d1a-40d2-af9d-c48c1594f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuer Versuch\n",
    "class LusiLossBasic2nd(tf.losses.Loss):\n",
    "    # for now, let tau = id\n",
    "    def __init__(self, phi, tau, W):\n",
    "        \n",
    "        \"\"\"Initialize Loss object given predicates and weight matrix.\n",
    "        \n",
    "        Parameters:\n",
    "            phi :: list\n",
    "            array of predicates over X space.\n",
    "            \n",
    "            \n",
    "            tau :: list\n",
    "            array of predicates over Y space.\n",
    "            \n",
    "            W :: weight matrix of adequate dimensions.\n",
    "            \n",
    "        \"\"\"\n",
    "        # Assume that predicates are factorizing, that is of form phi(x)tau(y)\n",
    "        \n",
    "        # Check if dims are ok\n",
    "        if not (len(phi) == W.shape[0] and len(tau) == w.shape[0] and W.shape[0] == W.shape[1]):\n",
    "            raise Exception(\"Check dims.\")\n",
    "\n",
    "        # if dims are ok, continue\n",
    "        super.__init__()\n",
    "        self.phi = phi\n",
    "        self.tau = tau\n",
    "        self.W = W\n",
    "    \n",
    "    \n",
    "    def call(self, y_pred, y_true):\n",
    "        return dot(self.phi * (y - y_pred), self.W, self.phi * (y - y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e613ce9-4147-468e-a3fd-bf328510586f",
   "metadata": {},
   "source": [
    "### From Scratch Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451f66c-6cd9-4959-91c3-6047ebdf082b",
   "metadata": {},
   "source": [
    "see this <a href=\"https://medium.com/analytics-vidhya/how-to-write-a-neural-network-in-tensorflow-from-scratch-without-using-keras-e056bb143d78\">link</a> for an implementation of a neural net in tensorflow without keras from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "54ac910d-12f9-4770-ba41-057e0aed4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ad18204d-27d8-43d2-ae6d-da80b8ca69c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (32, 28, 28) (32,)\n",
      "1 (32, 28, 28) (32,)\n",
      "2 (32, 28, 28) (32,)\n",
      "3 (32, 28, 28) (32,)\n",
      "4 (32, 28, 28) (32,)\n",
      "5 (32, 28, 28) (32,)\n",
      "6 (32, 28, 28) (32,)\n",
      "7 (32, 28, 28) (32,)\n",
      "8 (32, 28, 28) (32,)\n",
      "9 (32, 28, 28) (32,)\n"
     ]
    }
   ],
   "source": [
    "for (i,j) in enumerate(train_dataset):\n",
    "    if i < 10:\n",
    "        print(i, j[0].shape,j[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261090ac-a3b6-4476-b484-c888c6316d95",
   "metadata": {},
   "source": [
    "Eine Strategie könnte daraus bestehen, die tf Dataset Klasse zu überarbeiten und mehrere Batches auf einmal auszugeben -> neue Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "9b8fc9a7-1e15-48b2-887e-ba51ef12ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "823c7275-32a3-400f-b73f-90a0adf7b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bool = ops.convert_to_tensor(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ce0d3baf-8c65-443f-b7fc-83dfd87d6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bool_const = tensor_util.constant_value(t_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "87ad9442-fe9c-474c-9bd8-b5eb545549c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.bool_"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(t_bool_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "062df216-85a0-44ae-9707-523a2179116e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.bool_"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.True_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "aa0f340b-87d8-4fe3-93c8-d6eb928831b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensor_util.constant_value(ops.convert_to_tensor(64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "775721a8-681a-4799-83f6-7dddd27d60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.util import _pywrap_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "3d43f5f8-c0a9-4415-9b94-50b8e3211d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function FlattenForData in module tensorflow.python.util._pywrap_utils:\n",
      "\n",
      "FlattenForData(...) method of builtins.PyCapsule instance\n",
      "    FlattenForData(arg0: handle) -> object\n",
      "    \n",
      "    \n",
      "    Returns a flat sequence from a given nested structure.\n",
      "    \n",
      "    If `nest` is not a sequence, this returns a single-element list: `[nest]`.\n",
      "    \n",
      "    Args:\n",
      "      nest: an arbitrarily nested structure or a scalar object.\n",
      "        Note, numpy arrays are considered scalars.\n",
      "    \n",
      "    Returns:\n",
      "      A Python list, the flattened version of the input.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(_pywrap_utils.FlattenForData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "54d0161a-a8b9-450c-b76d-c252aeeb0f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4], [1, 0, -1]]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pywrap_utils.FlattenForData({1:[2,3,4], 2:[1,0,-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "facf99c8-0d42-4f8c-a1f2-924125d82607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pywrap_utils.FlattenForData(((((1,2),3),4),(5,6), 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "8b8828d9-5d42-4721-8b57-eee8fa2056a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [305]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_pywrap_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlattenForData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "zip(*_pywrap_utils.FlattenForData(((1,2),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e9358056-58d7-4e09-b03d-1c7bf0cbd87b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2697577169.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [306]\u001b[0;36m\u001b[0m\n\u001b[0;31m    help(*)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "help(*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e57777fc-20d4-425b-b173-6e240efe9f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x1ac9bdb00>\n"
     ]
    }
   ],
   "source": [
    "print(zip(*['A', 'n', 'd', 'y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "6c0c84c5-a0a4-4de9-bf5b-b5d746b7c383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on zip object:\n",
      "\n",
      "class zip(object)\n",
      " |  zip(*iterables, strict=False) --> Yield tuples until an input is exhausted.\n",
      " |  \n",
      " |     >>> list(zip('abcdefg', range(3), range(4)))\n",
      " |     [('a', 0, 0), ('b', 1, 1), ('c', 2, 2)]\n",
      " |  \n",
      " |  The zip object yields n-length tuples, where n is the number of iterables\n",
      " |  passed as positional arguments to zip().  The i-th element in every tuple\n",
      " |  comes from the i-th iterable argument to zip().  This continues until the\n",
      " |  shortest argument is exhausted.\n",
      " |  \n",
      " |  If strict is true and one of the arguments is exhausted before the others,\n",
      " |  raise a ValueError.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __next__(self, /)\n",
      " |      Implement next(self).\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Return state information for pickling.\n",
      " |  \n",
      " |  __setstate__(...)\n",
      " |      Set state information for unpickling.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(zip(*['A', 'n', 'd', 'y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "7de56db1-d4f9-40f2-b5bc-9407442c2af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] [2, 3] [4, 5]\n"
     ]
    }
   ],
   "source": [
    "print(*[[0,1],[2,3],[4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1b697311-091d-48fd-933b-973e5c8ba0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [2, 3], [4, 5]]\n"
     ]
    }
   ],
   "source": [
    "a = [[0,1],[2,3],[4,5]]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "70d1ef7c-802c-48ff-b720-652084348f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = zip(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0d8f7608-1545-42ca-87fc-f211578a0e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2, 4), (1, 3, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(list(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "9cdc6fd7-cd53-4aac-a5ee-96a3328c2d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.tensor_spec.TensorSpec"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset.element_spec[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "5e68e53d-654c-41e5-bd6b-5141380e6492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "8754a9ce-ae20-4825-abf3-1c10fac5fbdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [335]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m help(\u001b[43mtensorflow\u001b[49m\u001b[38;5;241m.\u001b[39mpython\u001b[38;5;241m.\u001b[39mframework\u001b[38;5;241m.\u001b[39mtensor_spec\u001b[38;5;241m.\u001b[39mTensorSpec)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensorflow' is not defined"
     ]
    }
   ],
   "source": [
    "help(tensorflow.python.framework.tensor_spec.TensorSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "7dc47676-79b7-4e2a-ba8f-753dad46ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.tensor_spec import TensorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "54bd1ac7-b417-4b40-8fdc-de1ae8ed0058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TensorSpec in module tensorflow.python.framework.tensor_spec:\n",
      "\n",
      "class TensorSpec(DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec)\n",
      " |  TensorSpec(shape, dtype=tf.float32, name=None)\n",
      " |  \n",
      " |  Describes a tf.Tensor.\n",
      " |  \n",
      " |  Metadata for describing the `tf.Tensor` objects accepted or returned\n",
      " |  by some TensorFlow APIs.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TensorSpec\n",
      " |      DenseSpec\n",
      " |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      " |      tensorflow.python.framework.type_spec.TypeSpec\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  is_compatible_with(self, spec_or_tensor)\n",
      " |      Returns True if spec_or_tensor is compatible with this TensorSpec.\n",
      " |      \n",
      " |      Two tensors are considered compatible if they have the same dtype\n",
      " |      and their shapes are compatible (see `tf.TensorShape.is_compatible_with`).\n",
      " |      \n",
      " |      Args:\n",
      " |        spec_or_tensor: A tf.TensorSpec or a tf.Tensor\n",
      " |      \n",
      " |      Returns:\n",
      " |        True if spec_or_tensor is compatible with self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_spec(spec, name=None) from abc.ABCMeta\n",
      " |      Returns a `TensorSpec` with the same shape and dtype as `spec`.\n",
      " |      \n",
      " |      >>> spec = tf.TensorSpec(shape=[8, 3], dtype=tf.int32, name=\"OriginalName\")\n",
      " |      >>> tf.TensorSpec.from_spec(spec, \"NewName\")\n",
      " |      TensorSpec(shape=(8, 3), dtype=tf.int32, name='NewName')\n",
      " |      \n",
      " |      Args:\n",
      " |        spec: The `TypeSpec` used to create the new `TensorSpec`.\n",
      " |        name: The name for the new `TensorSpec`.  Defaults to `spec.name`.\n",
      " |  \n",
      " |  from_tensor(tensor, name=None) from abc.ABCMeta\n",
      " |      Returns a `TensorSpec` that describes `tensor`.\n",
      " |      \n",
      " |      >>> tf.TensorSpec.from_tensor(tf.constant([1, 2, 3]))\n",
      " |      TensorSpec(shape=(3,), dtype=tf.int32, name=None)\n",
      " |      \n",
      " |      Args:\n",
      " |        tensor: The `tf.Tensor` that should be described.\n",
      " |        name: A name for the `TensorSpec`.  Defaults to `tensor.op.name`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `TensorSpec` that describes `tensor`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  value_type\n",
      " |      The Python type for values that are compatible with this TypeSpec.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from DenseSpec:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, shape, dtype=tf.float32, name=None)\n",
      " |      Creates a TensorSpec.\n",
      " |      \n",
      " |      Args:\n",
      " |        shape: Value convertible to `tf.TensorShape`. The shape of the tensor.\n",
      " |        dtype: Value convertible to `tf.DType`. The type of the tensor values.\n",
      " |        name: Optional name for the Tensor.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If shape is not convertible to a `tf.TensorShape`, or dtype is\n",
      " |          not convertible to a `tf.DType`.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  most_specific_compatible_type(self, other)\n",
      " |      Returns the most specific TypeSpec compatible with `self` and `other`.\n",
      " |      \n",
      " |      Args:\n",
      " |        other: A `TypeSpec`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      " |          and `other`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from DenseSpec:\n",
      " |  \n",
      " |  dtype\n",
      " |      Returns the `dtype` of elements in the tensor.\n",
      " |  \n",
      " |  name\n",
      " |      Returns the (optionally provided) name of the described tensor.\n",
      " |  \n",
      " |  shape\n",
      " |      Returns the `TensorShape` that represents the shape of the tensor.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from tensorflow.python.framework.type_spec.BatchableTypeSpec:\n",
      " |  \n",
      " |  __batch_encoder__ = <tensorflow.python.framework.type_spec.LegacyTypeS...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      Helper for pickle.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TensorSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "4e1d2bed-b065-4496-a251-5e47f1b76713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 0., 4., 1., 9., 2., 1., 3., 1., 4., 3., 5., 3., 6., 1., 7., 2.,\n",
       "       8., 6., 9., 4., 0., 9., 1., 1., 2., 4., 3., 2., 7., 3., 8.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#help(train_dataset.batch(32))\n",
    "train_dataset.batch(32).element_spec\n",
    "list(train_dataset.batch(32, drop_remainder=True).as_numpy_iterator())[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e2f9b",
   "metadata": {},
   "source": [
    "### 02.05.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a807849",
   "metadata": {},
   "source": [
    "#### I. LUSI for gradient descent on entire training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8af7c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = lambda x: x\n",
    "f_2 = lambda x: x**2\n",
    "f_3 = lambda x: x**3\n",
    "f_4 = lambda x: x**4\n",
    "\n",
    "f = np.array([f_1, f_2, f_3, f_4])\n",
    "y = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67a501e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_f = [f[i](y[j]) for j in range(y.shape[0])  for i in range(f.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51164382",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_f = np.asarray(y_f).reshape(y.shape[0], f.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2cf79ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0]\n",
      " [   1    1    1    1]\n",
      " [   2    4    8   16]\n",
      " [   3    9   27   81]\n",
      " [   4   16   64  256]\n",
      " [   5   25  125  625]\n",
      " [   6   36  216 1296]\n",
      " [   7   49  343 2401]\n",
      " [   8   64  512 4096]\n",
      " [   9   81  729 6561]]\n"
     ]
    }
   ],
   "source": [
    "print(y_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5b68b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7, 1, 7],\n",
       "       [9, 1, 0, 1],\n",
       "       [6, 7, 0, 1],\n",
       "       [7, 4, 8, 8],\n",
       "       [0, 0, 5, 5],\n",
       "       [1, 6, 5, 4],\n",
       "       [1, 0, 9, 0],\n",
       "       [0, 0, 4, 6],\n",
       "       [5, 5, 2, 4],\n",
       "       [6, 8, 7, 7]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_x = np.random.randint(0, 10, size=(y.shape[0], f.shape[0]))\n",
    "phi_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06970e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0],\n",
       "       [    9,     1,     0,     1],\n",
       "       [   12,    28,     0,    16],\n",
       "       [   21,    36,   216,   648],\n",
       "       [    0,     0,   320,  1280],\n",
       "       [    5,   150,   625,  2500],\n",
       "       [    6,     0,  1944,     0],\n",
       "       [    0,     0,  1372, 14406],\n",
       "       [   40,   320,  1024, 16384],\n",
       "       [   54,   648,  5103, 45927]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_x * y_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9c5ed5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuer Versuch\n",
    "class LusiLossNoBatch(tf.losses.Loss):\n",
    "    # for now, let tau = id\n",
    "    def __init__(self, phi_x, tau, W):\n",
    "    \n",
    "        \n",
    "        \"\"\"Initialize Loss object given predicates and weight matrix.\n",
    "        \n",
    "        Parameters:\n",
    "            phi :: list\n",
    "            array of evaluations of predicates over space X\n",
    "            dims: (batch_size, no_of_predicates)\n",
    "            \n",
    "            tau :: list\n",
    "            array of predicates over Y space.\n",
    "            \n",
    "            W :: symmetric, positive definite weight matrix\n",
    "                 of adequate dimensions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Assume that predicates are factorizing, that is of form phi(x)tau(y)\n",
    "        \n",
    "        # Check if dims are ok\n",
    "        if not (tau.shape[0] == W.shape[0] and W.shape[0] == W.shape[1]):\n",
    "            raise Exception(\"Check dims tau and W.\")\n",
    "\n",
    "        # if dims are ok, continue\n",
    "        super().__init__()\n",
    "        self.phi_x = phi_x\n",
    "        self.tau = tau\n",
    "        self.W = W\n",
    "    \n",
    "    \n",
    "    def call(self, y_pred, y_true):\n",
    "        # y_pred and y_true expected to have dims (batch_size, d0, ..., dN) where di means dimension i.\n",
    "        # Explicitly for bin. class: dims are given by (batch_size, d0)\n",
    "        \n",
    "        if not y_true.shape[0] == y_pred.shape[0]:\n",
    "            raise Exception(\"Check dims y-values.\")\n",
    "        \n",
    "        if not self.phi_x.shape[1] == self.tau.shape[0]:\n",
    "            raise Exception(\"Check dims tau and phi_x\")\n",
    "        \n",
    "        if not self.phi_x.shape[0] == y_pred.shape[0]:\n",
    "            print(self.phi_x.shape[0], y_pred.shape[0])\n",
    "            raise Exception(\"Check dims y and phi_x\")\n",
    "        \n",
    "        # for each y, we get vector [tau_1(y), ..., tau_d(y)], same for y_pred\n",
    "        y_dim = y_true.shape[0]\n",
    "        \n",
    "        y_tau = [self.tau[i](y_true[j]) for j in range(y_true.shape[0])  for i in range(self.tau.shape[0])]\n",
    "        # y_true = np.asarray(y_tau)\n",
    "        # y_true = y_true.reshape(y_dim, self.tau.shape[0])\n",
    "        \n",
    "        \n",
    "        y_true = tf.convert_to_tensor(y_tau, dtype=tf.float64)\n",
    "        y_true = tf.reshape(y_true, [y_dim, self.tau.shape[0]])\n",
    "\n",
    "        \n",
    "        y_pred_tau = [self.tau[i](y_pred[j]) for j in range(y_pred.shape[0])  for i in range(self.tau.shape[0])]\n",
    "#         y_pred = np.asarray(y_pred_tau)\n",
    "#         y_pred.reshape(y_dim, self.tau.shape[0])\n",
    "        y_pred = tf.convert_to_tensor(y_pred_tau, dtype=tf.float64)\n",
    "        y_pred = tf.reshape(y_pred,[y_dim, self.tau.shape[0]])\n",
    "        \n",
    "\n",
    "        \n",
    "        no_weight_loss = tf.reduce_mean(self.phi_x * (y_true - y_pred), axis=0)\n",
    "        # no_weight_loss should be tensor of dims (1, no_of_predicates)\n",
    "        no_weight_loss = tf.reshape(no_weight_loss, [self.tau.shape[0],1])\n",
    "        # no_weight_loss = tf.reduce_mean(self.phi_x * (y - y_), axis=0)\n",
    "\n",
    "        return dot(tf.transpose(no_weight_loss), no_weight_loss, self.W)\n",
    "        #return tf.square(y_true-y_pred)   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a850b",
   "metadata": {},
   "source": [
    "##### Try to fit model using this loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1136a699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df008a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(28,), dtype=float32, numpy=\n",
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.08613446, 0.3144258 , 0.37492996, 0.27254903,\n",
       "       0.22801122, 0.2401961 , 0.24845941, 0.24845938, 0.2245098 ,\n",
       "       0.25210086, 0.3053221 , 0.28557426, 0.20714286, 0.22675072,\n",
       "       0.3943978 , 0.3114846 , 0.13459383, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape\n",
    "tf.reduce_mean(x_train[1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8290823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(10).reshape(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29e23a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10).reshape(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f407fa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [2., 3.],\n",
       "       [4., 5.],\n",
       "       [6., 7.],\n",
       "       [8., 9.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(10).reshape(5,2)*np.arange(10).reshape(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9182ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float64, numpy=array([0.5, 2.5, 4.5, 6.5, 8.5])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(np.ones(10).reshape(5,2)*np.arange(10).reshape(5,2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c161822",
   "metadata": {},
   "source": [
    "-> reduce along axis 0 means reducing along rows, that is keeping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4794b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I. Define predicates on image data\n",
    "avg_pixel_intensity = lambda x: tf.reduce_mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "242d5b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.arange(1,15)\n",
    "np.arange(14, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b086a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.arange(1,15), np.arange(14, 0, -1)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2fc85c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_pixel_intesity(x):\n",
    "    row_mean = tf.reduce_mean(x, axis=1)\n",
    "    weights = np.concatenate([np.arange(1,15), np.arange(14, 0, -1)])\n",
    "    weighted_intesity = row_mean * weights\n",
    "    return np.mean(weighted_intesity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e8bab",
   "metadata": {},
   "source": [
    "Setting is supervised learning setting, i.e. the problem is to find prob. measure on $\\mathcal{X \\times Y}$\n",
    "\n",
    "Predicates are of the form $\\phi(x)\\tau(y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d62f2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_pixel_intensity(x, patch):\n",
    "    \"\"\"Calc. avg. pixel intensity on local patch of image.\n",
    "    \n",
    "    x :: np.array\n",
    "    dims = (batch, 28, 28).\n",
    "    \n",
    "    patch :: tuple[tuple]\n",
    "    coordinates for patch. Tuple structure as follows: ((x_dim_0, x_dim_1), (y_dim_0, y_dim_1)).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    extracted_patch = x[:, patch[0][0]:patch[0][1], patch[1][0]: patch[1][1]]\n",
    "    return tf.reduce_mean(extracted_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5f8a5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_pixel_intensity_single(x, patch):\n",
    "    # TODO: Find a way to accomodate single sample eval in the original function\n",
    "    \n",
    "    \"\"\"Calc. avg. pixel intensity on local patch of image.\n",
    "    \n",
    "    x :: np.array\n",
    "    dims = (28, 28).\n",
    "    \n",
    "    patch :: tuple[tuple]\n",
    "    coordinates for patch. Tuple structure as follows: ((x_dim_0, x_dim_1), (y_dim_0, y_dim_1)).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    extracted_patch = x[patch[0][0]:patch[0][1], patch[1][0]: patch[1][1]]\n",
    "    return tf.reduce_mean(extracted_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38361a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_x(predicates, x):\n",
    "    \"\"\" Evaluate predicates on data and store values.\n",
    "    \n",
    "    predicates :: np.array\n",
    "    List of \\R valued predicates working on x of dimension d.\n",
    "    \n",
    "    x :: np.array\n",
    "    data to apply predicates to of dimensinos (n, d0, ..., dN).\n",
    "    I.e. for MNIST, dims = (n, 28, 28)\n",
    "    \n",
    "    returns:\n",
    "    array of dimensions (n, d).\n",
    "    \"\"\"\n",
    "    \n",
    "    pred_evals = np.asarray([predicates[i](x[j]) for j in range(x.shape[0]) for i in range(predicates.shape[0])])\n",
    "    pred_evals = pred_evals.reshape(x.shape[0], predicates.shape[0])\n",
    "    \n",
    "    \n",
    "    return pred_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "69b2c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b9155224",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_pixel_intensity_center = functools.partial(local_pixel_intensity_single, patch=((10,20), (10,20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "826864bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = np.asarray([avg_pixel_intensity, weighted_pixel_intesity, local_pixel_intensity_center])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "892ff517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_x(phi, x_train[:1000, :, :]/255).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "90ac19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = lambda x: x\n",
    "tau = np.asarray([identity, identity, identity])\n",
    "# tau = tf.convert_to_tensor([identity, identity, identity])\n",
    "# Cannot convert a list of functions to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4e445333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<function <lambda> at 0x19e43c820>,\n",
       "       <function weighted_pixel_intesity at 0x19e276950>,\n",
       "       functools.partial(<function local_pixel_intensity_single at 0x19ef644c0>, patch=((10, 20), (10, 20)))],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f1f2ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_matrix = tf.convert_to_tensor(np.diag(np.ones(3)), dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfaf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: sevens, eights\n",
    "# sevens, eights\n",
    "# y_sevens, y_eights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d658cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network with one hidden layer and one output layer\n",
    "nn_bin_class = keras.Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=(28,28), name=\"flatten_input\"),  # declare shape of one input beforehand\n",
    "        layers.Dense(500, activation=\"relu\", name=\"hidden_layer_01\"),\n",
    "        layers.Dense(1, name=\"output_layer\", activation=\"sigmoid\"), # interpret output as prob. for class 1\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ff77cfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([400, 1])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_bin_class(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "05d5fe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4842, 28, 28)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4262a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "sevens_lusi = sevens[:200]\n",
    "eights_lusi = eights[:200]\n",
    "y_sevens_lusi = np.zeros(200)\n",
    "y_eights_lusi = np.ones(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ccf219c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([sevens_lusi, eights_lusi])\n",
    "y_train = np.concatenate([y_sevens_lusi, y_eights_lusi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9416a306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 28, 28)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1785fe4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "16d6c1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e17b02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_eval = phi_x(phi, x_train/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8595eac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 3)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4e7f4b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf.convert_to_tensor(phi_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "07c4de94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d35fc67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_bin_class.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    # loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    loss=LusiLossNoBatch(phi_eval, tau, w_matrix),\n",
    "    metrics=[keras.metrics.Accuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "263b6b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 9.0503e-11 - accuracy: 0.0175\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2874e-10 - accuracy: 0.0175\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1891e-10 - accuracy: 0.0175\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.9916e-11 - accuracy: 0.0175\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1563e-10 - accuracy: 0.0175\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2076e-10 - accuracy: 0.0175\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0294e-10 - accuracy: 0.0175\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3313e-10 - accuracy: 0.0175\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2168e-10 - accuracy: 0.0175\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.7659e-10 - accuracy: 0.0175\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5811e-11 - accuracy: 0.0175\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4841e-10 - accuracy: 0.0175\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0874e-10 - accuracy: 0.0175\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.2762e-11 - accuracy: 0.0175\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.3648e-11 - accuracy: 0.0175\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.5120e-11 - accuracy: 0.0175\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.7922e-11 - accuracy: 0.0175\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1969e-10 - accuracy: 0.0175\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0248e-11 - accuracy: 0.0175\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3661e-10 - accuracy: 0.0175\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7887e-11 - accuracy: 0.0175\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.9197e-11 - accuracy: 0.0175\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7368e-11 - accuracy: 0.0175\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1939e-11 - accuracy: 0.0175\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.7758e-11 - accuracy: 0.0175\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.5684e-11 - accuracy: 0.0175\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1141e-10 - accuracy: 0.0175\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8996e-11 - accuracy: 0.0175\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1913e-10 - accuracy: 0.0175\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1667e-11 - accuracy: 0.0175\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3372e-11 - accuracy: 0.0175\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.9734e-11 - accuracy: 0.0175\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0874e-10 - accuracy: 0.0175\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.4162e-11 - accuracy: 0.0175\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.0377e-11 - accuracy: 0.0175\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3464e-11 - accuracy: 0.0175\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.2721e-11 - accuracy: 0.0175\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1654e-10 - accuracy: 0.0175\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.3129e-11 - accuracy: 0.0175\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2921e-10 - accuracy: 0.0175\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1398e-11 - accuracy: 0.0175\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.9622e-11 - accuracy: 0.0175\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8292e-11 - accuracy: 0.0175\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.2140e-11 - accuracy: 0.0175\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7886e-11 - accuracy: 0.0175\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.0756e-11 - accuracy: 0.0175\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.1265e-11 - accuracy: 0.0175\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.4337e-11 - accuracy: 0.0175\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.3598e-11 - accuracy: 0.0175\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0626e-10 - accuracy: 0.0175\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.0461e-11 - accuracy: 0.0175\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.4342e-11 - accuracy: 0.0175\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.1291e-11 - accuracy: 0.0175\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0211e-10 - accuracy: 0.0175\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8666e-11 - accuracy: 0.0175\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.3404e-11 - accuracy: 0.0175\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.4584e-11 - accuracy: 0.0175\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.8695e-11 - accuracy: 0.0175\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.9628e-11 - accuracy: 0.0175\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0198e-10 - accuracy: 0.0175\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.8882e-11 - accuracy: 0.0175\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.8018e-11 - accuracy: 0.0175\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3314e-10 - accuracy: 0.0175\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2863e-10 - accuracy: 0.0175\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0607e-10 - accuracy: 0.0175\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.2727e-11 - accuracy: 0.0175\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.2902e-11 - accuracy: 0.0175\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.9608e-11 - accuracy: 0.0175\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.4920e-11 - accuracy: 0.0175\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.1153e-11 - accuracy: 0.0175\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0203e-10 - accuracy: 0.0175\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.6295e-11 - accuracy: 0.0175\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0201e-10 - accuracy: 0.0175\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.4550e-11 - accuracy: 0.0175\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.4472e-11 - accuracy: 0.0175\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8515e-11 - accuracy: 0.0175\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.5912e-11 - accuracy: 0.0175\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.8205e-11 - accuracy: 0.0175\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.0493e-11 - accuracy: 0.0175\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.8146e-11 - accuracy: 0.0175\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.2679e-11 - accuracy: 0.0175\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.8800e-11 - accuracy: 0.0175\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.3758e-11 - accuracy: 0.0175\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.8628e-11 - accuracy: 0.0175\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.8654e-11 - accuracy: 0.0175\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.1044e-11 - accuracy: 0.0175\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1232e-10 - accuracy: 0.0175\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.5209e-11 - accuracy: 0.0175\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.1279e-11 - accuracy: 0.0175\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6112e-11 - accuracy: 0.0175\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.2482e-11 - accuracy: 0.0175\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.5092e-11 - accuracy: 0.0175\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0290e-10 - accuracy: 0.0175\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.6685e-11 - accuracy: 0.0175\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.1051e-11 - accuracy: 0.0175\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.1508e-11 - accuracy: 0.0175\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.0228e-11 - accuracy: 0.0175\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.9197e-11 - accuracy: 0.0175\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0553e-10 - accuracy: 0.0175\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.9984e-11 - accuracy: 0.0175\n"
     ]
    }
   ],
   "source": [
    "hist_nn_bin_class = nn_bin_class.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=x_train.shape[0],\n",
    "    epochs=100\n",
    "    #validation_data=(x_val, y_val)  add argument\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "848f7e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00029203],\n",
       "       [0.06547606],\n",
       "       [0.00106779],\n",
       "       ...,\n",
       "       [0.00028142],\n",
       "       [0.00041658],\n",
       "       [0.00016576]], dtype=float32)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_bin_class.predict(sevens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "72aede71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1cdf1cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(tf.convert_to_tensor([1,2,3,4]), [2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Explicitly for bin. class - dims are given by (batch_size, d0)\n",
    "        \n",
    "        if not y_true.shape[0] == y_pred.shape[0]:\n",
    "            raise Exception(\"Check dims y-values.\")\n",
    "        \n",
    "        if not self.phi_x.shape[1] == self.tau.shape[0]:\n",
    "            raise Exception(\"Check dims tau and phi_x\")\n",
    "        \n",
    "        if not self.phi_x.shape[0] == y_pred.shape[0]:\n",
    "            raise Exception(\"Check dims y and phi_x\")\n",
    "        \n",
    "        y_dim = y_true.shape[0]\n",
    "\n",
    "        # for each y_true, calc vector [tau_1(y_true), ..., tau_d(y_true)], same for y_pred\n",
    "        y_tau = [self.tau[i](y_true[j]) for j in range(y_true.shape[0])  for i in range(self.tau.shape[0])]        \n",
    "        y_true = tf.convert_to_tensor(y_tau, dtype=tf.float64)\n",
    "        y_true = tf.reshape(y_true, [y_dim, self.tau.shape[0]])\n",
    "\n",
    "        y_pred_tau = [self.tau[i](y_pred[j]) for j in range(y_pred.shape[0])  for i in range(self.tau.shape[0])]\n",
    "        y_pred = tf.convert_to_tensor(y_pred_tau, dtype=tf.float64)\n",
    "        y_pred = tf.reshape(y_pred,[y_dim, self.tau.shape[0]])\n",
    "        \n",
    "\n",
    "        \n",
    "        no_weight_loss = tf.reduce_mean(self.phi_x * (y_true - y_pred), axis=0)\n",
    "        # no_weight_loss should be tensor of dims (1, no_of_predicates)\n",
    "        no_weight_loss = tf.reshape(no_weight_loss, [self.tau.shape[0],1])\n",
    "\n",
    "        return dot(tf.transpose(no_weight_loss), no_weight_loss, self.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e16b5c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 0, 0],\n",
       "       [0, 3, 0],\n",
       "       [0, 0, 2]], dtype=int32)>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.diag([1,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "94d061d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 3), dtype=int64, numpy=\n",
       "array([[[ 1,  0,  0],\n",
       "        [ 0,  2,  0],\n",
       "        [ 0,  0,  3]],\n",
       "\n",
       "       [[ 8,  0,  0],\n",
       "        [ 0, 10,  0],\n",
       "        [ 0,  0, 12]],\n",
       "\n",
       "       [[21,  0,  0],\n",
       "        [ 0, 24,  0],\n",
       "        [ 0,  0, 27]]])>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diags = tf.linalg.diag(np.array([[1,2,3],[4,5,6],[7,8,9]]))\n",
    "vecs = tf.constant([[[1,1,1]],[[2,2,2]],[[3,3,3]]], dtype=tf.int64)\n",
    "diags * vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5db8db9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 3), dtype=int64, numpy=\n",
       "array([[[1, 1, 1]],\n",
       "\n",
       "       [[2, 2, 2]],\n",
       "\n",
       "       [[3, 3, 3]]])>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "930fc40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.0004962 , 0.        , 0.        ],\n",
       "       [0.        , 0.00503395, 0.        ],\n",
       "       [0.        , 0.        , 0.00153187]], dtype=float32)>"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.diag(phi_eval)[0, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ebc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lusi_loss_batch(model, inputs, y_true, phi_x, tau, W):\n",
    "    \"\"\"Given batch, calculate loss and gradient of loss.\n",
    "    \n",
    "    Special gradient defined to get unbiased estimate of gradient.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if not y_true.shape[0] == y_pred.shape[0]:\n",
    "        raise Exception(\"Check dims y-values.\")\n",
    "\n",
    "    if not self.phi_x.shape[1] == self.tau.shape[0]:\n",
    "        raise Exception(\"Check dims tau and phi_x\")\n",
    "\n",
    "    if not self.phi_x.shape[0] == y_pred.shape[0]:\n",
    "        raise Exception(\"Check dims y and phi_x\")\n",
    "    \n",
    "    y_dim = y_true.shape[0]\n",
    "\n",
    "    # for each y_true, calc vector [tau_1(y_true), ..., tau_d(y_true)], same for y_pred\n",
    "    y_tau = [self.tau[i](y_true[j]) for j in range(y_true.shape[0])  for i in range(self.tau.shape[0])]        \n",
    "    y_true = tf.convert_to_tensor(y_tau, dtype=tf.float64)\n",
    "    y_true = tf.reshape(y_true, [y_dim, self.tau.shape[0]])\n",
    "    \n",
    "    y_pred = model(inputs)\n",
    "    y_pred_tau = [self.tau[i](y_pred[j]) for j in range(y_pred.shape[0])  for i in range(self.tau.shape[0])]\n",
    "    y_pred = tf.convert_to_tensor(y_pred_tau, dtype=tf.float64)\n",
    "    y_pred = tf.reshape(y_pred,[y_dim, self.tau.shape[0]])\n",
    "\n",
    "    no_weight_loss = tf.reduce_mean(self.phi_x * (y_true - y_pred), axis=0)\n",
    "    # no_weight_loss should be tensor of dims (1, no_of_predicates)\n",
    "    no_weight_loss = tf.reshape(no_weight_loss, [self.tau.shape[0],1])\n",
    "    \n",
    "    def grad(upstream):\n",
    "        # unbiased estimate of gradient based on batches\n",
    "        B = y_dim // 2\n",
    "        B_prime = y_dim - B\n",
    "            \n",
    "        \n",
    "        first_sum = 1/B * tf.linalg.diag(phi_x[:B])\n",
    "        \n",
    "        return None\n",
    "\n",
    "    \n",
    "    return dot(tf.transpose(no_weight_loss), no_weight_loss, self.W)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lusi",
   "language": "python",
   "name": "lusi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
