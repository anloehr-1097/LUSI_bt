{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69796484",
   "metadata": {},
   "source": [
    "## Minimum Working Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "29ba73e1-c587-4e1b-b3f3-6ac75f69de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d174ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11d7d0",
   "metadata": {},
   "source": [
    "### Minimum working sample no. 1 - most basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "855ae85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([15., 39.], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ = tf.Variable([[1,2,3], [5,6,7]], dtype=tf.float32)\n",
    "theta_ = tf.Variable([2,2,2], dtype=tf.float32)\n",
    "b_ = tf.Variable(3, dtype=tf.float32)\n",
    "# tf.tensordot(x_, theta_, axes=1)\n",
    "tf.add(tf.tensordot(x_, theta_, axes=1), b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c69d8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, theta, b):\n",
    "    # x, theta tef.Variable of dtype float32\n",
    "    # x of dim (batch_size, 3)\n",
    "    # theta of dim (3,)\n",
    "    return tf.add(tf.tensordot(x, theta, axes=1), b)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64155f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([15., 39.], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_, theta_, b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6317d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'theta:0' shape=(3,) dtype=float32, numpy=array([0.34192663, 0.9594108 , 0.6897817 ], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "theta_ = tf.Variable(np.random.rand(3), dtype=tf.float32, name='theta')\n",
    "print(theta_)\n",
    "with tf.GradientTape() as g_tape:\n",
    "    y = model(x_, theta_, b_)\n",
    "    y_prime = tf.sigmoid(model(x_, theta_, b_))\n",
    "\n",
    "# grads = g_tape.gradient(y, theta_)\n",
    "jacs = g_tape.jacobian(y, theta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7904baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 7.3300934 15.29457  ], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [5. 6. 7.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(jacs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61067fd",
   "metadata": {},
   "source": [
    "#### Result:\n",
    "This works correctly and jacobian yields the true jacobian as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7772287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_loss(y, y_pred):\n",
    "    return tf.square(y - y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "db74c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.transpose(tf.Variable([1,0], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9deb13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g_tape:\n",
    "    y_pred = tf.sigmoid(model(x_, theta_, b_))\n",
    "    loss = bin_loss(y_true, y_pred)\n",
    "\n",
    "jacs = g_tape.jacobian(loss, theta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "705ec780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-3.5762787e-07,  1.0000000e+00], dtype=float32)>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred - y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "39259803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[-2.5579530e-13, -5.1159061e-13, -7.6738594e-13],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16265a32",
   "metadata": {},
   "source": [
    "#### Result:\n",
    "This seems to work as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5957f712",
   "metadata": {},
   "source": [
    "### Minimum working sample no. 2 - keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "3b1ef114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network with one hidden layer and one output layer\n",
    "k_bin_class = keras.Sequential(\n",
    "    [   layers.Input(3),\n",
    "        layers.Dense(100, activation=\"relu\", name=\"hidden_layer_01\"),\n",
    "        layers.Dense(1, name=\"output_layer\", activation=\"sigmoid\"), # interpret output as prob. for class 1\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0f23b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_01 (Dense)     (None, 100)               400       \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 501\n",
      "Trainable params: 501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "k_bin_class.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3b4638c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.53563327],\n",
       "       [0.6795165 ]], dtype=float32)>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_bin_class(x_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7591e05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = tf.transpose(tf.Variable([[1,0]], dtype=tf.float32))\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "eadc1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g_tape:\n",
    "    y_pred = k_bin_class(x_)\n",
    "\n",
    "jacs = g_tape.jacobian(y_pred, k_bin_class.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "45164eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g_tape:\n",
    "    y_pred = k_bin_class(x_)\n",
    "    loss = bin_loss(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "jacs = g_tape.jacobian(loss, k_bin_class.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4f9088b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1, 3, 100])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "aca9e9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.21563646],\n",
       "       [0.46174267]], dtype=float32)>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a311fe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.53563327]\n",
      " [0.6795165 ]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "33d84402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a76ff12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.21563646],\n",
       "       [0.46174267]], dtype=float32)>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(y_pred - y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e2875bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[-0.46436673],\n",
       "       [ 0.6795165 ]], dtype=float32)>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred - y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "715ee0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = tf.Variable([[1,2,3], [5,6,7]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bc8d5566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [5., 6., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "170995df",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [200]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m k_bin_class\u001b[38;5;241m.\u001b[39mtrainable_weights \u001b[38;5;241m-\u001b[39m \u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjacs\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "k_bin_class.trainable_weights - 1e-5 * jacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3ae5469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b8586f5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "var and delta do not have the same shape[3,100] [2,1,3,100] [Op:ResourceApplyGradientDescent]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [209]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjacs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_bin_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/keras/optimizer_v2/optimizer_v2.py:672\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    669\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_utils\u001b[38;5;241m.\u001b[39mstrategy_supports_no_merge_call():\n\u001b[0;32m--> 672\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mapply_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m    676\u001b[0m       functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distributed_apply, apply_state\u001b[38;5;241m=\u001b[39mapply_state),\n\u001b[1;32m    677\u001b[0m       args\u001b[38;5;241m=\u001b[39m(grads_and_vars,),\n\u001b[1;32m    678\u001b[0m       kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    679\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[1;32m    680\u001b[0m       })\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/keras/optimizer_v2/optimizer_v2.py:721\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m distribution\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mcolocate_vars_with(var):\n\u001b[1;32m    718\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m name_scope_only_in_function_or_graph(\n\u001b[1;32m    719\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eagerly_outside_functions \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    720\u001b[0m       var\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m--> 721\u001b[0m     update_op \u001b[38;5;241m=\u001b[39m \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39min_cross_replica_context():\n\u001b[1;32m    724\u001b[0m       \u001b[38;5;66;03m# In cross-replica context, extended.update returns a list of\u001b[39;00m\n\u001b[1;32m    725\u001b[0m       \u001b[38;5;66;03m# update ops from all replicas (group=False).\u001b[39;00m\n\u001b[1;32m    726\u001b[0m       update_ops\u001b[38;5;241m.\u001b[39mextend(update_op)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2634\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2631\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   2632\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2633\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2636\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2637\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3709\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   3707\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   3708\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 3709\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3715\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3711\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   3712\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   3713\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   3714\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 3715\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   3717\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:601\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/keras/optimizer_v2/optimizer_v2.py:704\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply_state\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_apply_args:\n\u001b[1;32m    703\u001b[0m   apply_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply_state\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m apply_state\n\u001b[0;32m--> 704\u001b[0m update_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_apply_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mapply_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var\u001b[38;5;241m.\u001b[39mconstraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies([update_op]):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:142\u001b[0m, in \u001b[0;36mSGD._resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mraw_ops\u001b[38;5;241m.\u001b[39mResourceApplyKerasMomentum(\n\u001b[1;32m    134\u001b[0m       var\u001b[38;5;241m=\u001b[39mvar\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    135\u001b[0m       accum\u001b[38;5;241m=\u001b[39mmomentum_var\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m       use_locking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_locking,\n\u001b[1;32m    140\u001b[0m       use_nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnesterov)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResourceApplyGradientDescent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m      \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr_t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_locking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_locking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py:404\u001b[0m, in \u001b[0;36mkwarg_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[38;5;124m only takes keyword args (possible keys: \u001b[39m\u001b[38;5;132;01m{kwargs}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    402\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease pass these args as kwargs instead.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    403\u001b[0m       \u001b[38;5;241m.\u001b[39mformat(f\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mf_argspec\u001b[38;5;241m.\u001b[39margs))\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py:1940\u001b[0m, in \u001b[0;36mresource_apply_gradient_descent\u001b[0;34m(var, alpha, delta, use_locking, name)\u001b[0m\n\u001b[1;32m   1938\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1940\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   1942\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7106\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7107\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: var and delta do not have the same shape[3,100] [2,1,3,100] [Op:ResourceApplyGradientDescent]"
     ]
    }
   ],
   "source": [
    "optimizer.apply_gradients(zip(jacs, k_bin_class.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "880b8f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 100)\n",
      "(1, 100)\n",
      "(1, 100, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "for g in jacs:\n",
    "    print(tf.reduce_mean(g, axis=0).shape)\n",
    "    g = tf.reduce_mean(g, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4be3dfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1, 3, 100])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6aa1e179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 100])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_bin_class.trainable_variables[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8360d4",
   "metadata": {},
   "source": [
    "Unbiased estimator of gradient based on batches given that $\\tau_i = id \\hspace{0.25 cm } \\forall i \\in \\{1,\\dots, d\\}$:\n",
    "$$ 2 * \\left[ \\frac{1}{B} \\sum_{j \\in J} \\text{diag}(\\phi(x_j)) \\frac{d}{d \\theta}f_{\\theta}(x_j) \\right ]^T W \\left [ \\frac{1}{B^{\\prime}} \\sum_{j^{\\prime} \\in J^{\\prime}} \\phi(x_{j^{\\prime}}) \\odot [f_{\\theta}(x_{j^{\\prime}}) - y_{j^{\\prime}}] \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "Dimensions of components:\n",
    "- $\\phi(x_j) \\in \\mathbb{R}^{d}$ and thus\n",
    "\n",
    "- $\\text{diag}(\\phi(x_j)) \\in \\mathbb{R}^{d \\times d}$\n",
    "\n",
    "- $\\Theta$ assumed to be $w$-dimensional paramter space and thus $\\frac{d}{d \\theta}f_{\\theta}(x_j) \\in \\mathbb{R}^{d \\times w}$\n",
    "\n",
    "Remark: $\\frac{d}{d \\theta}f_{\\theta}(x_j) \\in \\mathbb{R}^{d \\times w}$ is the Jacobian w.r.t. $\\theta$.\n",
    "It is assumed that the actual parameter tensor is flattened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "303e615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lusi_batch_loss(x, y, phi_x, B, model, model_jacobian, W):\n",
    "    \"\"\"Custom batch loss lusi.\n",
    "    Let tau = id. Implementation of formula above.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae467283",
   "metadata": {},
   "source": [
    "### Intermediate Goal: Implement this lusi batch loss for a simple model like a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fb5a8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_model(x, theta, b):\n",
    "    return tf.sigmoid(tf.add(tf.tensordot(x, theta, 1), b))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "128a8276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.99999964, 1.        ], dtype=float32)>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model(x_, theta_, b_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6ed2c5",
   "metadata": {},
   "source": [
    "Do this on MNIST as desired as final product of implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1da9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        # for each y_true, calc vector [tau_1(y_true), ..., tau_d(y_true)], same for y_pred\n",
    "        y_tau = [self.tau[i](y_true[j]) for j in range(y_true.shape[0])  for i in range(self.tau.shape[0])]        \n",
    "        y_true = tf.convert_to_tensor(y_tau, dtype=tf.float64)\n",
    "        y_true = tf.reshape(y_true, [y_dim, self.tau.shape[0]])\n",
    "\n",
    "        y_pred_tau = [self.tau[i](y_pred[j]) for j in range(y_pred.shape[0])  for i in range(self.tau.shape[0])]\n",
    "        y_pred = tf.convert_to_tensor(y_pred_tau, dtype=tf.float64)\n",
    "        y_pred = tf.reshape(y_pred,[y_dim, self.tau.shape[0]])\n",
    "        \n",
    "\n",
    "        \n",
    "        no_weight_loss = tf.reduce_mean(self.phi_x * (y_true - y_pred), axis=0)\n",
    "        # no_weight_loss should be tensor of dims (1, no_of_predicates)\n",
    "        no_weight_loss = tf.reshape(no_weight_loss, [self.tau.shape[0],1])\n",
    "\n",
    "        return dot(tf.transpose(no_weight_loss), no_weight_loss, self.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "335990c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [2., 2., 2.],\n",
       "       [3., 3., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = tf.constant([[1], [2], [3]], dtype=tf.float32)\n",
    "tt = tf.broadcast_to(tt, shape=[tt.shape[0],3])\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ff408fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tphi = tf.constant([[1,2,3],[1,2,3],[1,2,3]], dtype=tf.float32)\n",
    "tphi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "13a66348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [2., 4., 6.],\n",
       "       [3., 6., 9.]], dtype=float32)>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt * tphi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "efe22064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[2., 4., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tloss = tf.reduce_mean(tt * tphi, axis=0, keepdims=True)\n",
    "tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "245008a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_matrix = tf.constant(np.eye(3), dtype=tf.float32)\n",
    "w_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "350fd9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[56.]], dtype=float32)>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tensordot(tloss, w_matrix @ tf.transpose(tloss), axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "97a47ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def lusi_batch_loss_log_reg(x, y, phi_x, B, model, W):\n",
    "    \"\"\"Custom batch loss lusi.\n",
    "\n",
    "    Parameters:\n",
    "    \n",
    "    x :: tf.Tensor of dimensions (batch_size, 784)\n",
    "    y :: tf.Tensor of dimensions (batch_size, 1)\n",
    "    phi_x :: tf.Tensor of dimensions (batch_size, no_of_predicates)\n",
    "    B :: batch parameter 1\n",
    "    model :: logistic regression model accepting x as input, generating output of y-dim\n",
    "    W :: tf.Tensor of dimensions (no_of_predicates, no_of_predicates)\n",
    "    \"\"\"\n",
    "    \n",
    "    # First is implementation of loss\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    assert y_pred.shape[0] == y.shape[0], \"Check dims y and y_pred.\"\n",
    "    \n",
    "    assert phi_x.shape[0] == y.shape[0], \"Check dims y and phi_x.\"\n",
    "    \n",
    "    y_dim = y.shape[0]\n",
    "    \n",
    "    y_diff = y - y_pred\n",
    "    \n",
    "    y_diff = tf.broadcast_to(y_diff, shape=[y_diff.shape[0], phi_x.shape[1]])\n",
    "    \n",
    "    loss = phi_x * y_diff\n",
    "    \n",
    "    batch_loss = tf.reduce_mean(loss, axis=0, keepdims=True)\n",
    "    \n",
    "    \n",
    "    return tf.tensordot(batch_loss, W @ tf.transpose(batch_loss), axes=1) \n",
    "    \n",
    "    def grad(upstream):\n",
    "        return upstream\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d313ef",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "\n",
    "- Mache MNIST Daten fertig für Nutzung mit Logistic Regression model -> flatten, nur 2 Klassen aussuchen (7,8)\n",
    "- Teste Funktion auf kleinem Datensatz von 2 - 5 Daten mit 2 Prädiakten.\n",
    "- Implementiere gradient Funktion\n",
    "\n",
    "Frage: Ich teile dann den Batch auf, das macht ja nichts, oder? Nochmal nachdenken.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9fd5e8-e554-4a99-9934-a9ef4ac50eee",
   "metadata": {},
   "source": [
    "#### Findings:\n",
    "\n",
    "**I.** Why not use @tf.custom_gradient decorator and define gradient manually?\n",
    "\n",
    "The problem with this method is, that you have to manually pass the gradients of the modell predictions with repect to $\\theta$ and it is not immediately clear how to do this. Maybe the use of the upstream variable would solve it?\n",
    "\n",
    "\n",
    "One possible solution would be to write entire training loop from scratch as displayed in the following cell and modify it as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6a017-6ca3-4638-a442-73c85f65d42f",
   "metadata": {},
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    \n",
    "    Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):    \n",
    "        \n",
    "        ** \n",
    "        Split batch into batches J J' with batch sizes B B' summing to original batch size.\n",
    "        Calculate y_pred for J' batch not recording calculation on gradient tape.\n",
    "         \n",
    "        in code something like:\n",
    "        x_J = x_batch_train[:B]\n",
    "        x_J_prime = x_batch_train[B:]\n",
    "        y_J_true = y_batch_train[:B]\n",
    "        y_J_prime_true = y_batch_train[B:]\n",
    "        \n",
    "        y_J_prime_pred = model(x_J_prime)\n",
    "        **\n",
    "        \n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation.\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            \n",
    "            y_J_pred = model(x_J training=True)  # Logits for J batch recorded on gradient tape\n",
    "\n",
    "            **\n",
    "            Merge preds\n",
    "          \n",
    "            in code something like:\n",
    "            y_pred = tf.concat([y_J_pred, y_J_prime_pred], axis=0)  \n",
    "            **\n",
    "\n",
    "            Compute the loss value for this minibatch.\n",
    "            loss_value = loss_fn(y_batch_train, y_pred)\n",
    "\n",
    "        Use the gradient tape to automatically retrieve\n",
    "        the gradients of the trainable variables with respect to the loss.\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        Run one step of gradient descent by updating\n",
    "        the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea9589-ab06-4b4a-b190-a5248e3be776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b6043-c31c-4069-850b-6040482e54c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3adb597-5559-4b71-b31b-63e0d0a03429",
   "metadata": {},
   "source": [
    "### Test gradient behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b42ab87c-0bde-4ba6-87cf-431b5dc82da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = tf.Variable([[1,2,3], [5,6,7]], dtype=tf.float32)\n",
    "y_ = tf.Variable([[1], [0.5]], dtype=tf.float32)\n",
    "theta_ = tf.transpose(tf.Variable([[2,2,2]], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01961e7f-c3a5-4689-938c-d7f8574986cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84f81c5a-d1ff-4510-ad1f-132e7cff5ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[12.],\n",
       "       [36.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tensordot(x_, theta_, axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dea9f03e-aa50-48a2-b209-5c10606a6e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
       "array([[11.],\n",
       "       [34.]], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ = tf.Variable([[11],[34]], dtype=tf.float32)\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8147718-2917-4ad1-a502-35c2028c4498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[12.]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1 = tf.tensordot(x_[:1], theta_, axes=1)\n",
    "y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf55653d-7a2d-4a1f-93c3-2085dcf28ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[12.],\n",
       "       [36.]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1 = tf.tensordot(x_[:1], theta_, axes=1)\n",
    "y_2 = tf.tensordot(x_[1:2], theta_, axes=1)\n",
    "\n",
    "tf.concat([y_1, y_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2de13-0dd2-43df-abec-920e4b952598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c66db7c-2417-406f-bb0a-bcd8fe03aa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[20.]\n",
      " [24.]\n",
      " [28.]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# y_1 should not be accounted for in gradient calculation\n",
    "y_1 = tf.tensordot(x_[:1], theta_, axes=1)\n",
    "with tf.GradientTape() as g_tape:\n",
    "    g_tape.watch(theta_)\n",
    "    y_2 =  tf.tensordot(x_[1:2], theta_, axes=1)\n",
    "    loss = tf.reduce_sum(tf.square(tf.subtract(tf.concat([y_1, y_2], axis=0), y_)))\n",
    "    \n",
    "\n",
    "grads = g_tape.gradient(loss, theta_)\n",
    "print(grads)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c082c494-f3d2-4bf9-a7c6-be14c17d609f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22.]\n",
      " [28.]\n",
      " [34.]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# y_1 SHOULD be accounted for in gradient calculation\n",
    "with tf.GradientTape() as g_tape:\n",
    "    g_tape.watch(theta_)\n",
    "    y_1 = tf.tensordot(x_[:1], theta_, axes=1)\n",
    "    y_2 =  tf.tensordot(x_[1:2], theta_, axes=1)\n",
    "    loss = tf.reduce_sum(tf.square(tf.subtract(tf.concat([y_1, y_2], axis=0), y_)))\n",
    "    \n",
    "\n",
    "grads = g_tape.gradient(loss, theta_)\n",
    "print(grads)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a34164f-ab27-4ead-be98-a4d1f26ed3f8",
   "metadata": {},
   "source": [
    "Expected gradient behavior. If y_1 is not calculated inside gradient_tape block, it will not be accounted for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593405f4-fff4-42ea-b3aa-37378ad7b5eb",
   "metadata": {},
   "source": [
    "### First implementation of the training loop described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ed479-5fea-4839-9f35-858531a755fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ecae2d-b9cb-47bb-975f-718e6495d261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "6e4f1681-db0c-43c5-9aa4-115cd32e2495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network with one hidden layer and one output layer\n",
    "k_bin_class = keras.Sequential(\n",
    "    [   layers.Flatten(input_shape=(28,28)),\n",
    "        layers.Dense(100, activation=\"relu\", name=\"hidden_layer_01\"),\n",
    "#        layers.Dense(1, name=\"output_layer\", activation=\"sigmoid\") # interpret output as prob. for class 1\n",
    "        layers.Dense(1, name=\"output_layer\", activation=\"relu\") # interpret output as prob. for class 1\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "214ce7a4-1833-4071-9200-c5e14e626608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an optimizer.    \n",
    "optimizer = keras.optimizers.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "35eb3699-cb37-4824-a8a5-24db49a8f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training dataset.\n",
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "bb4cbfb5-55af-44f9-ad14-f6e48efb453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = np.reshape(x_train, (-1, 784))\n",
    "# x_test = np.reshape(x_test, (-1, 784))\n",
    "\n",
    "eights = x_train[y_train == 8]/255\n",
    "sevens = x_train[y_train == 7]/255\n",
    "\n",
    "y_eights = np.ones(eights.shape[0])\n",
    "y_sevens = np.zeros(sevens.shape[0])\n",
    "\n",
    "# calc phi_x here\n",
    "\n",
    "\n",
    "eights_flat = np.reshape(eights, (-1, 784))\n",
    "sevens_flat = np.reshape(sevens, (-1, 784))\n",
    "\n",
    "x_train_2d = np.concatenate([eights, sevens])\n",
    "x_train = np.concatenate([eights_flat, sevens_flat])\n",
    "y_train = np.concatenate([y_eights, y_sevens])\n",
    "\n",
    "# Reserve 10,000 samples for validation.\n",
    "# x_val = x_train[-10000:]\n",
    "# y_val = y_train[-10000:]\n",
    "# x_train = x_train[:-10000]\n",
    "# y_train = y_train[:-10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "e4e43888-143a-4e04-821d-7961338918db",
   "metadata": {},
   "outputs": [],
   "source": [
    "eights_test = x_test[y_test == 8]/255\n",
    "sevens_test = x_test[y_test == 7]/255\n",
    "\n",
    "y_eights_test = np.ones(eights_test.shape[0])\n",
    "y_sevens_test = np.zeros(sevens_test.shape[0])\n",
    "\n",
    "x_test_selected = np.concatenate([eights_test, sevens_test])\n",
    "y_test_selected = np.concatenate([y_eights_test, y_sevens_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "d5bf0054-e86d-4fb9-94c7-8c5000043c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5851, 28, 28)\n",
      "(5851, 784)\n",
      "(6265, 28, 28)\n",
      "(6265, 784)\n",
      "(12116, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(eights.shape)\n",
    "print(eights_flat.shape)\n",
    "print(sevens.shape)\n",
    "print(sevens_flat.shape)\n",
    "print(x_train_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "8a2a8e6a-7fad-4753-b993-23d5e3c15d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1028, 28, 28)\n",
      "(974, 28, 28)\n",
      "(2002, 28, 28)\n",
      "(2002,)\n"
     ]
    }
   ],
   "source": [
    "print(sevens_test.shape)\n",
    "print(eights_test.shape)\n",
    "print(x_test_selected.shape)\n",
    "print(y_test_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "235e113e-3b41-4d69-b07e-1588b087c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for application of predicates on data\n",
    "import lusi_Andreas_Loehr as lal\n",
    "preds = lal.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "aa8df410-72fc-4003-8fc4-b89ce8d4ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_eval = lal.apply_predicates_on_data(preds, x_train_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "711336db-4ec6-4840-b0e0-69204f6084dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(12116, 3)\n"
     ]
    }
   ],
   "source": [
    "print(type(pred_eval))\n",
    "print(pred_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "87d101ce-5f98-4e24-80d3-b1fcd6b570a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training dataset.\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((pred_eval, x_train, y_train))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((pred_eval, x_train_2d, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "# Prepare the training dataset.\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "# val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "8e1a943e-6576-4198-88b5-2bb4b670ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_eval_test = lal.apply_predicates_on_data(preds, x_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "094e6691-509b-4bd3-9925-4fa21caf14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((pred_eval_test, x_test_selected, y_test_selected))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "6ba2bb01-8c7c-47df-a77e-30e5589b7fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch dimensions for batch number 0: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Test batch dimensions for batch number 0: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Train batch dimensions for batch number 1: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Test batch dimensions for batch number 1: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for b, b_ in zip(train_dataset, test_dataset):\n",
    "    if i < 2:\n",
    "        print(f\"Train batch dimensions for batch number {i}: {b[0].shape, b[1].shape, b[2].shape}\")\n",
    "        print(f\"Test batch dimensions for batch number {i}: {b_[0].shape, b_[1].shape, b_[2].shape}\")\n",
    "        i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe6a7a-8d77-4292-9413-1828f0a76c26",
   "metadata": {},
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    \n",
    "    Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):    \n",
    "        \n",
    "        ** \n",
    "        Split batch into batches J J' with batch sizes B B' summing to original batch size.\n",
    "        Calculate y_pred for J' batch not recording calculation on gradient tape.\n",
    "         \n",
    "        in code something like:\n",
    "        x_J = x_batch_train[:B]\n",
    "        x_J_prime = x_batch_train[B:]\n",
    "        y_J_true = y_batch_train[:B]\n",
    "        y_J_prime_true = y_batch_train[B:]\n",
    "        \n",
    "        y_J_prime_pred = model(x_J_prime)\n",
    "        **\n",
    "        \n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation.\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            \n",
    "            y_J_pred = model(x_J training=True)  # Logits for J batch recorded on gradient tape\n",
    "\n",
    "            **\n",
    "            Merge preds\n",
    "          \n",
    "            in code something like:\n",
    "            y_pred = tf.concat([y_J_pred, y_J_prime_pred], axis=0)  \n",
    "            **\n",
    "\n",
    "            Compute the loss value for this minibatch.\n",
    "            loss_value = loss_fn(y_batch_train, y_pred)\n",
    "\n",
    "        Use the gradient tape to automatically retrieve\n",
    "        the gradients of the trainable variables with respect to the loss.\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        Run one step of gradient descent by updating\n",
    "        the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "da29f321-fa29-4743-b5d5-5a54b01c7c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "(64, 3) (64, 28, 28) (64,)\n",
      "(40, 28, 28) (24, 28, 28) (40,) (24,)\n",
      "(64, 3) (64, 28, 28) (64,)\n",
      "(40, 28, 28) (24, 28, 28) (40,) (24,)\n",
      "\n",
      "Start of epoch 1\n",
      "(64, 3) (64, 28, 28) (64,)\n",
      "(40, 28, 28) (24, 28, 28) (40,) (24,)\n",
      "(64, 3) (64, 28, 28) (64,)\n",
      "(40, 28, 28) (24, 28, 28) (40,) (24,)\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "B = 40\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (pred_batch, x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        x_J = x_batch_train[:B]\n",
    "        x_J_prime = x_batch_train[B:]\n",
    "        y_J_true = y_batch_train[:B]\n",
    "        y_J_prime_true = y_batch_train[B:]\n",
    "        \n",
    "        if step < 2:\n",
    "            print(pred_batch.shape, x_batch_train.shape, y_batch_train.shape)\n",
    "            print(x_J.shape, x_J_prime.shape, y_J_true.shape, y_J_prime_true.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac4422-a9bd-49fb-88aa-184d5364d445",
   "metadata": {},
   "source": [
    "This works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8e292487-5565-485e-b731-86229e6ff8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [3.],\n",
       "       [2.]], dtype=float32)>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = tf.Variable([[1],[3],[2]], dtype=tf.float32)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5e3b088f-6d5d-4621-bcea-698badebe924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [3., 3., 3.],\n",
       "       [2., 2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.broadcast_to(y_test, shape=[y_test.shape[0], 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e6f1c8bd-16e8-4931-8124-71973fbb9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = tf.cast(tf.linalg.diag(np.ones(3)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a114b079-2111-418d-930f-16cae2eef792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "975e26fa-33e6-4e18-aa9e-3a125a844570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: -1.1826\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 50: 0.3440\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 100: 0.1269\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 150: 0.0004\n",
      "Seen so far: 9664 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: -1.3440\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 50: 0.2060\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 100: 0.0458\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 150: 0.0077\n",
      "Seen so far: 9664 samples\n"
     ]
    }
   ],
   "source": [
    "trainable_weights_list = []\n",
    "grads_list = []\n",
    "\n",
    "epochs = 2\n",
    "B = 32\n",
    "\n",
    "# important: only for full batches\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (pred_batch, x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        x_J = x_batch_train[:B]\n",
    "        x_J_prime = x_batch_train[B:]\n",
    "        y_J_true = y_batch_train[:B]\n",
    "        y_J_prime_true = y_batch_train[B:]\n",
    "        \n",
    "        # Dirty solution -> one type for every tensor in advance\n",
    "        y_J_prime_true = tf.cast(y_J_prime_true, tf.float32)\n",
    "        y_J_prime_true = tf.expand_dims(y_J_prime_true, axis=1)\n",
    "        \n",
    "        \n",
    "        pred_J = pred_batch[:B]\n",
    "        pred_J_prime = pred_batch[B:]\n",
    "        \n",
    "        \n",
    "        \n",
    "        y_J_prime_pred = k_bin_class(x_J_prime)\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation.\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            \n",
    "            y_J_pred = k_bin_class(x_J, training=True)  # Logits for J batch recorded on gradient tape\n",
    "            # tape.watch(y_J_pred)\n",
    "            # y_J_test = k_bin_class(x_J, training=True)  # Logits for J batch recorded on gradient tape\n",
    "            \n",
    "            \n",
    "            # y_pred = tf.concat([y_J_pred, y_J_prime_pred], axis=0)  # not sure if needed\n",
    "            \n",
    "            y_J_pred = tf.broadcast_to(y_J_pred, shape=[y_J_pred.shape[0], pred_J.shape[1]])\n",
    "            \n",
    "            # Compute the loss value for this minibatch.\n",
    "            v = tf.reduce_mean(pred_J * y_J_pred, axis=0, keepdims=True)\n",
    "\n",
    "            v_prime_inter = tf.broadcast_to(y_J_prime_pred - y_J_prime_true, \n",
    "                                            shape=[y_J_prime_true.shape[0], pred_J_prime.shape[1]])\n",
    "\n",
    "            v_prime = tf.reduce_mean(pred_J_prime * v_prime_inter, axis=0, keepdims=True)\n",
    "            \n",
    "            \n",
    "            v_prime_times_weight_matrix = tf.matmul(weight_matrix, tf.transpose(v_prime))\n",
    "            \n",
    "            loss_value = tf.multiply(tf.Variable(2, dtype=tf.float32),\n",
    "                                     tf.tensordot(v, tf.matmul(weight_matrix, tf.transpose(v_prime)), axes=1))\n",
    "            \n",
    "            watched_vars = tape.watched_variables()\n",
    "        # Use the gradient tape to automatically retrieve\n",
    "        \n",
    "        # the gradients of the trainable variables with respect to the loss.\n",
    "        # grads = tape.gradient(y_J_test, k_bin_class.trainable_weights)\n",
    "        # grads_list.append(grads)\n",
    "\n",
    "        grads = tape.gradient(loss_value, k_bin_class.trainable_weights)\n",
    "        \n",
    "        grads_list.append(grads)\n",
    "        # Until here, seems to work fine.\n",
    "        \n",
    "        \n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        # print(k_bin_class.trainable_weights)\n",
    "        # print(grads)\n",
    "        \n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, k_bin_class.trainable_weights))\n",
    "        # print(k_bin_class.trainable_weights)\n",
    "        # raise Exception\n",
    "        trainable_weights_list.append(k_bin_class.trainable_weights)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 50 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "8005b14e-0f57-4ec0-932a-2c0812232efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(784, 100), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "  array([-0.1265485 ,  0.04624289, -0.02045986,  0.09868255, -0.00856819,\n",
       "         -0.5037414 , -0.03872331, -0.14567667, -0.04105351,  0.03231958,\n",
       "          0.        ,  0.07943166, -0.30713117,  0.066203  , -0.19996947,\n",
       "          0.01399532,  0.1252125 ,  0.04116756, -0.00198721, -0.03701806,\n",
       "         -0.00765781, -0.18240747,  0.01622752, -0.01010206, -0.0923773 ,\n",
       "          0.04285697, -0.02336374,  0.        , -0.1053443 ,  0.31035903,\n",
       "          0.081309  ,  0.07467842, -0.3009097 ,  0.13826475, -0.2635858 ,\n",
       "         -0.01081666, -0.17953385,  0.09940323,  0.11174734,  0.1288798 ,\n",
       "          0.        , -0.0965777 ,  0.0247663 ,  0.15709238,  0.03580011,\n",
       "         -0.10185191,  0.02446333,  0.035389  , -0.00946827, -0.14100763,\n",
       "          0.21090262,  0.03760305,  0.        , -0.02554984, -0.11953285,\n",
       "          0.20328586,  0.05385329,  0.12520947,  0.01850996, -0.2169759 ,\n",
       "          0.10190963,  0.19053984,  0.02414428,  0.00643626, -0.07947015,\n",
       "          0.11346914, -0.08528011,  0.11708546, -0.14023128,  0.04033821,\n",
       "          0.21227656,  0.02202662,  0.10068697, -0.03374351,  0.12689675,\n",
       "         -0.09852564, -0.00487456,  0.1927242 , -0.14289391, -0.07099399,\n",
       "          0.05238291,  0.06765067,  0.0619353 , -0.12194479,  0.1671354 ,\n",
       "          0.02550568,  0.03632853, -0.04670331, -0.18299054,  0.01435432,\n",
       "          0.00675181,  0.08586406,  0.03420746,  0.05728539, -0.1477893 ,\n",
       "          0.00743886,  0.01137595, -0.14916228, -0.19560942,  0.09920378],\n",
       "        dtype=float32)>,\n",
       "  <tf.Tensor: shape=(100, 1), dtype=float32, numpy=\n",
       "  array([[-1.30440056e+00],\n",
       "         [-1.30844247e-02],\n",
       "         [-8.31445754e-02],\n",
       "         [-1.31413117e-01],\n",
       "         [-4.76702768e-03],\n",
       "         [-2.94783068e+00],\n",
       "         [-5.17853312e-02],\n",
       "         [-5.30408680e-01],\n",
       "         [-8.70202929e-02],\n",
       "         [-9.83899683e-02],\n",
       "         [ 0.00000000e+00],\n",
       "         [-3.61357868e-01],\n",
       "         [-2.44208860e+00],\n",
       "         [-3.61170322e-02],\n",
       "         [-4.30416822e-01],\n",
       "         [-8.43650639e-01],\n",
       "         [-1.68717831e-01],\n",
       "         [-2.09739972e-02],\n",
       "         [-8.39458823e-01],\n",
       "         [-1.46164691e+00],\n",
       "         [-1.06465483e+00],\n",
       "         [-1.92522541e-01],\n",
       "         [-1.28107741e-01],\n",
       "         [-9.58123151e-03],\n",
       "         [-2.15123489e-01],\n",
       "         [-1.42497867e-01],\n",
       "         [-1.83275342e-01],\n",
       "         [ 0.00000000e+00],\n",
       "         [-2.02371389e-01],\n",
       "         [-2.13950932e-01],\n",
       "         [-1.57596886e-01],\n",
       "         [-7.98892379e-01],\n",
       "         [-6.99128449e-01],\n",
       "         [-1.21186674e-01],\n",
       "         [-1.61688733e+00],\n",
       "         [-9.91122499e-02],\n",
       "         [-8.24040115e-01],\n",
       "         [-3.29765864e-02],\n",
       "         [-4.94074598e-02],\n",
       "         [-9.65096876e-02],\n",
       "         [ 0.00000000e+00],\n",
       "         [-3.30747873e-01],\n",
       "         [-4.15232360e-01],\n",
       "         [-5.31893015e-01],\n",
       "         [-7.89925158e-02],\n",
       "         [-8.15979838e-02],\n",
       "         [-9.39774990e-01],\n",
       "         [-3.60285752e-02],\n",
       "         [-2.99107144e-03],\n",
       "         [-6.40739024e-01],\n",
       "         [-3.47121149e-01],\n",
       "         [-1.12062246e-02],\n",
       "         [ 0.00000000e+00],\n",
       "         [-3.71679664e-02],\n",
       "         [-1.46021262e-01],\n",
       "         [-2.71749020e-01],\n",
       "         [-2.69914400e-02],\n",
       "         [-1.80113629e-01],\n",
       "         [-6.43746495e-01],\n",
       "         [-8.02689910e-01],\n",
       "         [-3.67503703e-01],\n",
       "         [-8.10982883e-01],\n",
       "         [-3.29741053e-02],\n",
       "         [-2.32847214e-01],\n",
       "         [-6.81091994e-02],\n",
       "         [-6.67049527e-01],\n",
       "         [-5.78072131e-01],\n",
       "         [-4.56020117e-01],\n",
       "         [-1.54501110e-01],\n",
       "         [-1.19244434e-01],\n",
       "         [-1.55753791e-01],\n",
       "         [-2.67412495e-02],\n",
       "         [-9.79452133e-02],\n",
       "         [-3.28316167e-02],\n",
       "         [-3.95950414e-02],\n",
       "         [-2.39006266e-01],\n",
       "         [-5.74658453e-01],\n",
       "         [-5.61689079e-01],\n",
       "         [-1.40180543e-01],\n",
       "         [-1.56814992e+00],\n",
       "         [-1.18918009e-02],\n",
       "         [-3.75980809e-02],\n",
       "         [-4.87470850e-02],\n",
       "         [-7.74442255e-01],\n",
       "         [-1.84037387e-01],\n",
       "         [-1.77948922e-02],\n",
       "         [-9.89160389e-02],\n",
       "         [-2.87616681e-02],\n",
       "         [-8.02907884e-01],\n",
       "         [-3.37043375e-01],\n",
       "         [-1.14548981e-01],\n",
       "         [-8.47456008e-02],\n",
       "         [-1.77618891e-01],\n",
       "         [-4.59902100e-02],\n",
       "         [-6.70416832e-01],\n",
       "         [-1.70377307e-02],\n",
       "         [-1.15983491e-03],\n",
       "         [-1.38774264e+00],\n",
       "         [-5.18855393e-01],\n",
       "         [-3.45651239e-01]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-2.8343036], dtype=float32)>],\n",
       " [<tf.Tensor: shape=(784, 100), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "  array([-0.02743692,  0.00563585, -0.02248749,  0.00265353, -0.01562436,\n",
       "         -0.10769667, -0.00357095, -0.03444283, -0.00502902,  0.01890681,\n",
       "          0.        ,  0.01500893, -0.07117338,  0.01557957, -0.03840664,\n",
       "         -0.0009735 ,  0.00833507,  0.        , -0.00390247, -0.01308192,\n",
       "         -0.00487249, -0.04946215,  0.00396811,  0.        , -0.02027723,\n",
       "          0.00817648, -0.00503591,  0.        , -0.02411718,  0.00687091,\n",
       "          0.0063829 ,  0.00963469, -0.05609929,  0.00653789, -0.05862551,\n",
       "         -0.00438101, -0.03619548,  0.00724492,  0.00698055,  0.01265599,\n",
       "          0.        , -0.01940705,  0.00489346,  0.01317846,  0.00642813,\n",
       "         -0.01992385,  0.00185145,  0.01133686, -0.00102503, -0.02497273,\n",
       "          0.03045329,  0.00720356,  0.        , -0.01306584, -0.04102777,\n",
       "          0.01430437,  0.00495905,  0.01371891,  0.00068518, -0.04220656,\n",
       "          0.01176077,  0.03308577,  0.00507475,  0.00046945, -0.01833303,\n",
       "          0.01284667, -0.0207725 ,  0.01633107, -0.03116903,  0.00556072,\n",
       "          0.00679518,  0.00424119,  0.0160639 , -0.00572395,  0.02176408,\n",
       "         -0.01430519, -0.00298912,  0.01919462, -0.03725789, -0.02104432,\n",
       "          0.007798  ,  0.01561172,  0.01161017, -0.02548211,  0.01551558,\n",
       "          0.00477139,  0.01196945, -0.00274284, -0.04561697,  0.00129273,\n",
       "          0.00069468,  0.01447465,  0.00233013,  0.01994316, -0.02988411,\n",
       "          0.        ,  0.        , -0.03681894, -0.04348361,  0.01262339],\n",
       "        dtype=float32)>,\n",
       "  <tf.Tensor: shape=(100, 1), dtype=float32, numpy=\n",
       "  array([[-3.06147993e-01],\n",
       "         [-2.27398681e-03],\n",
       "         [-2.15084516e-02],\n",
       "         [-1.17550557e-03],\n",
       "         [-1.01710986e-02],\n",
       "         [-7.37945437e-01],\n",
       "         [-1.46728475e-02],\n",
       "         [-1.85527951e-01],\n",
       "         [-1.41759904e-03],\n",
       "         [-2.02182010e-02],\n",
       "         [ 0.00000000e+00],\n",
       "         [-6.54940084e-02],\n",
       "         [-5.58154404e-01],\n",
       "         [-1.66613106e-02],\n",
       "         [-1.03129104e-01],\n",
       "         [-1.46694675e-01],\n",
       "         [-2.01573363e-03],\n",
       "         [ 0.00000000e+00],\n",
       "         [-1.34524196e-01],\n",
       "         [-2.23558336e-01],\n",
       "         [-2.04552382e-01],\n",
       "         [-1.18934587e-01],\n",
       "         [-2.37689484e-02],\n",
       "         [ 0.00000000e+00],\n",
       "         [-6.13358058e-02],\n",
       "         [-3.30768190e-02],\n",
       "         [-4.82171178e-02],\n",
       "         [ 0.00000000e+00],\n",
       "         [-7.20521510e-02],\n",
       "         [-7.51072634e-03],\n",
       "         [-9.17432364e-03],\n",
       "         [-1.26159877e-01],\n",
       "         [-2.27162912e-01],\n",
       "         [-1.90676132e-03],\n",
       "         [-3.80740881e-01],\n",
       "         [-4.20048237e-02],\n",
       "         [-1.74057692e-01],\n",
       "         [-4.18485934e-03],\n",
       "         [-1.05608068e-03],\n",
       "         [-1.34154763e-02],\n",
       "         [ 0.00000000e+00],\n",
       "         [-2.05964036e-02],\n",
       "         [-1.12409458e-01],\n",
       "         [-3.10073327e-02],\n",
       "         [-2.69666687e-02],\n",
       "         [-2.10025720e-02],\n",
       "         [-2.22182199e-01],\n",
       "         [-1.40330503e-02],\n",
       "         [-1.43231323e-03],\n",
       "         [-1.43203184e-01],\n",
       "         [-1.91315953e-02],\n",
       "         [-3.80840153e-04],\n",
       "         [ 0.00000000e+00],\n",
       "         [-5.76496078e-03],\n",
       "         [-5.57160415e-02],\n",
       "         [-1.42883183e-02],\n",
       "         [-5.49721625e-03],\n",
       "         [-2.83294581e-02],\n",
       "         [-8.18922594e-02],\n",
       "         [-1.90267190e-01],\n",
       "         [-2.47293841e-02],\n",
       "         [-1.59165695e-01],\n",
       "         [-4.91257804e-03],\n",
       "         [-4.13268209e-02],\n",
       "         [-1.27214119e-02],\n",
       "         [-9.13681462e-02],\n",
       "         [-1.21956177e-01],\n",
       "         [-6.48269951e-02],\n",
       "         [-4.24008183e-02],\n",
       "         [-1.16224810e-02],\n",
       "         [-4.57188766e-03],\n",
       "         [-6.09274162e-03],\n",
       "         [-2.56297495e-02],\n",
       "         [-1.88934302e-03],\n",
       "         [-2.01956462e-02],\n",
       "         [-3.28967795e-02],\n",
       "         [-9.50203985e-02],\n",
       "         [-2.74983756e-02],\n",
       "         [-3.62755992e-02],\n",
       "         [-3.03862393e-01],\n",
       "         [-1.16488524e-03],\n",
       "         [-1.62232425e-02],\n",
       "         [-7.30319880e-03],\n",
       "         [-1.68308824e-01],\n",
       "         [-1.44528560e-02],\n",
       "         [-5.54686598e-03],\n",
       "         [-2.16243006e-02],\n",
       "         [-4.45122278e-04],\n",
       "         [-1.93599835e-01],\n",
       "         [-2.33433358e-02],\n",
       "         [-1.62670426e-02],\n",
       "         [-1.79136917e-02],\n",
       "         [-1.32622765e-02],\n",
       "         [-6.06898684e-03],\n",
       "         [-1.26785710e-01],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [-3.39902580e-01],\n",
       "         [-1.27531677e-01],\n",
       "         [-6.37729764e-02]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.5197502], dtype=float32)>]]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "31a0ce17-1c68-48ab-b648-3a6668c02031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'hidden_layer_01/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       " array([[ 0.01073142, -0.06118976,  0.06179187, ...,  0.08095287,\n",
       "         -0.02647142, -0.04624945],\n",
       "        [ 0.02629852, -0.03350095, -0.03168495, ..., -0.04187032,\n",
       "         -0.04313279, -0.02131545],\n",
       "        [ 0.04443857,  0.07623483,  0.04600461, ...,  0.04216161,\n",
       "          0.02683131,  0.01071049],\n",
       "        ...,\n",
       "        [ 0.0257911 ,  0.03355408,  0.06353562, ..., -0.00682994,\n",
       "          0.04125407, -0.06643349],\n",
       "        [-0.06869259, -0.03053903,  0.02378943, ..., -0.04671562,\n",
       "          0.04001233,  0.02089246],\n",
       "        [-0.03512982,  0.03589466,  0.05481695, ...,  0.02176029,\n",
       "          0.02164723, -0.0812026 ]], dtype=float32)>,\n",
       " <tf.Variable 'hidden_layer_01/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([-3.1395685e-03, -3.1661750e-03, -4.4490239e-03, -1.7456340e-03,\n",
       "        -4.8857853e-03, -8.6470712e-03, -2.3194901e-03, -3.9822715e-03,\n",
       "        -3.5901198e-03,  1.2590647e-03, -2.0797276e-04, -2.6732690e-03,\n",
       "        -7.1191494e-03, -5.3152558e-03, -2.2925895e-03, -1.6329818e-03,\n",
       "        -1.8772226e-03, -2.3049649e-03, -1.8228618e-03, -3.6837501e-03,\n",
       "        -2.6425666e-03, -8.0621922e-03, -2.5044306e-04, -5.0758133e-03,\n",
       "        -6.5750821e-04, -2.6616633e-03,  5.7456797e-05, -1.7859106e-04,\n",
       "        -3.4894336e-03,  3.0672443e-03,  1.2293900e-03, -1.2414329e-03,\n",
       "        -4.4203592e-03, -1.7355937e-04, -6.1619859e-03, -2.0594393e-04,\n",
       "        -2.6484956e-03,  8.4639317e-04, -5.1257573e-03,  4.4410960e-03,\n",
       "        -9.7905882e-05, -3.9601033e-03, -8.3550776e-04, -3.3182523e-03,\n",
       "        -4.9569155e-04, -8.2056560e-03, -1.2764760e-03, -9.2070171e-04,\n",
       "        -1.1840735e-03, -2.1200955e-03,  2.0764298e-04, -4.9399883e-03,\n",
       "         3.5866784e-04, -5.2547329e-03, -7.0562665e-03,  4.1226968e-03,\n",
       "        -1.0127913e-02,  1.6346000e-03, -9.1809809e-04, -6.4849136e-03,\n",
       "        -2.7583765e-03, -5.2986229e-03, -3.1465872e-03, -2.4762243e-04,\n",
       "        -6.2814662e-03,  1.5960262e-03, -3.4202423e-03, -3.9945054e-04,\n",
       "        -1.0685495e-02, -1.8488645e-04, -1.0424871e-03, -1.3749606e-03,\n",
       "        -5.7554934e-03, -1.2312727e-03, -3.0921339e-03, -5.1116929e-03,\n",
       "        -5.6210672e-04, -2.8513505e-03, -2.6969982e-03, -3.9837961e-03,\n",
       "        -6.9847973e-03,  2.9908959e-04, -4.0484574e-03, -3.4009896e-03,\n",
       "        -8.3063170e-03,  9.8408130e-04, -1.4242589e-03, -1.1408057e-03,\n",
       "        -6.5480573e-03, -5.7247504e-05, -3.6119770e-06,  1.3715656e-03,\n",
       "        -5.7542318e-04, -5.5777666e-04, -5.0163907e-03,  9.6588361e-04,\n",
       "         5.6745490e-04, -3.8618441e-03, -9.6334815e-03, -2.0207847e-03],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'output_layer/kernel:0' shape=(100, 1) dtype=float32, numpy=\n",
       " array([[ 0.03000795],\n",
       "        [-0.18806195],\n",
       "        [ 0.14978032],\n",
       "        [-0.21252368],\n",
       "        [ 0.1936549 ],\n",
       "        [ 0.16919012],\n",
       "        [ 0.11744425],\n",
       "        [ 0.07306249],\n",
       "        [ 0.08277166],\n",
       "        [-0.11114022],\n",
       "        [ 0.0712025 ],\n",
       "        [-0.07909267],\n",
       "        [ 0.10356963],\n",
       "        [-0.16999598],\n",
       "        [ 0.13529132],\n",
       "        [-0.01475358],\n",
       "        [-0.19736399],\n",
       "        [-0.20548217],\n",
       "        [-0.00210193],\n",
       "        [ 0.00512396],\n",
       "        [ 0.00207312],\n",
       "        [ 0.15455225],\n",
       "        [-0.04069237],\n",
       "        [ 0.1506245 ],\n",
       "        [ 0.10562829],\n",
       "        [-0.06720748],\n",
       "        [ 0.02209514],\n",
       "        [ 0.05526323],\n",
       "        [ 0.093647  ],\n",
       "        [-0.20199841],\n",
       "        [-0.09823975],\n",
       "        [-0.05125009],\n",
       "        [ 0.12976968],\n",
       "        [-0.18751767],\n",
       "        [ 0.09704704],\n",
       "        [ 0.02104805],\n",
       "        [ 0.07038634],\n",
       "        [-0.2231935 ],\n",
       "        [-0.21628703],\n",
       "        [-0.17448367],\n",
       "        [ 0.0254561 ],\n",
       "        [ 0.14175649],\n",
       "        [-0.0141574 ],\n",
       "        [-0.09357291],\n",
       "        [-0.05387324],\n",
       "        [ 0.1920926 ],\n",
       "        [-0.03287734],\n",
       "        [-0.11912458],\n",
       "        [ 0.07730178],\n",
       "        [ 0.06873257],\n",
       "        [-0.14697814],\n",
       "        [-0.20988594],\n",
       "        [-0.10793375],\n",
       "        [ 0.20129319],\n",
       "        [ 0.17673372],\n",
       "        [-0.17154615],\n",
       "        [-0.18298453],\n",
       "        [-0.1148046 ],\n",
       "        [-0.01424207],\n",
       "        [ 0.12040418],\n",
       "        [-0.09778965],\n",
       "        [-0.1333383 ],\n",
       "        [-0.12837972],\n",
       "        [-0.00844245],\n",
       "        [ 0.19975258],\n",
       "        [-0.06588092],\n",
       "        [ 0.06382819],\n",
       "        [-0.07437959],\n",
       "        [ 0.20081271],\n",
       "        [-0.05970161],\n",
       "        [-0.24189179],\n",
       "        [-0.09983107],\n",
       "        [-0.13612819],\n",
       "        [ 0.16393809],\n",
       "        [-0.22948699],\n",
       "        [ 0.10176939],\n",
       "        [ 0.00065664],\n",
       "        [-0.11064281],\n",
       "        [ 0.19912149],\n",
       "        [ 0.01325064],\n",
       "        [-0.21520239],\n",
       "        [-0.23092824],\n",
       "        [-0.23651013],\n",
       "        [ 0.0511586 ],\n",
       "        [-0.17477089],\n",
       "        [-0.11479043],\n",
       "        [-0.07011364],\n",
       "        [ 0.2317241 ],\n",
       "        [ 0.1117963 ],\n",
       "        [-0.01180794],\n",
       "        [-0.01232152],\n",
       "        [-0.17030416],\n",
       "        [-0.04951891],\n",
       "        [-0.17577559],\n",
       "        [ 0.09228241],\n",
       "        [-0.10834356],\n",
       "        [-0.23409532],\n",
       "        [ 0.04821341],\n",
       "        [ 0.13562326],\n",
       "        [-0.06611744]], dtype=float32)>,\n",
       " <tf.Variable 'output_layer/bias:0' shape=(1,) dtype=float32, numpy=array([-0.01648698], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watched_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "9cab552a-4451-4251-b98f-2b73a823a549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden_layer_01/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       " array([[ 0.01073142, -0.06118976,  0.06179187, ...,  0.08095287,\n",
       "         -0.02647142, -0.04624945],\n",
       "        [ 0.02629852, -0.03350095, -0.03168495, ..., -0.04187032,\n",
       "         -0.04313279, -0.02131545],\n",
       "        [ 0.04443857,  0.07623483,  0.04600461, ...,  0.04216161,\n",
       "          0.02683131,  0.01071049],\n",
       "        ...,\n",
       "        [ 0.0257911 ,  0.03355408,  0.06353562, ..., -0.00682994,\n",
       "          0.04125407, -0.06643349],\n",
       "        [-0.06869259, -0.03053903,  0.02378943, ..., -0.04671562,\n",
       "          0.04001233,  0.02089246],\n",
       "        [-0.03512982,  0.03589466,  0.05481695, ...,  0.02176029,\n",
       "          0.02164723, -0.0812026 ]], dtype=float32)>,\n",
       " <tf.Variable 'hidden_layer_01/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([-3.69183789e-03, -4.73327050e-03, -5.12447814e-03, -1.94649375e-03,\n",
       "        -7.34464359e-03, -7.43289245e-03, -3.37059842e-03, -2.41232035e-03,\n",
       "        -6.38941070e-03,  6.09570590e-04, -3.71587754e-04, -5.83047001e-03,\n",
       "        -7.19741778e-03, -2.66133389e-03,  2.67442738e-05, -2.85249273e-03,\n",
       "        -3.09268571e-03, -3.30881798e-03, -2.68770894e-03, -5.27571701e-03,\n",
       "        -3.66186351e-03, -8.19811318e-03, -1.58140378e-04, -6.83338894e-03,\n",
       "        -1.80672831e-03, -3.45363864e-03,  1.49113170e-04, -1.31613851e-04,\n",
       "        -3.40752373e-03,  7.86297582e-03,  1.94998994e-03, -3.43300728e-03,\n",
       "        -3.21760285e-03,  3.90871288e-03, -6.06027478e-03, -3.25555971e-04,\n",
       "        -2.77125952e-03, -1.55885599e-03, -5.45640476e-03,  6.28271839e-03,\n",
       "        -3.21943982e-04, -5.05071413e-03, -1.51237671e-03, -3.21378768e-03,\n",
       "        -1.30008021e-03, -1.23595968e-02, -2.95882719e-03, -3.01672448e-03,\n",
       "        -3.04290839e-03, -1.94047100e-03,  2.47962261e-03, -5.84423123e-03,\n",
       "        -8.27765674e-04, -6.71135820e-03, -6.77471934e-03,  6.61649508e-03,\n",
       "        -1.05742207e-02,  1.46047445e-03, -1.69190287e-03, -7.10019190e-03,\n",
       "        -2.60873721e-03, -1.09946197e-02, -3.35691334e-03, -4.51363245e-04,\n",
       "        -6.13262597e-03,  1.77751912e-03, -4.02563484e-03, -3.04414844e-03,\n",
       "        -9.24150646e-03,  1.16661994e-03,  2.93786218e-03, -2.02463614e-03,\n",
       "        -5.34480019e-03, -1.46871503e-03, -2.90496554e-03, -6.26051007e-03,\n",
       "        -8.43184534e-04, -1.37334131e-03, -2.75111222e-03, -5.34425350e-03,\n",
       "        -9.71119199e-03, -4.18227678e-03, -2.41792435e-03, -3.40858824e-03,\n",
       "        -7.37224473e-03,  2.34071491e-03, -4.11501853e-03, -1.24353531e-03,\n",
       "        -9.28051956e-03, -1.06350104e-04, -2.64089700e-04,  3.04283312e-04,\n",
       "        -2.71869158e-06, -3.15999030e-03, -6.48039626e-03,  3.34707298e-03,\n",
       "         8.36540654e-04, -3.99766490e-03, -1.08463271e-02, -4.88361437e-03],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'output_layer/kernel:0' shape=(100, 1) dtype=float32, numpy=\n",
       " array([[ 0.05379987],\n",
       "        [-0.1868296 ],\n",
       "        [ 0.14677593],\n",
       "        [-0.21197572],\n",
       "        [ 0.19212615],\n",
       "        [ 0.18701169],\n",
       "        [ 0.11661611],\n",
       "        [ 0.07649484],\n",
       "        [ 0.07686131],\n",
       "        [-0.11077659],\n",
       "        [ 0.07110894],\n",
       "        [-0.06747589],\n",
       "        [ 0.10851563],\n",
       "        [-0.17810513],\n",
       "        [ 0.14395271],\n",
       "        [-0.00299228],\n",
       "        [-0.19820422],\n",
       "        [-0.20454234],\n",
       "        [ 0.0039032 ],\n",
       "        [ 0.02088192],\n",
       "        [ 0.01004331],\n",
       "        [ 0.15092109],\n",
       "        [-0.04556822],\n",
       "        [ 0.14930943],\n",
       "        [ 0.10341043],\n",
       "        [-0.0642743 ],\n",
       "        [ 0.02481456],\n",
       "        [ 0.05528998],\n",
       "        [ 0.09579877],\n",
       "        [-0.22371688],\n",
       "        [-0.10224955],\n",
       "        [-0.03230101],\n",
       "        [ 0.12096933],\n",
       "        [-0.192881  ],\n",
       "        [ 0.10062237],\n",
       "        [ 0.02284224],\n",
       "        [ 0.07734836],\n",
       "        [-0.22300184],\n",
       "        [-0.21724752],\n",
       "        [-0.18557903],\n",
       "        [ 0.02399018],\n",
       "        [ 0.14064756],\n",
       "        [-0.01857425],\n",
       "        [-0.10112447],\n",
       "        [-0.05048408],\n",
       "        [ 0.18397093],\n",
       "        [-0.00307224],\n",
       "        [-0.11550237],\n",
       "        [ 0.07225892],\n",
       "        [ 0.06633645],\n",
       "        [-0.16502282],\n",
       "        [-0.20982169],\n",
       "        [-0.10623547],\n",
       "        [ 0.20048304],\n",
       "        [ 0.17688815],\n",
       "        [-0.18252708],\n",
       "        [-0.1834205 ],\n",
       "        [-0.11509879],\n",
       "        [-0.00940203],\n",
       "        [ 0.09031983],\n",
       "        [-0.09794752],\n",
       "        [-0.0949076 ],\n",
       "        [-0.12702703],\n",
       "        [-0.00633255],\n",
       "        [ 0.20129533],\n",
       "        [-0.06477455],\n",
       "        [ 0.06787047],\n",
       "        [-0.06272853],\n",
       "        [ 0.19961284],\n",
       "        [-0.06580605],\n",
       "        [-0.24609792],\n",
       "        [-0.09973069],\n",
       "        [-0.13679308],\n",
       "        [ 0.1639466 ],\n",
       "        [-0.23046757],\n",
       "        [ 0.09690782],\n",
       "        [ 0.00767834],\n",
       "        [-0.11851688],\n",
       "        [ 0.20093831],\n",
       "        [ 0.03192448],\n",
       "        [-0.21389958],\n",
       "        [-0.22771949],\n",
       "        [-0.23709397],\n",
       "        [ 0.04402466],\n",
       "        [-0.1802433 ],\n",
       "        [-0.11678164],\n",
       "        [-0.0632192 ],\n",
       "        [ 0.23234479],\n",
       "        [ 0.10709642],\n",
       "        [-0.01494982],\n",
       "        [-0.00901287],\n",
       "        [-0.17096192],\n",
       "        [-0.05069222],\n",
       "        [-0.17378171],\n",
       "        [ 0.0715398 ],\n",
       "        [-0.11195408],\n",
       "        [-0.23497556],\n",
       "        [ 0.0667716 ],\n",
       "        [ 0.12359367],\n",
       "        [-0.0534934 ]], dtype=float32)>,\n",
       " <tf.Variable 'output_layer/bias:0' shape=(1,) dtype=float32, numpy=array([0.01457183], dtype=float32)>]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_bin_class.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "c4d813bb-b5c5-4a1b-a141-c7cf972013e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'hidden_layer_01/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       "array([[ 0.0636145 , -0.0076432 , -0.00561202, ...,  0.03012008,\n",
       "         0.01259983, -0.02248793],\n",
       "       [-0.07323446, -0.0143358 , -0.0768824 , ..., -0.04073061,\n",
       "        -0.01604898,  0.02849007],\n",
       "       [-0.02575516,  0.04928607,  0.0580136 , ...,  0.04621132,\n",
       "         0.05542828, -0.01495838],\n",
       "       ...,\n",
       "       [ 0.03037722,  0.02300749, -0.04763236, ..., -0.00194457,\n",
       "        -0.04645958,  0.03088919],\n",
       "       [-0.06072239, -0.01714939,  0.03747405, ..., -0.02863833,\n",
       "         0.05618244,  0.01271334],\n",
       "       [ 0.02142437, -0.01126021,  0.00824724, ...,  0.05121529,\n",
       "         0.079267  , -0.07179282]], dtype=float32)>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_weights_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "5d0c2a45-a816-47bf-a815-581e2dae5d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainable_weights_list[200][3] == trainable_weights_list[0][3]).numpy().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "2407bded-4a9c-4959-b456-15d3716086fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden_layer_01/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       " array([[-0.03297234,  0.06398897,  0.06231843, ...,  0.01900039,\n",
       "         -0.01990391,  0.06412043],\n",
       "        [-0.03843292,  0.04306623, -0.03138997, ..., -0.04816258,\n",
       "          0.04108296,  0.01508191],\n",
       "        [ 0.04524964,  0.0156443 , -0.03722803, ..., -0.0538349 ,\n",
       "          0.07933705, -0.00457983],\n",
       "        ...,\n",
       "        [ 0.00535303,  0.03425984,  0.01024895, ...,  0.0437479 ,\n",
       "         -0.07003608,  0.06067763],\n",
       "        [-0.04419505, -0.02390099, -0.00946222, ..., -0.00399697,\n",
       "         -0.02851115,  0.04664697],\n",
       "        [ 0.06966358,  0.03562521, -0.02139363, ..., -0.05863429,\n",
       "          0.06986205, -0.06611254]], dtype=float32)>,\n",
       " <tf.Variable 'hidden_layer_01/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([ 4.12886217e-03, -6.28611259e-03, -1.01801277e-04, -4.87495199e-05,\n",
       "         1.19360360e-04,  5.40785841e-04, -2.50541046e-03,  3.98033269e-04,\n",
       "         1.54720135e-02,  1.43523570e-02,  9.14110395e-04,  7.51471892e-03,\n",
       "         9.76460797e-05, -1.78030794e-04, -1.41671707e-03, -8.37168470e-03,\n",
       "         1.82642732e-02, -8.45268602e-04, -2.44900002e-03, -5.40999603e-03,\n",
       "        -2.76967208e-03, -3.28777765e-04,  2.86983093e-03,  2.35752435e-03,\n",
       "         1.19311584e-03, -8.90103518e-04,  1.12759210e-02,  1.42585125e-03,\n",
       "         5.43138152e-03, -1.88093609e-03, -4.74789971e-03, -8.88704509e-03,\n",
       "         2.00936873e-03,  2.26732274e-03, -9.03285109e-04, -1.44253182e-03,\n",
       "         7.10244349e-04,  8.04610364e-03,  1.00544235e-02, -2.62835622e-03,\n",
       "         4.42231260e-03, -5.79605391e-03, -4.26718639e-03,  6.22501271e-03,\n",
       "        -2.74204719e-03,  1.55764911e-02,  3.58626130e-04, -2.55869073e-03,\n",
       "        -4.09105746e-03, -6.91619935e-03, -2.41183816e-03, -9.49878991e-03,\n",
       "         3.26715177e-03,  1.90478563e-03, -2.79468787e-03,  5.99661749e-03,\n",
       "        -3.62045568e-04,  8.19842273e-04,  2.06516050e-02, -1.21885492e-03,\n",
       "         1.52567591e-05, -1.69034465e-03,  2.11603171e-03, -1.14734937e-03,\n",
       "         6.58285499e-05,  6.99169049e-03,  2.02057641e-02,  4.50202460e-05,\n",
       "        -2.40253401e-03, -8.85264669e-03,  6.85496908e-03,  1.35999192e-02,\n",
       "         4.56472248e-04,  1.47208106e-02, -5.47461445e-03,  5.21269176e-05,\n",
       "        -4.52995300e-03, -8.70715070e-04,  2.10553495e-04, -2.22306815e-03,\n",
       "         1.25579778e-02, -4.65824688e-03,  2.70255674e-02, -3.39315477e-04,\n",
       "        -9.84051148e-04,  1.09144757e-02,  6.56316464e-04, -4.06489056e-03,\n",
       "         1.87662209e-03, -9.83723626e-03,  1.81935132e-02,  3.95819033e-03,\n",
       "        -7.38748861e-03,  1.46676367e-02,  1.56959444e-02, -5.72425139e-04,\n",
       "        -7.93539546e-03, -5.06150973e-05,  1.84466727e-02,  6.55071996e-03],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'output_layer/kernel:0' shape=(100, 1) dtype=float32, numpy=\n",
       " array([[ 0.2260527 ],\n",
       "        [-0.17423265],\n",
       "        [ 0.01940686],\n",
       "        [ 0.17943978],\n",
       "        [ 0.0378119 ],\n",
       "        [ 0.17666896],\n",
       "        [ 0.11929838],\n",
       "        [ 0.07703614],\n",
       "        [-0.2685333 ],\n",
       "        [-0.22695495],\n",
       "        [-0.11552842],\n",
       "        [-0.24680237],\n",
       "        [-0.00877237],\n",
       "        [ 0.2494858 ],\n",
       "        [ 0.05326592],\n",
       "        [ 0.17961441],\n",
       "        [-0.2096273 ],\n",
       "        [ 0.18437968],\n",
       "        [ 0.24314521],\n",
       "        [ 0.19856383],\n",
       "        [ 0.08353461],\n",
       "        [-0.13191068],\n",
       "        [-0.1187553 ],\n",
       "        [ 0.2159526 ],\n",
       "        [ 0.16257824],\n",
       "        [ 0.13645265],\n",
       "        [-0.19963834],\n",
       "        [-0.09263291],\n",
       "        [-0.0940347 ],\n",
       "        [ 0.16715479],\n",
       "        [ 0.25088605],\n",
       "        [ 0.24118026],\n",
       "        [ 0.11474485],\n",
       "        [-0.20839259],\n",
       "        [ 0.06184133],\n",
       "        [-0.18205531],\n",
       "        [ 0.06133762],\n",
       "        [-0.20914686],\n",
       "        [-0.17810543],\n",
       "        [ 0.16727693],\n",
       "        [ 0.25407195],\n",
       "        [ 0.09082853],\n",
       "        [ 0.1352701 ],\n",
       "        [-0.10722538],\n",
       "        [ 0.22076309],\n",
       "        [-0.2303489 ],\n",
       "        [ 0.19255488],\n",
       "        [ 0.02870506],\n",
       "        [ 0.13616498],\n",
       "        [ 0.12541217],\n",
       "        [ 0.198116  ],\n",
       "        [ 0.11134282],\n",
       "        [-0.16583624],\n",
       "        [-0.03493395],\n",
       "        [ 0.03752352],\n",
       "        [ 0.22282574],\n",
       "        [ 0.19435456],\n",
       "        [ 0.12848237],\n",
       "        [-0.28872138],\n",
       "        [ 0.13234328],\n",
       "        [ 0.26740623],\n",
       "        [ 0.03891222],\n",
       "        [-0.09108957],\n",
       "        [ 0.03720751],\n",
       "        [-0.08925751],\n",
       "        [-0.14054242],\n",
       "        [-0.22387213],\n",
       "        [ 0.01943064],\n",
       "        [ 0.00372579],\n",
       "        [ 0.06541821],\n",
       "        [-0.1237882 ],\n",
       "        [-0.20393972],\n",
       "        [-0.03020026],\n",
       "        [-0.22870569],\n",
       "        [ 0.18007219],\n",
       "        [-0.00849218],\n",
       "        [ 0.13974537],\n",
       "        [ 0.06548549],\n",
       "        [-0.01980455],\n",
       "        [ 0.21958531],\n",
       "        [-0.2184192 ],\n",
       "        [ 0.15189977],\n",
       "        [-0.31582546],\n",
       "        [ 0.02141678],\n",
       "        [ 0.16864038],\n",
       "        [-0.17383039],\n",
       "        [ 0.16562848],\n",
       "        [ 0.05821539],\n",
       "        [ 0.2711913 ],\n",
       "        [ 0.09667346],\n",
       "        [-0.28929684],\n",
       "        [ 0.10645938],\n",
       "        [-0.13582413],\n",
       "        [-0.20236468],\n",
       "        [-0.19858699],\n",
       "        [ 0.23353787],\n",
       "        [ 0.13515313],\n",
       "        [-0.00112332],\n",
       "        [-0.2500383 ],\n",
       "        [ 0.1904106 ]], dtype=float32)>,\n",
       " <tf.Variable 'output_layer/bias:0' shape=(1,) dtype=float32, numpy=array([-0.06949243], dtype=float32)>]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_weights_list[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9821d5d4-bf36-42b8-8d80-b32d88c79694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[nan]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "644accd3-8b5a-4f7d-8b05-58c551bbed1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(784, 100), dtype=float32, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       " array([-0.02054243,  0.05793682,  0.07653738,  0.00570444, -0.07568566,\n",
       "        -0.00932901, -0.03408472, -0.01560976,  0.05559244,  0.01364557,\n",
       "        -0.02676675,  0.06552649, -0.00215461, -0.03146821,  0.00212018,\n",
       "         0.0091311 , -0.05213089, -0.01451191,  0.08497681, -0.08352898,\n",
       "        -0.0111833 ,  0.08036668,  0.00256528,  0.        , -0.02500333,\n",
       "        -0.00424051,  0.01141829,  0.03628527,  0.0168561 ,  0.01697373,\n",
       "        -0.0032806 , -0.00033963,  0.01660213, -0.01578393, -0.01887781,\n",
       "        -0.00047858, -0.00948823, -0.0029682 ,  0.00135482, -0.07928964,\n",
       "         0.01035485,  0.06157262,  0.00238648,  0.00485795,  0.        ,\n",
       "         0.0285595 , -0.03653642, -0.01322417,  0.01470489,  0.06697732,\n",
       "         0.        ,  0.05688934, -0.01290106, -0.01351899,  0.00339727,\n",
       "        -0.0522668 ,  0.02743933, -0.02940879,  0.0043973 , -0.00707496,\n",
       "        -0.0091045 ,  0.02458283, -0.01638258,  0.03216598, -0.04879198,\n",
       "         0.02050773,  0.04459535,  0.03006398, -0.05033101, -0.01174076,\n",
       "        -0.02287684, -0.00055812, -0.06275157,  0.07409058, -0.00733222,\n",
       "         0.08130538, -0.06822963, -0.02570503, -0.01041138,  0.05419084,\n",
       "         0.        , -0.01804593,  0.08147407,  0.00258405, -0.03745424,\n",
       "        -0.03651138,  0.03051753,  0.01932159,  0.02838464,  0.04548696,\n",
       "        -0.04453183,  0.0014736 , -0.0065514 ,  0.04257555, -0.03508282,\n",
       "         0.0004514 , -0.07378474, -0.03098838, -0.01756419,  0.01092737],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(100, 1), dtype=float32, numpy=\n",
       " array([[5.97090162e-02],\n",
       "        [1.16407029e-01],\n",
       "        [1.37379050e-01],\n",
       "        [4.51285914e-02],\n",
       "        [7.25553483e-02],\n",
       "        [1.36926211e-02],\n",
       "        [1.89477697e-01],\n",
       "        [7.53700584e-02],\n",
       "        [7.25648329e-02],\n",
       "        [1.03685141e-01],\n",
       "        [7.19269067e-02],\n",
       "        [1.67081639e-01],\n",
       "        [9.03416018e-04],\n",
       "        [4.73111868e-02],\n",
       "        [8.91350734e-04],\n",
       "        [2.72592925e-03],\n",
       "        [8.02022070e-02],\n",
       "        [8.23335350e-03],\n",
       "        [1.13909684e-01],\n",
       "        [1.82360381e-01],\n",
       "        [3.41874473e-02],\n",
       "        [2.86419213e-01],\n",
       "        [1.50048107e-01],\n",
       "        [0.00000000e+00],\n",
       "        [6.43567666e-02],\n",
       "        [6.13294262e-03],\n",
       "        [4.40975931e-03],\n",
       "        [3.30065936e-02],\n",
       "        [4.73522581e-02],\n",
       "        [1.75137609e-01],\n",
       "        [3.95610854e-02],\n",
       "        [3.58952934e-06],\n",
       "        [5.14499471e-02],\n",
       "        [3.06710992e-02],\n",
       "        [2.16581300e-02],\n",
       "        [6.55001058e-05],\n",
       "        [7.67975524e-02],\n",
       "        [2.68765111e-02],\n",
       "        [2.33916636e-03],\n",
       "        [2.63005257e-01],\n",
       "        [3.67693342e-02],\n",
       "        [1.82660714e-01],\n",
       "        [9.00838932e-04],\n",
       "        [3.22766555e-03],\n",
       "        [0.00000000e+00],\n",
       "        [4.68648039e-02],\n",
       "        [2.60834277e-01],\n",
       "        [4.24335040e-02],\n",
       "        [6.32905364e-02],\n",
       "        [1.03608355e-01],\n",
       "        [0.00000000e+00],\n",
       "        [1.06199622e-01],\n",
       "        [1.10736378e-01],\n",
       "        [5.49432077e-02],\n",
       "        [4.10424545e-02],\n",
       "        [1.80455267e-01],\n",
       "        [5.57892621e-02],\n",
       "        [2.83642374e-02],\n",
       "        [8.84559453e-02],\n",
       "        [3.04685999e-02],\n",
       "        [9.16323531e-03],\n",
       "        [1.44537315e-01],\n",
       "        [8.66160244e-02],\n",
       "        [3.34683247e-02],\n",
       "        [2.98574746e-01],\n",
       "        [2.47431789e-02],\n",
       "        [1.22568727e-01],\n",
       "        [3.54319029e-02],\n",
       "        [6.48372993e-02],\n",
       "        [1.31614236e-02],\n",
       "        [1.04106918e-01],\n",
       "        [8.37228075e-03],\n",
       "        [9.32894945e-02],\n",
       "        [2.09803194e-01],\n",
       "        [2.54487479e-03],\n",
       "        [1.50751695e-01],\n",
       "        [1.18901543e-01],\n",
       "        [4.48495857e-02],\n",
       "        [4.15842421e-02],\n",
       "        [6.71980605e-02],\n",
       "        [0.00000000e+00],\n",
       "        [4.29254584e-02],\n",
       "        [2.03381255e-01],\n",
       "        [1.72936451e-03],\n",
       "        [4.39775996e-02],\n",
       "        [1.36997491e-01],\n",
       "        [1.16039086e-02],\n",
       "        [2.48754099e-02],\n",
       "        [2.71041989e-02],\n",
       "        [4.14184667e-02],\n",
       "        [5.34103923e-02],\n",
       "        [1.05082022e-03],\n",
       "        [1.45063810e-02],\n",
       "        [2.31236428e-01],\n",
       "        [1.14089303e-01],\n",
       "        [2.00631708e-01],\n",
       "        [8.26677158e-02],\n",
       "        [4.22210060e-02],\n",
       "        [3.15204740e-01],\n",
       "        [9.24671814e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.38547385], dtype=float32)>]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74644190-051e-4fa1-a16b-a5dddbe3c805",
   "metadata": {},
   "source": [
    "### Possible way to define custom loss function:\n",
    "\n",
    "see https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#define_the_loss_and_gradients_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "dbd72960-15a4-4039-98c3-90d355798b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(x, y, phi_x):\n",
    "    \n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        return \"a\"\n",
    "    \n",
    "    return loss(model(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3924a-f894-45dc-8db3-1c611d2941f2",
   "metadata": {},
   "source": [
    "### 05.05.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123e28d-73f2-4d89-bb11-b38edc788475",
   "metadata": {},
   "source": [
    "I. Modify training loop from yersterday:\n",
    "- Add metrics to track performance  - DONE\n",
    "\n",
    "II. Create a baseline model following standard risk minimization framework.  - DONE\n",
    "\n",
    "III. Clean up -> e.g. write a class where training loop is implemented and params are provided upon instatiation\n",
    "\n",
    "IV. write function to reset weights to complete random.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "d2ff1441-e4ca-45c2-90ea-5327adee3ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: -1.0929\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: -0.0621\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: -0.7012\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: -0.0109\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: -1.0154\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0406\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: -1.5759\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0085\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: -1.2217\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0876\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: -0.9066\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: -0.0218\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: -0.4143\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: -0.0118\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: -0.8693\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: -0.0191\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: -0.7387\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0066\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: -0.5557\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0144\n",
      "Seen so far: 6464 samples\n"
     ]
    }
   ],
   "source": [
    "trainable_weights_list = []\n",
    "grads_list = []\n",
    "\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "B = 32\n",
    "\n",
    "# important: only for full batches\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (pred_batch, x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        x_J = x_batch_train[:B]\n",
    "        x_J_prime = x_batch_train[B:]\n",
    "        y_J_true = y_batch_train[:B]\n",
    "        y_J_prime_true = y_batch_train[B:]\n",
    "        \n",
    "        # Dirty solution -> one type for every tensor in advance\n",
    "        y_J_prime_true = tf.cast(y_J_prime_true, tf.float32)\n",
    "        y_J_prime_true = tf.expand_dims(y_J_prime_true, axis=1)\n",
    "        \n",
    "        \n",
    "        pred_J = pred_batch[:B]\n",
    "        pred_J_prime = pred_batch[B:]\n",
    "        \n",
    "        \n",
    "        \n",
    "        y_J_prime_pred = k_bin_class(x_J_prime)\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation.\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            \n",
    "            y_J_pred = k_bin_class(x_J, training=True)  # Logits for J batch recorded on gradient tape\n",
    "            # tape.watch(y_J_pred)\n",
    "            # y_J_test = k_bin_class(x_J, training=True)  # Logits for J batch recorded on gradient tape\n",
    "            \n",
    "            \n",
    "            # y_pred = tf.concat([y_J_pred, y_J_prime_pred], axis=0)  # not sure if needed\n",
    "            \n",
    "            y_J_pred = tf.broadcast_to(y_J_pred, shape=[y_J_pred.shape[0], pred_J.shape[1]])\n",
    "            \n",
    "            # Compute the loss value for this minibatch.\n",
    "            v = tf.reduce_mean(pred_J * y_J_pred, axis=0, keepdims=True)\n",
    "\n",
    "            v_prime_inter = tf.broadcast_to(y_J_prime_pred - y_J_prime_true, \n",
    "                                            shape=[y_J_prime_true.shape[0], pred_J_prime.shape[1]])\n",
    "\n",
    "            v_prime = tf.reduce_mean(pred_J_prime * v_prime_inter, axis=0, keepdims=True)\n",
    "            \n",
    "            \n",
    "            v_prime_times_weight_matrix = tf.matmul(weight_matrix, tf.transpose(v_prime))\n",
    "            \n",
    "            loss_value = tf.multiply(tf.Variable(2, dtype=tf.float32),\n",
    "                                     tf.tensordot(v, tf.matmul(weight_matrix, tf.transpose(v_prime)), axes=1))\n",
    "            \n",
    "            watched_vars = tape.watched_variables()\n",
    "        # Use the gradient tape to automatically retrieve\n",
    "        \n",
    "        # the gradients of the trainable variables with respect to the loss.\n",
    "        # grads = tape.gradient(y_J_test, k_bin_class.trainable_weights)\n",
    "        # grads_list.append(grads)\n",
    "        \n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "        epoch_accuracy.update_state(y_batch_train, tf.round(k_bin_class(x_batch_train, training=True)))\n",
    "        \n",
    "        grads = tape.gradient(loss_value, k_bin_class.trainable_weights)\n",
    "        grads_list.append(grads)\n",
    "        # Until here, seems to work fine.\n",
    "        \n",
    "        \n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        # print(k_bin_class.trainable_weights)\n",
    "        # print(grads)\n",
    "        \n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, k_bin_class.trainable_weights))\n",
    "        # print(k_bin_class.trainable_weights)\n",
    "        # raise Exception\n",
    "        trainable_weights_list.append(k_bin_class.trainable_weights)\n",
    "    \n",
    "        # Log every 200 batches.\n",
    "        if step % 100 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    # Epoch stats\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "158b5ce3-d9c8-4c94-8b87-46ce6918f485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.06272748>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.011001756>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0057237484>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0039799097>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0041482914>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0021573582>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0033132925>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0031591486>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0032810452>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0012288719>]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "bab7719b-03c6-405c-be4e-30c3035f66ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.8958333>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.93005955>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9418816>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9451058>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9467593>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.93907076>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.94055885>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.942791>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.94651127>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9463459>]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "b1e38d0a-323b-426f-9c8f-5d89bf2d2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "7ac5b1c7-a75a-4732-96ff-9210641fc7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "test_accuracy.update_state(y_test_selected, tf.round(k_bin_class(x_test_selected)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "3930610e-ca8e-42e7-a694-d4b5e2236019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2002, 28, 28)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "3b49eb29-9599-40bd-9e7d-a78e51efdb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "0b7d63f2-781e-4a6b-8d50-59dd70bc680f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: ((64, 3), (64, 28, 28), (64,)), types: (tf.float32, tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "47167e01-22f0-49b4-af85-9f677b64ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "for step, (pred_batch_test, x_batch_test, y_batch_test) in enumerate(test_dataset):\n",
    "    test_accuracy.update_state(y_batch_test, tf.round(k_bin_class(x_batch_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "53e98b2a-160b-46eb-8f6c-ede15525b0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.905746>"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef724b-8acd-4072-8c3c-cd3e2159696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network with one hidden layer and one output layer\n",
    "k_bin_class = keras.Sequential(\n",
    "    [   layers.Flatten(input_shape=(28,28)),\n",
    "        layers.Dense(100, activation=\"relu\", name=\"hidden_layer_01\"),\n",
    "#        layers.Dense(1, name=\"output_layer\", activation=\"sigmoid\") # interpret output as prob. for class 1\n",
    "        layers.Dense(1, name=\"output_layer\", activation=\"relu\") # interpret output as prob. for class 1\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "cba320bb-033d-4364-93cd-7b2b7f450aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_bin_class = keras.Sequential(\n",
    "[\n",
    "    layers.Flatten(input_shape=(28,28)),\n",
    "    layers.Dense(100, activation=\"relu\", name=\"hidden_layer\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\") # interpret output as prob. for class 1\n",
    "    # layers.Dense(1, name=\"output_layer\", activation=\"relu\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "f950dc12-dc18-4e9c-9bdc-270f31772f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_bin_class.compile(\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    # loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # loss=keras.losses.binary_crossentropy(),\n",
    "    loss = keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "efefff6a-ef12-44dc-825c-8c9b2bae3988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 760us/step - loss: 0.7243 - binary_accuracy: 0.4341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7242804765701294, 0.43406593799591064]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval untrained model\n",
    "baseline_bin_class.evaluate(x_test_selected, y_test_selected, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "2f20b33a-9bac-4693-8a0d-c1c8a3a5b4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "190/190 [==============================] - 0s 964us/step - loss: 0.2844 - binary_accuracy: 0.9328\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 916us/step - loss: 0.1093 - binary_accuracy: 0.9749\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 943us/step - loss: 0.0788 - binary_accuracy: 0.9794\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 918us/step - loss: 0.0649 - binary_accuracy: 0.9815\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 930us/step - loss: 0.0565 - binary_accuracy: 0.9837\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 942us/step - loss: 0.0508 - binary_accuracy: 0.9849\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 972us/step - loss: 0.0466 - binary_accuracy: 0.9857\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 946us/step - loss: 0.0432 - binary_accuracy: 0.9864\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 982us/step - loss: 0.0407 - binary_accuracy: 0.9875\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 948us/step - loss: 0.0385 - binary_accuracy: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b64b1150>"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_bin_class.fit(x_train_2d, y_train, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "c53d6366-c5cd-4afe-9c29-95c1eda5c4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 930us/step - loss: 0.0519 - binary_accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.051938824355602264, 0.9815185070037842]"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_bin_class.evaluate(x_test_selected, y_test_selected, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "ebc047bb-a1e7-49fb-8224-46240d85c398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9994277]], dtype=float32)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_bin_class.predict(x_test_selected[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "20fe2e44-a0a8-4871-9412-5b6b0f5431e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b65ae7a0>"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test_selected[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "aab4b4e4-0c49-4d64-8f31-b4aa5df8ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = lal.LusiModel(predicates=None, weight_matrix=weight_matrix)\n",
    "my_model.add_optimizer(tf.keras.optimizers.SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "f11aa921-4d0f-4b06-a661-c97908384037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modify_metric = lal.modify_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "5b911953-8f76-42b0-bc22-ab629e12c204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.5302419>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=377.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=555.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.51974523>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.423676>),\n",
       " ('Mean', <tf.Tensor: shape=(), dtype=float32, numpy=0.0>)]"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics = [modify_metric(tf.keras.metrics.BinaryAccuracy(name=\"Binary Accuracy\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.FalsePositives(name=\"False Positives\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.FalseNegatives(name=\"False Negatives\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.Precision(name=\"Precision\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.Recall(name=\"Recall\"), \"pred_and_true\"),\n",
    "                modify_metric(tf.keras.metrics.Mean(name=\"Mean\"), \"loss\")\n",
    "               ]\n",
    "my_model.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "6e49fe5c-f265-4cd8-b80c-159cf0b3417d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics[0].reset_state()\n",
    "\n",
    "#my_model.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "1070eaf4-76f4-4b6e-a0b4-3431c361c0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: -1.0425\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.7104\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: -1.0505\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1994\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: -1.2303\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1529\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: -1.0123\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1392\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: -0.6522\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0871\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: -0.5270\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0409\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: -0.3803\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0962\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: -0.3648\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0558\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: -0.3023\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0707\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: -0.1665\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0634\n",
      "Seen so far: 6464 samples\n"
     ]
    }
   ],
   "source": [
    "my_model.train(train_dataset, 10, B, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "afe60940-c5da-4828-aca0-7a8320128d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch 0 -----\n",
      "Binary Accuracy: 0.52685546875\n",
      "False Positives: 377.0\n",
      "False Negatives: 592.0\n",
      "Precision: 0.5357142686843872\n",
      "Recall: 0.42356377840042114\n",
      "Mean: -0.03257717937231064\n",
      "----- Epoch 1 -----\n",
      "Binary Accuracy: 0.8444602489471436\n",
      "False Positives: 1507.0\n",
      "False Negatives: 683.0\n",
      "Precision: 0.8026970624923706\n",
      "Recall: 0.8997651934623718\n",
      "Mean: -0.00986365508288145\n",
      "----- Epoch 2 -----\n",
      "Binary Accuracy: 0.9413855671882629\n",
      "False Positives: 488.0\n",
      "False Negatives: 221.0\n",
      "Precision: 0.9202353954315186\n",
      "Recall: 0.9622286558151245\n",
      "Mean: -0.12175240367650986\n",
      "----- Epoch 3 -----\n",
      "Binary Accuracy: 0.9608134627342224\n",
      "False Positives: 382.0\n",
      "False Negatives: 92.0\n",
      "Precision: 0.9377951622009277\n",
      "Recall: 0.9842761754989624\n",
      "Mean: -0.11836786568164825\n",
      "----- Epoch 4 -----\n",
      "Binary Accuracy: 0.9656084775924683\n",
      "False Positives: 346.0\n",
      "False Negatives: 70.0\n",
      "Precision: 0.9435286521911621\n",
      "Recall: 0.9880362153053284\n",
      "Mean: -0.11974052339792252\n",
      "----- Epoch 5 -----\n",
      "Binary Accuracy: 0.9677579402923584\n",
      "False Positives: 327.0\n",
      "False Negatives: 63.0\n",
      "Precision: 0.9465249180793762\n",
      "Recall: 0.98923259973526\n",
      "Mean: -0.10738988220691681\n",
      "----- Epoch 6 -----\n",
      "Binary Accuracy: 0.9679232835769653\n",
      "False Positives: 314.0\n",
      "False Negatives: 74.0\n",
      "Precision: 0.9484485387802124\n",
      "Recall: 0.9873526096343994\n",
      "Mean: -0.10603021830320358\n",
      "----- Epoch 7 -----\n",
      "Binary Accuracy: 0.9698247313499451\n",
      "False Positives: 290.0\n",
      "False Negatives: 75.0\n",
      "Precision: 0.9521925449371338\n",
      "Recall: 0.9871816635131836\n",
      "Mean: -0.09736069291830063\n",
      "----- Epoch 8 -----\n",
      "Binary Accuracy: 0.971230149269104\n",
      "False Positives: 270.0\n",
      "False Negatives: 78.0\n",
      "Precision: 0.9553201794624329\n",
      "Recall: 0.9866689443588257\n",
      "Mean: -0.0956244021654129\n",
      "----- Epoch 9 -----\n",
      "Binary Accuracy: 0.9713954925537109\n",
      "False Positives: 271.0\n",
      "False Negatives: 75.0\n",
      "Precision: 0.9551844000816345\n",
      "Recall: 0.9871816635131836\n",
      "Mean: -0.09069140255451202\n",
      "----- Epoch 10 -----\n",
      "Binary Accuracy: 0.9721395373344421\n",
      "False Positives: 261.0\n",
      "False Negatives: 76.0\n",
      "Precision: 0.9567594528198242\n",
      "Recall: 0.9870107769966125\n",
      "Mean: -0.08321402966976166\n"
     ]
    }
   ],
   "source": [
    "for j,e in enumerate(my_model.epoch_train_metrics_results):\n",
    "    print(f\"----- Epoch {j} -----\")\n",
    "    for i in e:\n",
    "        print(f\"{i[0]}: {i[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "dfed53d7-6af5-43cd-8bf5-b4fec3ee556d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.8142641>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=526.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=211.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.76632607>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.8910124>),\n",
       " ('Mean', <tf.Tensor: shape=(), dtype=float32, numpy=0.0>)]"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "b5b2cf18-fee4-4756-93e3-ebea315cc108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.9701108]], dtype=float32)>"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict(x_test_selected[[22]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2559208d-612e-4b0c-ae72-eea0138b1196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "c4e958cb-f5e1-4748-b409-577dd7f4c9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \n",
      "\n",
      "Binary Accuracy: 0.8071733117103577\n",
      "False Positives: 2014.0\n",
      "False Negatives: 701.0\n",
      "Precision: 0.7523059844970703\n",
      "Recall: 0.897183895111084\n",
      "Mean: 0.0200845655053854\n",
      "Epoch 1 \n",
      "\n",
      "Binary Accuracy: 0.9328703880310059\n",
      "False Positives: 508.0\n",
      "False Negatives: 304.0\n",
      "Precision: 0.916102409362793\n",
      "Recall: 0.9480430483818054\n",
      "Mean: -0.10966261476278305\n",
      "Epoch 2 \n",
      "\n",
      "Binary Accuracy: 0.9653604626655579\n",
      "False Positives: 321.0\n",
      "False Negatives: 98.0\n",
      "Precision: 0.947151780128479\n",
      "Recall: 0.9832507371902466\n",
      "Mean: -0.11335418373346329\n",
      "Epoch 3 \n",
      "\n",
      "Binary Accuracy: 0.9695767164230347\n",
      "False Positives: 289.0\n",
      "False Negatives: 79.0\n",
      "Precision: 0.9523180723190308\n",
      "Recall: 0.9864980578422546\n",
      "Mean: -0.11480322480201721\n",
      "Epoch 4 \n",
      "\n",
      "Binary Accuracy: 0.9718088507652283\n",
      "False Positives: 265.0\n",
      "False Negatives: 76.0\n",
      "Precision: 0.9561258554458618\n",
      "Recall: 0.9870107769966125\n",
      "Mean: -0.11239594966173172\n",
      "Epoch 5 \n",
      "\n",
      "Binary Accuracy: 0.9728835821151733\n",
      "False Positives: 251.0\n",
      "False Negatives: 77.0\n",
      "Precision: 0.9583402276039124\n",
      "Recall: 0.9868398308753967\n",
      "Mean: -0.10140147805213928\n",
      "Epoch 6 \n",
      "\n",
      "Binary Accuracy: 0.9747850298881531\n",
      "False Positives: 233.0\n",
      "False Negatives: 72.0\n",
      "Precision: 0.9612441658973694\n",
      "Recall: 0.9876943826675415\n",
      "Mean: -0.09337197989225388\n",
      "Epoch 7 \n",
      "\n",
      "Binary Accuracy: 0.9747023582458496\n",
      "False Positives: 231.0\n",
      "False Negatives: 75.0\n",
      "Precision: 0.9615448713302612\n",
      "Recall: 0.9871816635131836\n",
      "Mean: -0.09054035693407059\n",
      "Epoch 8 \n",
      "\n",
      "Binary Accuracy: 0.9751983880996704\n",
      "False Positives: 226.0\n",
      "False Negatives: 74.0\n",
      "Precision: 0.9623521566390991\n",
      "Recall: 0.9873526096343994\n",
      "Mean: -0.08981653302907944\n",
      "Epoch 9 \n",
      "\n",
      "Binary Accuracy: 0.9765211343765259\n",
      "False Positives: 210.0\n",
      "False Negatives: 74.0\n",
      "Precision: 0.9649239778518677\n",
      "Recall: 0.9873526096343994\n",
      "Mean: -0.08282019942998886\n"
     ]
    }
   ],
   "source": [
    "for j,e in enumerate(my_model.epoch_train_metrics_results):\n",
    "    print(f\"Epoch {j} \\n\")\n",
    "    for i in e:\n",
    "        print(f\"{i[0]}: {i[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "58fedfd6-8e8d-4789-a0fd-4c07a383aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "mets = my_model.epoch_train_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "7040a4df-c130-485c-a646-eea2bb40c737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.93382716>"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mets[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "ed4f584b-5ba4-44dd-b1e8-cc1e443714ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b9072380>"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test_selected[22])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lusi",
   "language": "python",
   "name": "lusi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
