{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b2b655-7de3-446f-8784-c894435d97b1",
   "metadata": {},
   "source": [
    "# Demo version 06.05.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03aae76f-f48d-4e21-bf7b-200623da9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ba554-3321-4077-b745-49eee6dece62",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b6ceea-b147-4310-a1b7-db6ab2e0572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lusi_Andreas_Loehr as lal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87d952d-1014-4b2a-996f-afff0ca9cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functinos into global namespace\n",
    "modify_metric = lal.modify_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4150b-bf8f-4e2d-aadc-6ab6c840153f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8e1d67-3966-488a-88d9-fa6058e3befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset, set batch size.\n",
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bede0435-77c5-464e-85df-063fe307c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep train dataset.\n",
    "eights = x_train[y_train == 8]/255\n",
    "sevens = x_train[y_train == 7]/255\n",
    "\n",
    "y_eights = np.ones(eights.shape[0])\n",
    "y_sevens = np.zeros(sevens.shape[0])\n",
    "\n",
    "# not needed as \n",
    "# eights_flat = np.reshape(eights, (-1, 784))\n",
    "# sevens_flat = np.reshape(sevens, (-1, 784))\n",
    "# x_train = np.concatenate([eights_flat, sevens_flat])\n",
    "\n",
    "x_train_2d = np.concatenate([eights, sevens])\n",
    "y_train = np.concatenate([y_eights, y_sevens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31b6406-d3d6-4274-beff-25aadb8cd2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'eights' data: (5851, 28, 28)\n",
      "Shape of 'sevens' data: (6265, 28, 28)\n",
      "Shape of entire training dataset: (12116, 28, 28)\n",
      "Shape of training dataset labels: (12116,)\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "print(f\"Shape of 'eights' data: {eights.shape}\")\n",
    "print(f\"Shape of 'sevens' data: {sevens.shape}\")\n",
    "print(f\"Shape of entire training dataset: {x_train_2d.shape}\")\n",
    "print(f\"Shape of training dataset labels: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "483fe52f-e102-4646-8f9f-bca39dffd778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep test dataset.\n",
    "eights_test = x_test[y_test == 8]/255\n",
    "sevens_test = x_test[y_test == 7]/255\n",
    "\n",
    "y_eights_test = np.ones(eights_test.shape[0])\n",
    "y_sevens_test = np.zeros(sevens_test.shape[0])\n",
    "\n",
    "x_test = np.concatenate([eights_test, sevens_test])\n",
    "y_test = np.concatenate([y_eights_test, y_sevens_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e41debeb-3d32-4070-a804-5088afdb262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'eights' test data: (974, 28, 28)\n",
      "Shape of 'sevens' test data: (1028, 28, 28)\n",
      "Shape of entire test dataset: (2002, 28, 28)\n",
      "Shape of entire test dataset labels: (2002,)\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "print(f\"Shape of 'eights' test data: {eights_test.shape}\")\n",
    "print(f\"Shape of 'sevens' test data: {sevens_test.shape}\")\n",
    "print(f\"Shape of entire test dataset: {x_test.shape}\")\n",
    "print(f\"Shape of entire test dataset labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb82304-2b07-42da-88ec-a851fedf76ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<function avg_pixel_intensity at 0x1a0ba4790>,\n",
       "       <function weighted_pixel_intesity at 0x1a0ba4940>,\n",
       "       functools.partial(<function local_pixel_intensity_single at 0x1a0ba49d0>, patch=((10, 20), (10, 20)))],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load numpy array of predicate functions\n",
    "preds = lal.phi\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ffb064-6892-49ea-8eab-a710cc8c2e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 11:31:36.387081: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predicates on training data\n",
    "pred_eval = lal.apply_predicates_on_data(preds, x_train_2d)\n",
    "pred_eval_test = lal.apply_predicates_on_data(preds, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc58c7a-9bff-4965-9543-439282feb34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of pred_eval is: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "\n",
      "Shape of pred_eval is: (12116, 3). This is the result of applying 3 predicates on the training data.\n",
      "\n",
      "Shape of pred_eval_test is: (2002, 3). This is the result of applying 3 predicates on the test data.\n",
      "\n",
      "Shape of train dataset is: (12116, 28, 28)\n",
      "Shape of training labels is: (12116,)\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "print(f\"Type of pred_eval is: {type(pred_eval)}\\n\")\n",
    "print(f\"Shape of pred_eval is: {pred_eval.shape}. This is the result of applying {preds.shape[0]} predicates on the training data.\\n\")\n",
    "print(f\"Shape of pred_eval_test is: {pred_eval_test.shape}. This is the result of applying {preds.shape[0]} predicates on the test data.\\n\")\n",
    "print(f\"Shape of train dataset is: {x_train_2d.shape}\")\n",
    "print(f\"Shape of training labels is: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2cf02d6-ddfe-44c5-b3fd-b8844e415bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch training dataset and prepare for training with custom lusi loss.\n",
    "# Important: Set reminder to true, else B in custom training loop might greater than batch_size of last batch.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((pred_eval, x_train_2d, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf92c134-b80f-4358-ba44-b41ca30f493a",
   "metadata": {},
   "source": [
    "### Zipped train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd49ff4-8402-4502-aa2b-96191873b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((pred_eval, x_train_2d, y_train))\n",
    "\n",
    "\n",
    "train_dataset_b = train_dataset.shuffle(buffer_size=1024).batch(64, drop_remainder=True)\n",
    "train_dataset_b_prime = train_dataset.shuffle(buffer_size=1024).batch(54, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "6b276429-6a5a-4a29-b96c-b909dd007b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Periphery:\n",
    "    def __init__(self, train_data=None, test_data=None, n_train=None, n_test=None, \n",
    "                 model=None, phi=None, batch_size_1=32, batch_size_2=32) -> None:\n",
    "        \n",
    "        \"\"\"Bind all data and objetcs for Lusi method.\n",
    "        \n",
    "        Parameters:\n",
    "        train_data :: tuple of np.ndarrays - (x_train, y_train) | None\n",
    "            Training data.\n",
    "        \n",
    "        test_data :: tuple of np.ndarrays - (x_test, y_test) | None\n",
    "            Test data.\n",
    "        \n",
    "        n_train :: int | None \n",
    "            Number of samples to be used for training.\n",
    "            If None, use entire train_data.\n",
    "            \n",
    "        n_test :: int | None\n",
    "            Number of samples to be used for testing.\n",
    "            If None, use entire test_data.\n",
    "        \n",
    "        model :: tensorflow model | None\n",
    "            Either compiled tf model or LusiModel instance.\n",
    "            \n",
    "        phi :: np.ndarray[list[function]]\n",
    "            A numpy array of list of functions to be applied on x_data.\n",
    "        \n",
    "        batch_size_1 :: int\n",
    "            Batch size B from paper. This batch size is used in training.\n",
    "            Default value: 32.\n",
    "            \n",
    "        batch_size_2 :: int\n",
    "            Batch size B' from paper. This batch size is used in training.\n",
    "            Default value: 32.        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.n_train = n_train\n",
    "        self.n_test = n_test\n",
    "        self.phi = phi\n",
    "        self.batch_size_1 = batch_size_1\n",
    "        self.batch_size_2 = batch_size_2\n",
    "       \n",
    "        if self.train_data:\n",
    "            self.generate_batched_data(train=True)\n",
    "        \n",
    "        if self.test_data:\n",
    "            self.generate_batched_data(train=False)\n",
    "            \n",
    "        if self.n_train:\n",
    "            pass\n",
    "            \n",
    "    \n",
    "    \n",
    "    def generate_batched_data(self, train=True):\n",
    "        if train:\n",
    "            self.train_data_batched_p = self.batch_train(include_phi=True)\n",
    "            self.train_data_batched_nop = self.batch_train(include_phi=False)\n",
    "        else:\n",
    "            # test data\n",
    "            self.test_data_batched_p = self.batch_test(include_phi=True)\n",
    "            self.test_data_batched_nop = self.batch_test(include_phi=False)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def shrink_data(self, train=True):\n",
    "        # Not like this. Cannot shrink it here if already shrunk in batch_train or batch_test method\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def batch_train(self, include_phi=True):\n",
    "        \n",
    "        data = self.train_data\n",
    "        n = self.n_train\n",
    "        \n",
    "        if not data:\n",
    "            raise ValueError(\"No data provided.\")\n",
    "        \n",
    "        if not n:\n",
    "            x = data[0]\n",
    "            y = data[1]\n",
    "                \n",
    "        else:\n",
    "            # Do not use entire dataset.\n",
    "            indices = np.random.randint(0, data[0].shape[0], size=n)\n",
    "            x = data[0][indices]\n",
    "            y = data[1][indices]\n",
    "            \n",
    "            self.class_balance = {0 : y[y==0].shape, 1 : y[y==1].shape}\n",
    "\n",
    "        if include_phi:\n",
    "            # also implies training with two batches desired, i.e. Lusi training\n",
    "            phi_x = self.apply_phi(x)\n",
    "            dataset = tf.data.Dataset.from_tensor_slices((phi_x, x, y))   \n",
    "\n",
    "            batch_dataset_1 = dataset.shuffle(buffer_size=1024).batch(self.batch_size_1, drop_remainder=True)\n",
    "            batch_dataset_2 = dataset.shuffle(buffer_size=1024).batch(self.batch_size_2, drop_remainder=True)\n",
    "\n",
    "            return tf.data.Dataset.zip((batch_dataset_1, batch_dataset_2))            \n",
    "\n",
    "        else:\n",
    "        # return basic batch dataset for regular keras model\n",
    "            dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "            return dataset.shuffle(buffer_size=1024).batch(self.batch_size_1, drop_remainder=False)\n",
    "\n",
    "    \n",
    "    def batch_test(self, include_phi=True):\n",
    "        \n",
    "        data = self.test_data\n",
    "        n = self.n_test\n",
    "        \n",
    "        if not data:\n",
    "            raise ValueError(\"No data provided.\")\n",
    "        \n",
    "            if not n:\n",
    "                x = data[0]\n",
    "                y = data[1]\n",
    "                \n",
    "            else:\n",
    "                # Do not use entire dataset.\n",
    "                indices = np.random.randint(0, data[0].shape[0], size=n)\n",
    "                x = data[0][indices]\n",
    "                y = data[1][indices]\n",
    "                \n",
    "            if include_phi:\n",
    "                # also implies training with two batches desired, i.e. Lusi training\n",
    "                phi_x = self.apply_phi(x)\n",
    "                dataset = tf.data.Dataset.from_tensor_slices((phi_x, x, y))   \n",
    "\n",
    "                batch_dataset_1 = dataset.shuffle(buffer_size=1024).batch(self.batch_size_1, drop_remainder=True)\n",
    "                batch_dataset_2 = dataset.shuffle(buffer_size=1024).batch(self.batch_size_2, drop_remainder=True)\n",
    "\n",
    "                return tf.data.Dataset.zip((batch_dataset_1, batch_dataset_2))            \n",
    "\n",
    "            else:\n",
    "            # return basic batch dataset for regular keras model\n",
    "                dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "                return dataset.shuffle(buffer_size=1024).batch(self.batch_size_1, drop_remainder=False)\n",
    "\n",
    "            \n",
    "    def apply_phi(self, x) -> None:\n",
    "            \"\"\" Evaluate predicates on x and store values.\n",
    "\n",
    "            Parameters: \n",
    "            x :: np.ndarray\n",
    "                Data to apply predicates to of dimensinos (n, d0, ..., dN).\n",
    "                For MNIST, dims = (n, 28, 28)\n",
    "\n",
    "            Returns:\n",
    "            Tensor of dimensions (n, d).\n",
    "            \"\"\"\n",
    "\n",
    "            phi_x = np.asarray([self.phi[i](x[j]) for j in range(x.shape[0]) for i in range(self.phi.shape[0])])\n",
    "            phi_x = phi_x.reshape(x.shape[0], self.phi.shape[0])\n",
    "            phi_x = tf.convert_to_tensor(phi_x, dtype=tf.float32)\n",
    "\n",
    "            return phi_x\n",
    "    \n",
    "    \n",
    "    def set_batch_sizes(self, batch_sizes : tuple) -> None:\n",
    "        self.batch_size_1 = batch_sizes[0]\n",
    "        self.batch_size_2 = batch_sizes[1]\n",
    "\n",
    "        return None\n",
    "    \n",
    "        \n",
    "    def set_phi(self, phi : list) -> None:\n",
    "        self.phi = phi\n",
    "    \n",
    "        return None\n",
    "    \n",
    "    def set_total_train_size(self, n_train) -> None:\n",
    "        self.n_train = n_train\n",
    "        \n",
    "        return None\n",
    "\n",
    "    \n",
    "    def set_total_test_size(self, n_test) -> None:\n",
    "        self.n_test = n_test\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def set_train_data(self, train_data):\n",
    "        self.train_data = train_data\n",
    "        self.generate_batched_data(train=True)\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def set_test_data(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        self.generate_batched_data(train=False)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b2ea5-7ee6-449c-b1ab-c9bdfac75163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "b66942f9-3a32-48d0-8327-6bf6559a12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_s = Periphery((x_train_2d, y_train), (x_test, y_test), n_train=600, phi=lal.phi, batch_size_1=64, batch_size_2=64)\n",
    "size_m = Periphery((x_train_2d, y_train), (x_test, y_test), n_train=2000, phi=lal.phi, batch_size_1=64, batch_size_2=64)\n",
    "size_l = Periphery((x_train_2d, y_train), (x_test, y_test), phi=lal.phi, batch_size_1=64, batch_size_2=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "2a177fa0-c2c2-4db1-ba98-f0649e48ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: (((64, 3), (64, 28, 28), (64,)), ((64, 3), (64, 28, 28), (64,))), types: ((tf.float32, tf.float64, tf.float64), (tf.float32, tf.float64, tf.float64))>"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_s.class_balance\n",
    "size_l.train_data_batched_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "6d2145db-455b-4478-987a-eb337466b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LusiPeriphery:\n",
    "    def __init__(self, train_data=None, test_data=None, n_train=None, n_test=None, \n",
    "                 model=None, phi=None, batch_size_1=32, batch_size_2=32) -> None:\n",
    "        \"\"\"\n",
    "        Bind all data and objetcs for Lusi method.\n",
    "        \n",
    "        Parameters:\n",
    "        train_data :: tuple of np.ndarrays - (x_train, y_train) | None\n",
    "            Training data.\n",
    "        \n",
    "        test_data :: tuple of np.ndarrays - (x_test, y_test) | None\n",
    "            Test data.\n",
    "        \n",
    "        n_train :: int | None \n",
    "            Number of samples to be used for training.\n",
    "            If None, use entire train_data.\n",
    "            \n",
    "        n_test :: int | None\n",
    "            Number of samples to be used for testing.\n",
    "            If None, use entire test_data.\n",
    "        \n",
    "        model :: tensorflow model | None\n",
    "            Either compiled tf model or LusiModel instance.\n",
    "            \n",
    "        phi :: np.ndarray[list[function]]\n",
    "            A numpy array of list of functions to be applied on x_data.\n",
    "        \n",
    "        batch_size_1 :: int\n",
    "            Batch size B from paper. This batch size is used in training.\n",
    "            Default value: 32.\n",
    "            \n",
    "        batch_size_2 :: int\n",
    "            Batch size B' from paper. This batch size is used in training.\n",
    "            Default value: 32.        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.n_train = n_train\n",
    "        self.n_test = n_test\n",
    "        self.model = model\n",
    "        self.phi = phi\n",
    "        self.batch_size_1 = batch_size_1\n",
    "        self.batch_size_2 = batch_size_2\n",
    "    \n",
    "    \n",
    "    def batch_data(self)\n",
    "            \n",
    "    def generate_batch_data(self, train=True, include_phi=True):\n",
    "        \"\"\"Create batch data set for training.\"\"\"\n",
    "        \n",
    "        if train:\n",
    "            data = self.train_data\n",
    "            n = self.n_train\n",
    " \n",
    "            if not data:\n",
    "                raise ValueError(\"No data provided.\")\n",
    "        \n",
    "            if not n:\n",
    "                x = data[0]\n",
    "                y = data[1]\n",
    "                \n",
    "            else:\n",
    "                # Do not use entire dataset.\n",
    "                indices = np.random.randint(0, data[0].shape[0], size=n)\n",
    "                x = data[0][indices]\n",
    "                y = data[1][indices]    \n",
    "\n",
    "            if include_phi:\n",
    "                # also implies training with two batches desired, i.e. Lusi training\n",
    "                phi_x = self.apply_phi(x)\n",
    "                dataset = tf.data.Dataset.from_tensor_slices((phi_x, x, y))   \n",
    "\n",
    "                batch_dataset_1 = dataset.shuffle(buffer_size=1024).batch(self.batch_size_1, drop_remainder=True)\n",
    "                batch_dataset_2 = dataset.shuffle(buffer_size=1024).batch(self.batch_size_2, drop_remainder=True)\n",
    "\n",
    "                self.train_batch = tf.data.Dataset.zip((batch_dataset_1, batch_dataset_2))            \n",
    "\n",
    "            else:\n",
    "            # return basic batch dataset for regular keras model\n",
    "                dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "                self.train_batch =  dataset.shuffle(buffer_size=1024).batch(self.batch_size_1, drop_remainder=False)\n",
    "\n",
    "        else:\n",
    "            # test data to be batched\n",
    "            data = self.test_data\n",
    "            n = self.n_test\n",
    "            if not data:\n",
    "                raise ValueError(\"No data provided.\")\n",
    "        \n",
    "            if not n:\n",
    "                x = data[0]\n",
    "                y = data[1]\n",
    "                \n",
    "            else:\n",
    "                # Do not use entire dataset.\n",
    "                indices = np.random.randint(0, data[0].shape[0], size=n)\n",
    "                x = data[0][indices]\n",
    "                y = data[1][indices]    \n",
    "\n",
    "            if include_phi:\n",
    "                # also implies training with two batches desired, i.e. Lusi training\n",
    "                phi_x = self.apply_phi(x)\n",
    "                dataset = tf.data.Dataset.from_tensor_slices((phi_x, x, y))   \n",
    "\n",
    "                batch_dataset_1 = dataset.shuffle(buffer_size=1024).batch(self.batch_size_1, drop_remainder=True)\n",
    "                batch_dataset_2 = dataset.shuffle(buffer_size=1024).batch(self.batch_size_2, drop_remainder=True)\n",
    "\n",
    "                self.train_batch = tf.data.Dataset.zip((batch_dataset_1, batch_dataset_2))            \n",
    "\n",
    "            else:\n",
    "            # return basic batch dataset for regular keras model\n",
    "                dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "                self.train_batch =  dataset.shuffle(buffer_size=1024).batch(self.batch_size_1, drop_remainder=False)\n",
    "    \n",
    "    def apply_phi(self, x) -> None:\n",
    "        \"\"\" Evaluate predicates on x and store values.\n",
    "        \n",
    "        Parameters: \n",
    "        x :: np.ndarray\n",
    "            Data to apply predicates to of dimensinos (n, d0, ..., dN).\n",
    "            For MNIST, dims = (n, 28, 28)\n",
    "\n",
    "        Returns:\n",
    "        Tensor of dimensions (n, d).\n",
    "        \"\"\"\n",
    "    \n",
    "        phi_x = np.asarray([self.phi[i](x[j]) for j in range(x.shape[0]) for i in range(self.phi.shape[0])])\n",
    "        phi_x = phi_x.reshape(x.shape[0], self.phi.shape[0])\n",
    "        phi_x = tf.convert_to_tensor(phi_x, dtype=tf.float32)\n",
    "    \n",
    "        return phi_x \n",
    "    \n",
    "    \n",
    "    def set_model(self, model) -> None:\n",
    "        self.model = model\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def set_batch_sizes(self, batch_sizes : tuple) -> None:\n",
    "        self.batch_size_1 = batch_sizes[0]\n",
    "        self.batch_size_2 = batch_sizes[1]\n",
    "\n",
    "        return None\n",
    "        \n",
    "    def set_phi(self, phi : list) -> None:\n",
    "        self.phi = phi\n",
    "    \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def set_total_train_size(self, n_train) -> None:\n",
    "        self.n_train = n_train\n",
    "        \n",
    "        return None\n",
    "\n",
    "    \n",
    "    def set_total_test_size(self, n_test) -> None:\n",
    "        self.n_test = n_test\n",
    "        \n",
    "        return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "6a5a5661-0c30-4f4d-b1e7-125911cac5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = LusiPeriphery(train_data=(x_train_2d, y_train))\n",
    "lp.set_phi(lal.phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "b7af99a1-8828-4a93-a4a7-ea4cfa3b388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = lp.generate_batch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d99ba949-63f6-4ec2-8c67-8e8de68d7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = tf.data.Dataset.zip((train_dataset_b, train_dataset_b_prime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "1f7ad462-f2e2-4bd5-9605-e203a735473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch 1 dimensions for batch number 0: (TensorShape([32, 3]), TensorShape([32, 28, 28]), TensorShape([32]))\n",
      "Train batch 2 dimensions for batch number 0: (TensorShape([32, 3]), TensorShape([32, 28, 28]), TensorShape([32]))\n",
      "Train batch 1 dimensions for batch number 1: (TensorShape([32, 3]), TensorShape([32, 28, 28]), TensorShape([32]))\n",
      "Train batch 2 dimensions for batch number 1: (TensorShape([32, 3]), TensorShape([32, 28, 28]), TensorShape([32]))\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "i = 0\n",
    "for b, b_ in ds:\n",
    "    if i < 2:\n",
    "        print(f\"Train batch 1 dimensions for batch number {i}: {b[0].shape, b[1].shape, b[2].shape}\")\n",
    "        print(f\"Train batch 2 dimensions for batch number {i}: {b_[0].shape, b_[1].shape, b_[2].shape}\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dbf8101-e76c-4064-afcd-0272892eef85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float64, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 2.],\n",
       "       [2., 2., 2.],\n",
       "       [2., 2., 2.],\n",
       "       [2., 2., 2.]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable(np.ones(shape=(2,3)))\n",
    "b = tf.Variable(2 * np.ones(shape=(4,3)))\n",
    "c = tf.concat([a,b], axis=0)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e03f726-af18-46cb-afaa-ad236f6ed140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes for batches of step 0:\n",
      "Predicates batch 1 have shape (64, 3)\n",
      "Predicates batch 2 have shape (54, 3)\n",
      "x values batch 1 have shape (64, 28, 28)\n",
      "x values batch 2 have shape (54, 28, 28)\n",
      "y values batch 1 have shape (64,)\n",
      "y values batch 2 have shape (54,)\n",
      "\n",
      "Shapes for batches of step 1:\n",
      "Predicates batch 1 have shape (64, 3)\n",
      "Predicates batch 2 have shape (54, 3)\n",
      "x values batch 1 have shape (64, 28, 28)\n",
      "x values batch 2 have shape (54, 28, 28)\n",
      "y values batch 1 have shape (64,)\n",
      "y values batch 2 have shape (54,)\n"
     ]
    }
   ],
   "source": [
    "for step, ((pred_batch_1, x_batch_train_1, y_batch_train_1), (pred_batch_2, x_batch_train_2, y_batch_train_2))  in enumerate(train_batch):\n",
    "    if step <= 1:\n",
    "        print(f\"\\nShapes for batches of step {step}:\")\n",
    "        print(f\"Predicates batch 1 have shape {pred_batch_1.shape}\")\n",
    "        print(f\"Predicates batch 2 have shape {pred_batch_2.shape}\")\n",
    "        print(f\"x values batch 1 have shape {x_batch_train_1.shape}\")\n",
    "        print(f\"x values batch 2 have shape {x_batch_train_2.shape}\")\n",
    "        print(f\"y values batch 1 have shape {y_batch_train_1.shape}\")\n",
    "        print(f\"y values batch 2 have shape {y_batch_train_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "8c1f30c4-2445-4e23-8687-00f13d21aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch test dataset and prepare for evaluation with custom lusi loss.\n",
    "# Important: Set reminder to true, else B in custom training loop might greater than batch_size of last batch.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((pred_eval_test, x_test, y_test))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "88246712-6dad-4bac-b2cf-d23192a3a068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch dimensions for batch number 0: (TensorShape([3]), TensorShape([28, 28]), TensorShape([]))\n",
      "Test batch dimensions for batch number 0: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Train batch dimensions for batch number 1: (TensorShape([3]), TensorShape([28, 28]), TensorShape([]))\n",
      "Test batch dimensions for batch number 1: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "i = 0\n",
    "for b, b_ in zip(train_dataset, test_dataset):\n",
    "    if i < 2:\n",
    "        print(f\"Train batch dimensions for batch number {i}: {b[0].shape, b[1].shape, b[2].shape}\")\n",
    "        print(f\"Test batch dimensions for batch number {i}: {b_[0].shape, b_[1].shape, b_[2].shape}\")\n",
    "        i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "977046a9-d7b3-4b28-adae-059e5cd0e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and testset for baseline model\n",
    "train_dataset_baseline = tf.data.Dataset.from_tensor_slices((x_train_2d, y_train))\n",
    "train_dataset_baseline = train_dataset_baseline.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset_baseline = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset_baseline = test_dataset_baseline.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20b39cde-d74d-4c82-94a6-740389082662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch dimensions for batch number 0: (TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Test batch dimensions for batch number 0: (TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Train batch dimensions for batch number 1: (TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Test batch dimensions for batch number 1: (TensorShape([64, 28, 28]), TensorShape([64]))\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "i = 0\n",
    "for b, b_ in zip(train_dataset_baseline, test_dataset_baseline):\n",
    "    if i < 2:\n",
    "        print(f\"Train batch dimensions for batch number {i}: {b[0].shape, b[1].shape}\")\n",
    "        print(f\"Test batch dimensions for batch number {i}: {b_[0].shape, b_[1].shape}\")\n",
    "        i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c7152-148d-4f09-919b-7223530e3d1b",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ed40f-8c58-490c-900f-db84d7517514",
   "metadata": {},
   "source": [
    "### Baseline model - standard neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "5937f999-a1b1-4a34-b5c4-9930fbe452a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "baseline_bin_class = keras.Sequential(\n",
    "[\n",
    "    layers.Flatten(input_shape=(28,28)),\n",
    "    layers.Dense(100, activation=\"relu\", name=\"hidden_layer_1\"),\n",
    "    # layers.Dense(500, activation=\"relu\", name=\"hidden_layer_2\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\") # interpret output as prob. for class 1\n",
    "    # layers.Dense(1, name=\"output_layer\", activation=\"relu\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "84aeb4ac-3c84-4820-b9e6-68ea3fb5c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_bin_class.compile(\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    # loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # loss=keras.losses.binary_crossentropy(),\n",
    "    loss = keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy(), \"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "3aa98851-3b47-4886-98b0-dbe71d67924d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_18 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " hidden_layer_1 (Dense)      (None, 100)               78500     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,601\n",
      "Trainable params: 78,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "baseline_bin_class.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "daa2ee3f-830b-4904-8e43-bf98585aaa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0530 - binary_accuracy: 0.9795 - accuracy: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05300832539796829, 0.9795204997062683, 0.9795204997062683]"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate baseline model on test set with no training.\n",
    "# baseline_bin_class.evaluate(x_test, y_test, batch_size=x_test.shape[0])\n",
    "baseline_bin_class.evaluate(size_m.test_data[0], size_m.test_data[1], batch_size=size_m.test_data[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "184e8d3b-80cc-42e9-b2cb-83f5940d81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = np.mean(np.round(baseline_bin_class(x_test)[0]) == y_test)\n",
    "temp = np.mean(tf.round(baseline_bin_class(x_test)[:, 0]) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "133b8a6c-accf-4feb-9dfa-4d73605b9152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6398601398601399"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "bf022a01-2542-454e-9a18-c20005070158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "190/190 [==============================] - 0s 964us/step - loss: 0.2655 - binary_accuracy: 0.9520 - accuracy: 0.9520\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 998us/step - loss: 0.1045 - binary_accuracy: 0.9787 - accuracy: 0.9787\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.0760 - binary_accuracy: 0.9817 - accuracy: 0.9817\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.0629 - binary_accuracy: 0.9844 - accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.0550 - binary_accuracy: 0.9859 - accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.0496 - binary_accuracy: 0.9866 - accuracy: 0.9866\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.0456 - binary_accuracy: 0.9873 - accuracy: 0.9873\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.0424 - binary_accuracy: 0.9877 - accuracy: 0.9877\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.0399 - binary_accuracy: 0.9883 - accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.0378 - binary_accuracy: 0.9892 - accuracy: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab524220>"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train baseline model for 10 epochs.\n",
    "baseline_bin_class.fit(x_train_2d, y_train, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3f5dbb2-451d-4fad-ba03-b7e94ea17f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0530 - binary_accuracy: 0.9800 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.053045302629470825, 0.9800199866294861, 0.9800199866294861]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate trained baseline model on test set.\n",
    "baseline_bin_class.evaluate(x_test, y_test, batch_size=x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa595e00-15da-4fba-99fd-b4305b1abe36",
   "metadata": {},
   "source": [
    "#### Remarks:\n",
    "One can recognize an improvement during training as well in the pre training evaluation score and the post training eval score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71df26-7325-4758-85da-0a98ef608f62",
   "metadata": {},
   "source": [
    "### Custom model - standard neural net with custom LUSI training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "10337808-0571-461c-9482-df81c1ccf421",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = tf.cast(tf.linalg.diag(np.ones(len(preds))), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "c3e506f8-3c1e-437f-b242-dd18e5d9ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "d215167b-ca4f-4fde-a6c4-c001b7b8518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The predicat evaluations are part of the dataset, thus predicates=None\n",
    "lusi_net = lal.LusiModel(m_inner_prod=weight_matrix)\n",
    "lusi_net.add_optimizer(tf.keras.optimizers.SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "84a88f79-9632-423e-93c4-c88361622e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_20 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " hidden_layer_01 (Dense)     (None, 100)               78500     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,601\n",
      "Trainable params: 78,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lusi_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "22df208f-040b-45f9-ba66-5f28abecd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify some evaluation metrics for custom model\n",
    "eval_metrics = [modify_metric(tf.keras.metrics.BinaryAccuracy(name=\"Binary Accuracy\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.FalsePositives(name=\"False Positives\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.FalseNegatives(name=\"False Negatives\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.Precision(name=\"Precision\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.Recall(name=\"Recall\"), \"pred_and_true\"),\n",
    "                # modify_metric(tf.keras.metrics.Mean(name=\"Mean\"), \"loss\"),\n",
    "                # modify_metric(tf.keras.metrics.Accuracy(), \"pred_and_true\")\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "ecf37966-71eb-4aa0-b381-ed03fdc2f584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for eval_metric in eval_metrics:\n",
    "    eval_metric.reset_state()\n",
    "    print(eval_metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "2266b0ab-bb88-4703-8070-d321b57a4195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.964036>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=41.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=31.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.9583333>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.9681725>)]"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.evaluate(size_s.test_data, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "43747dd4-3d1c-4349-8002-e35589305541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2002, 28, 28), (2002,))"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_s.test_data[0].shape, size_s.test_data[1].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "5752e274-bb3d-4167-8608-ff3b4992d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: -1.1592\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.8662\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: -0.7866\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.3673\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: -1.1022\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.2539\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: -0.8287\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1920\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: -0.6916\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1425\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: -0.4747\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1145\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: -0.4020\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1015\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: -0.3852\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0393\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: -0.2666\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0659\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: -0.3054\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0554\n",
      "Seen so far: 6464 samples\n"
     ]
    }
   ],
   "source": [
    "lusi_net.train_correct(size_l.train_data_batched_p, num_epochs=10, train_metrics=eval_metrics)\n",
    "# lusi_net.train_correct(train_batch, num_epochs=10, train_metrics=eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "52a5621b-5551-4b78-89eb-077bfdbc82ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.964036>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=41.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=31.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.9583333>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.9681725>)]"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.evaluate(size_s.test_data, eval_metrics)\n",
    "#lusi_net.evaluate((x_test, y_test), eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "3e82e571-a5f3-46a7-befe-069cbaa82990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2002, 28, 28), (2002,))"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_l.test_data[0].shape, size_l.test_data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "d2b2539a-0dd4-49b3-ab27-e60e9388f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lusi_net.evaluate_testset(x_test, y_test, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "4591449d-f2c2-4335-b253-c0dc8f1eca16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.9642137>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=41.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=30.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.9580777>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.9689762>)]"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2604d878-7123-4ad8-9c11-6cfc85d55f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4020979020979021"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 1- (902 + 295)/2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "63601413-c2c8-47d7-b53a-2be515bc6779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.2998992>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=562.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=827.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.1994302>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.14477766>),\n",
       " ('accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.2998992>)]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre training evaluation on test dataset (Calculate scores for each batch and average over batches)\n",
    "# Caution: Evaluation for 'Mean' metric not yet implemented.\n",
    "lusi_net.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "07e32cd2-371e-44ee-9e91-3131d318c6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 3), (64, 28, 28), (64,)), types: (tf.float32, tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "b6a39b2f-f205-422c-9538-9802f612de8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3006993006993007"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test_temp = lusi_net.predict(x_test)\n",
    "y_pred_test_temp = np.asarray([j[0] for j in y_pred_test_temp])\n",
    "y_pred_test_temp\n",
    "np.mean(np.round(y_pred_test_temp) ==  y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "92046e91-c76e-4b34-af09-9982880fd0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: -1.1331\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.9742\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: -0.8624\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.5927\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: -1.0895\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1699\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: -0.6861\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0951\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: -0.8297\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1503\n",
      "Seen so far: 6464 samples\n"
     ]
    }
   ],
   "source": [
    "lusi_net.train_correct(train_batch, 5, train_metrics=eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ec3e8706-1d66-4f46-ace7-c736c44b3ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.95254743>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=46.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=49.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.95262617>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.949692>),\n",
       " ('accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.95254743>)]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.evaluate((x_test, y_test), eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "65041f78-dc73-4a58-9830-b0825661f66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525474525474525"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test_temp = lusi_net.predict(x_test)\n",
    "y_pred_test_temp = np.asarray([j[0] for j in y_pred_test_temp])\n",
    "y_pred_test_temp\n",
    "np.mean(np.round(y_pred_test_temp) ==  y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "8b3b716e-5b6e-43f0-88c4-70f562887325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8896103896103896"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 221/2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "676d1b4b-e09d-43fb-a3ff-5ead78d12482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.952621>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=45.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=49.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.95327103>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.9493278>),\n",
       " ('accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.952621>)]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "22731bd7-b8a1-48a8-97fc-bea1b0789d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525474525474525"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (46+49)/2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c0551b2-ede3-42ae-ba76-b1c52ac16c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train custom model for 10 epochs\n",
    "# lusi_net.train(train_dataset, 10, train_metrics=eval_metrics,  batch_1_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b6914d15-b608-4092-a723-0e5137119977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "fc76088a-f546-4ca4-bf6e-69a21997050b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorSliceDataset' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [299]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorSliceDataset' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "train_dataset.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "649598ce-5eaf-40e4-98e2-fb9d08a28827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(train_dataset, tf.data.Dataset)\n",
    "isinstance(x_test, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "082fa42b-508e-4adf-8bb0-622ccd1a1a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch -1 -----\n",
      "Binary Accuracy: 0.29449981451034546\n",
      "False Positives: 562.0\n",
      "False Negatives: 930.0\n",
      "Precision: 0.2161785215139389\n",
      "Recall: 0.1428571492433548\n",
      "accuracy: 0.29019981622695923\n",
      "----- Epoch 0 -----\n",
      "Binary Accuracy: 0.7587069272994995\n",
      "False Positives: 3986.0\n",
      "False Negatives: 1106.0\n",
      "Precision: 0.7435006499290466\n",
      "Recall: 0.912638247013092\n",
      "accuracy: 0.7903319001197815\n",
      "----- Epoch 1 -----\n",
      "Binary Accuracy: 0.9079453945159912\n",
      "False Positives: 1608.0\n",
      "False Negatives: 445.0\n",
      "Precision: 0.8749416470527649\n",
      "Recall: 0.9619495272636414\n",
      "accuracy: 0.907945454120636\n",
      "----- Epoch 2 -----\n",
      "Binary Accuracy: 0.9568645358085632\n",
      "False Positives: 822.0\n",
      "False Negatives: 140.0\n",
      "Precision: 0.9336133003234863\n",
      "Recall: 0.988034188747406\n",
      "accuracy: 0.9568648338317871\n",
      "----- Epoch 3 -----\n",
      "Binary Accuracy: 0.9620657563209534\n",
      "False Positives: 729.0\n",
      "False Negatives: 117.0\n",
      "Precision: 0.9407846927642822\n",
      "Recall: 0.9899991154670715\n",
      "accuracy: 0.9620661735534668\n",
      "----- Epoch 4 -----\n",
      "Binary Accuracy: 0.9634556174278259\n",
      "False Positives: 688.0\n",
      "False Negatives: 127.0\n",
      "Precision: 0.9438779950141907\n",
      "Recall: 0.989143431186676\n",
      "accuracy: 0.9634562134742737\n"
     ]
    }
   ],
   "source": [
    "# Inspection of training progress\n",
    "# Epoch -1 is evaluation before first gradient update in epoch 0\n",
    "for j,e in enumerate(lusi_net.epoch_train_metrics_results):\n",
    "    print(f\"----- Epoch {j-1} -----\")\n",
    "    for i in e:\n",
    "        print(f\"{i[0]}: {i[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "ef45af87-534c-49e7-95d9-b4b2272a98f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.9521169>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=46.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=49.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.9522326>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.9492754>),\n",
       " ('accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.9521169>)]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "21408e22-7ff1-499e-93fd-c64910a08a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "lusi_net_test_pred = np.round(lusi_net.predict(x_test))\n",
    "preds_y_test = np.asarray([j[0] for j in lusi_net_test_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "0aeaa416-2b6c-462f-81c1-07271f8b8c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6748251748251748"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- (22 + 629)/2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "86ad6a34-2308-40f2-8abc-8510fe7e58c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2002,)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "e1608cc3-3b89-486c-acef-dcd7462dc38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3006993006993007"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds_y_test == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9f961-6373-4755-8114-bf0c37d38bed",
   "metadata": {},
   "source": [
    "#### Visual validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "fef05ff4-7e6f-4941-ad26-1e691af959ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_indices = np.random.randint(0, high=x_test.shape[0], size=20).reshape(5,4)\n",
    "fig, ax = plt.subplots(nrows=5, ncols=4, figsize=(10,10))\n",
    "fig.figsize=(10,10)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        ax[i,j].imshow(x_test[random_indices[i,j]])\n",
    "        ax[i,j].set_title(f\"pred: {lusi_net_test_pred[random_indices[i,j]][0]}, true: {y_test[random_indices[i,j]]}\")\n",
    "        ax[i,j].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ad510c06-63e7-4513-80fe-4f240a1dc6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'hidden_layer_01/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       " array([[ 0.01029615,  0.07308923,  0.0528736 , ...,  0.01764344,\n",
       "          0.03428844,  0.06806841],\n",
       "        [ 0.04321082, -0.03620856, -0.07285321, ...,  0.00256582,\n",
       "          0.01069878,  0.01379132],\n",
       "        [-0.01839224, -0.00344887, -0.04425785, ..., -0.03740519,\n",
       "          0.0312849 , -0.04990429],\n",
       "        ...,\n",
       "        [-0.06186682,  0.0360487 ,  0.07773726, ..., -0.03847785,\n",
       "         -0.07957546, -0.02448065],\n",
       "        [ 0.05378409, -0.07762517,  0.04541375, ...,  0.03921954,\n",
       "          0.07320769,  0.00610677],\n",
       "        [ 0.05557923, -0.00094198, -0.05384734, ..., -0.02304952,\n",
       "          0.0453769 , -0.02132869]], dtype=float32)>,\n",
       " <tf.Variable 'hidden_layer_01/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([ 2.26809527e-04,  3.96134565e-03, -4.38527612e-04, -5.05398260e-04,\n",
       "         4.54691658e-03, -2.63975060e-04, -2.56159110e-04, -3.66585399e-03,\n",
       "        -8.84142704e-03,  2.18607159e-03, -4.28816769e-03,  1.76143716e-04,\n",
       "        -5.57816471e-04,  1.36483917e-02, -2.47226958e-03, -1.71850005e-03,\n",
       "         2.52297614e-03,  2.22494127e-03, -8.80592153e-04,  1.33114445e-04,\n",
       "         1.41630108e-02, -8.70910997e-04, -1.53928029e-03, -4.77380725e-03,\n",
       "         3.65213817e-03,  2.15177480e-02, -5.71892085e-03,  6.18357025e-03,\n",
       "        -6.06950256e-04, -5.06683951e-04,  1.69775949e-03, -4.95205459e-04,\n",
       "         8.21010035e-04, -1.08476041e-03,  5.62768430e-04, -1.39365136e-03,\n",
       "         1.41739380e-03,  9.17178520e-04, -3.93974260e-05,  4.04950231e-03,\n",
       "         4.11294075e-03, -3.17837740e-03, -2.10375572e-03,  6.43259007e-03,\n",
       "        -1.21001285e-05,  5.98589366e-04,  1.64643154e-02, -1.87751127e-03,\n",
       "        -1.63302396e-03,  5.18971262e-03,  1.35330921e-02,  2.92126671e-04,\n",
       "        -9.06071276e-04, -2.06274053e-04,  3.36102606e-03, -5.01740607e-04,\n",
       "        -3.01522948e-03, -6.06079912e-03,  2.09781546e-02, -1.14404783e-03,\n",
       "        -5.58817293e-03, -2.30286340e-03, -7.16997718e-04, -5.08583151e-03,\n",
       "         8.02360754e-03, -1.15097570e-03,  8.72854237e-03, -6.05636509e-04,\n",
       "         1.77481398e-03, -1.33668625e-04,  3.48352653e-04, -3.97695258e-04,\n",
       "        -4.24364535e-03, -1.15601555e-03, -4.16563504e-04,  4.14360431e-04,\n",
       "        -7.40939938e-03, -1.18069362e-03,  1.54637572e-04,  1.74802188e-02,\n",
       "        -3.29329330e-03,  6.20836799e-04,  2.54564662e-03,  5.64347161e-03,\n",
       "        -1.63309902e-04, -2.58819479e-03,  1.96071453e-02,  5.23259165e-04,\n",
       "         5.87213319e-04, -8.53157311e-04,  6.93565793e-03, -2.83122621e-03,\n",
       "        -4.70332615e-03, -3.29470588e-03, -1.00467249e-03,  1.20383564e-04,\n",
       "        -5.64512593e-05,  1.23781606e-03, -8.12349608e-04, -3.27170826e-03],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'output_layer/kernel:0' shape=(100, 1) dtype=float32, numpy=\n",
       " array([[ 0.11114368],\n",
       "        [-0.2036928 ],\n",
       "        [-0.09194616],\n",
       "        [ 0.03443073],\n",
       "        [ 0.21001953],\n",
       "        [-0.09168968],\n",
       "        [ 0.13674422],\n",
       "        [ 0.17293061],\n",
       "        [ 0.17219798],\n",
       "        [ 0.19200025],\n",
       "        [-0.15656388],\n",
       "        [ 0.04083515],\n",
       "        [-0.0168728 ],\n",
       "        [-0.24002966],\n",
       "        [ 0.02326028],\n",
       "        [-0.07635178],\n",
       "        [-0.06430998],\n",
       "        [ 0.17660926],\n",
       "        [ 0.03497497],\n",
       "        [-0.15011287],\n",
       "        [-0.22275603],\n",
       "        [ 0.30111793],\n",
       "        [ 0.12796466],\n",
       "        [ 0.20043823],\n",
       "        [-0.09060262],\n",
       "        [-0.26549476],\n",
       "        [ 0.1879256 ],\n",
       "        [ 0.2169814 ],\n",
       "        [ 0.00280541],\n",
       "        [ 0.00553943],\n",
       "        [ 0.25241753],\n",
       "        [ 0.00722321],\n",
       "        [-0.11566548],\n",
       "        [-0.13172092],\n",
       "        [-0.03703616],\n",
       "        [ 0.11718238],\n",
       "        [-0.05979731],\n",
       "        [ 0.11927122],\n",
       "        [ 0.23473883],\n",
       "        [ 0.12576611],\n",
       "        [ 0.09027097],\n",
       "        [ 0.08634842],\n",
       "        [ 0.0420751 ],\n",
       "        [-0.2367859 ],\n",
       "        [-0.1090173 ],\n",
       "        [ 0.04510849],\n",
       "        [-0.23268801],\n",
       "        [ 0.12269735],\n",
       "        [ 0.03582183],\n",
       "        [-0.24701343],\n",
       "        [-0.24492319],\n",
       "        [ 0.143189  ],\n",
       "        [ 0.14147264],\n",
       "        [-0.07677127],\n",
       "        [ 0.17240363],\n",
       "        [-0.00275729],\n",
       "        [ 0.23690161],\n",
       "        [ 0.08683027],\n",
       "        [-0.29086998],\n",
       "        [-0.16757733],\n",
       "        [ 0.21848556],\n",
       "        [ 0.13875453],\n",
       "        [-0.06372794],\n",
       "        [ 0.23294646],\n",
       "        [-0.20074776],\n",
       "        [ 0.019244  ],\n",
       "        [-0.16055378],\n",
       "        [ 0.0957694 ],\n",
       "        [-0.11775611],\n",
       "        [ 0.01437548],\n",
       "        [ 0.0470678 ],\n",
       "        [ 0.00532391],\n",
       "        [ 0.24100648],\n",
       "        [ 0.20964393],\n",
       "        [ 0.1010114 ],\n",
       "        [-0.02088319],\n",
       "        [ 0.22716816],\n",
       "        [ 0.09422396],\n",
       "        [-0.11323582],\n",
       "        [-0.2605425 ],\n",
       "        [ 0.05846438],\n",
       "        [-0.1546749 ],\n",
       "        [-0.04887423],\n",
       "        [-0.12644652],\n",
       "        [-0.02363356],\n",
       "        [-0.06631897],\n",
       "        [-0.2827494 ],\n",
       "        [-0.02738449],\n",
       "        [ 0.03367053],\n",
       "        [ 0.03189033],\n",
       "        [-0.13869171],\n",
       "        [ 0.2338955 ],\n",
       "        [-0.15246318],\n",
       "        [ 0.0699367 ],\n",
       "        [ 0.00265309],\n",
       "        [ 0.02052687],\n",
       "        [-0.00625603],\n",
       "        [-0.02872088],\n",
       "        [ 0.0209651 ],\n",
       "        [ 0.09216578]], dtype=float32)>,\n",
       " <tf.Variable 'output_layer/bias:0' shape=(1,) dtype=float32, numpy=array([-0.04689331], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.watches_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7ad8f282-b639-400a-bc0e-cb42127d1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = (lusi_net.model_weight_list[4][1][0] - lusi_net.model_weight_list[15][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9f728335-c28f-4250-8159-48d55f5ee10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0033567557\n",
      "-0.004465893\n"
     ]
    }
   ],
   "source": [
    "print(np.max(temp[temp != 0]))\n",
    "print(np.min(temp[temp != 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a4019b88-457c-4171-b06d-c94e6edc5e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 4.8890710e-05,  3.0188531e-02, -4.0214725e-02, ...,\n",
       "         -1.3065308e-02, -2.8753571e-02, -4.9196303e-02],\n",
       "        [-7.3631488e-02,  4.3032289e-02, -6.9208182e-02, ...,\n",
       "         -7.8303888e-02,  2.5965855e-02,  5.5982769e-02],\n",
       "        [ 4.7780767e-02, -6.9650389e-02, -3.1469338e-02, ...,\n",
       "          1.7053321e-02, -2.0180274e-02,  6.0287729e-02],\n",
       "        ...,\n",
       "        [ 4.6156347e-02, -1.6654171e-02, -1.3102941e-02, ...,\n",
       "          3.8317069e-02,  4.9839109e-02, -4.5718636e-02],\n",
       "        [-5.2456081e-02,  7.4608058e-02, -2.8712895e-02, ...,\n",
       "         -2.5966190e-02, -2.2572141e-02, -4.1668400e-02],\n",
       "        [ 7.1549192e-02,  1.4410384e-02, -4.1738898e-02, ...,\n",
       "         -5.7290137e-02,  4.4993132e-02,  1.8160544e-02]], dtype=float32),\n",
       " array([ 5.7783659e-04, -1.3924793e-03, -5.2779360e-04, -4.4235124e-04,\n",
       "        -1.4338095e-03, -5.7914876e-05,  1.1531371e-02, -2.4699224e-03,\n",
       "         2.2904804e-02,  5.6161243e-05,  3.2234148e-04, -4.1506483e-04,\n",
       "         4.5874060e-04,  1.7970765e-03,  4.4022123e-03, -3.0980368e-06,\n",
       "        -2.0375004e-04,  4.7427402e-03,  6.3437212e-04, -5.5768522e-03,\n",
       "        -1.5085543e-03, -2.9552225e-03,  3.4754831e-04,  3.2967711e-03,\n",
       "        -4.7435886e-03,  1.2063422e-02,  1.8547284e-03,  1.0513941e-02,\n",
       "         3.2484033e-03, -2.0468934e-03,  2.8461393e-03,  1.1244617e-02,\n",
       "         8.5363043e-03, -7.7896955e-04, -1.7941325e-03,  2.5085641e-02,\n",
       "         5.9913431e-04, -7.9686817e-04,  3.1058672e-03,  8.7509362e-04,\n",
       "         4.9461154e-03,  2.9542097e-03,  5.6075925e-05, -4.9906652e-03,\n",
       "        -1.9305777e-03, -2.6764697e-03, -1.1387613e-03,  1.4760866e-04,\n",
       "         3.4878922e-05, -1.7882745e-04, -1.9738158e-04,  6.7975646e-04,\n",
       "         1.4648387e-03, -2.7172966e-04, -3.6959123e-04,  1.7963398e-02,\n",
       "         2.8940805e-04,  3.7509955e-03, -4.0028826e-03, -1.0417402e-03,\n",
       "        -1.7033350e-04,  2.6266321e-03,  1.1889829e-03, -1.4541231e-03,\n",
       "        -1.6932978e-03, -6.5186555e-03,  1.5757494e-02,  3.0340687e-03,\n",
       "         3.5254229e-04,  4.0275245e-03, -1.8161288e-03, -3.3445877e-03,\n",
       "         2.4918213e-03, -8.3336898e-04, -4.4866125e-03,  1.4168575e-03,\n",
       "        -4.0953145e-03,  1.8342107e-04, -2.7800135e-03,  2.5343241e-03,\n",
       "        -2.1112805e-06,  4.8032273e-03, -4.4013276e-03,  4.4369299e-04,\n",
       "         4.7371513e-04,  7.6719152e-04,  1.2135681e-02,  1.0378398e-02,\n",
       "        -4.1813413e-03,  9.2546071e-04,  1.2803325e-02,  3.4975132e-04,\n",
       "        -3.1957042e-03,  3.5371357e-03,  1.7198659e-03, -1.0569824e-03,\n",
       "        -9.2050852e-04,  1.3801064e-03,  8.4746098e-03, -5.1822774e-03],\n",
       "       dtype=float32),\n",
       " array([[-0.20059454],\n",
       "        [ 0.03447524],\n",
       "        [ 0.00881702],\n",
       "        [-0.0113197 ],\n",
       "        [-0.03213465],\n",
       "        [ 0.03818565],\n",
       "        [-0.2387995 ],\n",
       "        [-0.10877749],\n",
       "        [-0.30535737],\n",
       "        [ 0.2031484 ],\n",
       "        [ 0.15825436],\n",
       "        [ 0.00679056],\n",
       "        [-0.03286299],\n",
       "        [ 0.08037402],\n",
       "        [ 0.20356688],\n",
       "        [-0.02885782],\n",
       "        [ 0.00844176],\n",
       "        [-0.11429662],\n",
       "        [ 0.21479481],\n",
       "        [ 0.0396217 ],\n",
       "        [ 0.06942929],\n",
       "        [-0.04426892],\n",
       "        [ 0.15035571],\n",
       "        [-0.23991224],\n",
       "        [-0.2075693 ],\n",
       "        [-0.2132185 ],\n",
       "        [ 0.08874245],\n",
       "        [-0.23193912],\n",
       "        [ 0.0690214 ],\n",
       "        [-0.0965923 ],\n",
       "        [ 0.17115436],\n",
       "        [-0.15875062],\n",
       "        [-0.15434223],\n",
       "        [ 0.0041569 ],\n",
       "        [-0.1961741 ],\n",
       "        [-0.28804097],\n",
       "        [-0.02725314],\n",
       "        [-0.21237892],\n",
       "        [-0.10873495],\n",
       "        [-0.13487828],\n",
       "        [ 0.17008388],\n",
       "        [ 0.17814574],\n",
       "        [ 0.2293996 ],\n",
       "        [-0.19508651],\n",
       "        [ 0.07829114],\n",
       "        [ 0.17102265],\n",
       "        [-0.03923079],\n",
       "        [ 0.05440478],\n",
       "        [-0.00807561],\n",
       "        [-0.01610262],\n",
       "        [ 0.14052862],\n",
       "        [-0.05261081],\n",
       "        [-0.09381764],\n",
       "        [ 0.001239  ],\n",
       "        [ 0.02782851],\n",
       "        [-0.2866566 ],\n",
       "        [-0.2208907 ],\n",
       "        [-0.15664367],\n",
       "        [ 0.12559755],\n",
       "        [ 0.11959109],\n",
       "        [-0.06849486],\n",
       "        [-0.07593989],\n",
       "        [-0.03343773],\n",
       "        [ 0.04632038],\n",
       "        [ 0.13255486],\n",
       "        [-0.22175358],\n",
       "        [-0.30275348],\n",
       "        [-0.05944433],\n",
       "        [ 0.15039371],\n",
       "        [-0.15730223],\n",
       "        [ 0.03108528],\n",
       "        [ 0.08760694],\n",
       "        [ 0.0612407 ],\n",
       "        [ 0.19019397],\n",
       "        [ 0.11720552],\n",
       "        [ 0.10985125],\n",
       "        [ 0.20166878],\n",
       "        [ 0.03487407],\n",
       "        [ 0.17331082],\n",
       "        [-0.09846546],\n",
       "        [ 0.01150913],\n",
       "        [-0.18528467],\n",
       "        [-0.05146036],\n",
       "        [ 0.15840809],\n",
       "        [ 0.15176463],\n",
       "        [ 0.05976834],\n",
       "        [-0.23333915],\n",
       "        [-0.25489405],\n",
       "        [ 0.08205753],\n",
       "        [-0.05855844],\n",
       "        [-0.17998405],\n",
       "        [-0.23211026],\n",
       "        [ 0.10358115],\n",
       "        [ 0.0624211 ],\n",
       "        [-0.05946539],\n",
       "        [ 0.16713949],\n",
       "        [ 0.03025427],\n",
       "        [ 0.18678224],\n",
       "        [-0.1919475 ],\n",
       "        [ 0.09823414]], dtype=float32),\n",
       " array([-0.01813001], dtype=float32)]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "147f5b15-83c6-4324-9621-01d27ad77f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 3),\n",
       " ListWrapper([array([[-0.03290785, -0.0049599 , -0.06872204, ..., -0.02190971,\n",
       "          0.04855919,  0.048613  ],\n",
       "        [-0.04266789, -0.03542301,  0.02982783, ..., -0.06789184,\n",
       "          0.01476679,  0.01816675],\n",
       "        [-0.0708926 ,  0.00394389,  0.0236842 , ...,  0.05096431,\n",
       "         -0.05892266,  0.06849761],\n",
       "        ...,\n",
       "        [ 0.0201686 ,  0.04717921,  0.0217082 , ..., -0.0435766 ,\n",
       "         -0.02208497, -0.08158264],\n",
       "        [-0.00258563,  0.05347441,  0.02945437, ..., -0.05903338,\n",
       "          0.02728259,  0.06087816],\n",
       "        [-0.05981946, -0.0771868 , -0.03381646, ...,  0.03348702,\n",
       "         -0.07569855, -0.07999133]], dtype=float32), array([ 4.5682047e-04,  3.8227742e-03,  5.5619900e-04, -5.8357842e-04,\n",
       "        -1.4825790e-04, -1.0391799e-03, -5.1099993e-04, -1.0579149e-03,\n",
       "         1.1329939e-04,  2.3807606e-03, -1.0065484e-03, -2.8342973e-03,\n",
       "         2.6445771e-03, -1.3772832e-03, -3.7042033e-03,  2.5061311e-04,\n",
       "         3.0714814e-03,  1.5233811e-03,  2.2009217e-04, -1.5971886e-03,\n",
       "         2.6499191e-03, -1.3413057e-03,  6.3573971e-05, -3.6084373e-04,\n",
       "         1.8763730e-04, -5.8248108e-05, -2.9737495e-03,  2.0344094e-05,\n",
       "        -6.7593163e-04, -6.2817743e-04, -2.4301907e-04, -9.9065085e-04,\n",
       "         1.2395054e-04, -3.5566662e-03, -1.2225637e-03, -3.2049608e-03,\n",
       "         3.1158638e-06, -9.0815818e-05, -3.3026370e-03,  1.5621297e-03,\n",
       "         2.6697428e-03, -1.1554683e-03,  1.6209007e-03, -2.8005075e-05,\n",
       "        -1.3574115e-03,  1.9956450e-03,  1.5416593e-04,  5.7654306e-05,\n",
       "        -6.3696440e-05,  6.6652143e-04,  9.0434594e-04, -6.1110692e-04,\n",
       "        -1.6902912e-03, -5.2607933e-04,  9.4639795e-04,  1.9239815e-04,\n",
       "        -1.5185005e-03, -1.1420096e-03,  3.9816817e-04, -2.9051614e-03,\n",
       "        -1.2108909e-03,  2.3878780e-03,  6.8560580e-04,  4.0148690e-04,\n",
       "        -3.3990114e-03, -2.9790349e-04, -1.6653206e-03,  2.2728657e-03,\n",
       "         4.8393640e-04, -1.7675519e-03,  0.0000000e+00, -7.6890159e-05,\n",
       "         9.3643088e-04, -6.3645793e-04,  3.7040850e-03, -2.2764022e-03,\n",
       "         2.0977540e-03, -2.5538611e-03,  2.9466895e-03, -3.0527196e-06,\n",
       "         1.4500902e-04, -6.9511414e-04, -1.6892872e-04,  5.8412936e-04,\n",
       "        -1.0083901e-03, -6.5598200e-04,  2.1348314e-03,  2.5034384e-03,\n",
       "        -1.0127673e-03,  3.2929944e-05, -3.8744940e-05, -2.5575177e-03,\n",
       "        -2.6410664e-03,  3.0294491e-03,  9.0734160e-05, -1.5040788e-04,\n",
       "         9.8735836e-05, -4.0670825e-06,  2.0955824e-03, -2.4323000e-03],\n",
       "       dtype=float32), array([[ 0.13121857],\n",
       "        [ 0.22575504],\n",
       "        [ 0.03253194],\n",
       "        [-0.03734798],\n",
       "        [-0.09556158],\n",
       "        [-0.03669713],\n",
       "        [-0.01853899],\n",
       "        [-0.13052666],\n",
       "        [ 0.01449126],\n",
       "        [ 0.18308409],\n",
       "        [-0.21304041],\n",
       "        [-0.14429992],\n",
       "        [ 0.1378451 ],\n",
       "        [-0.13037382],\n",
       "        [-0.19128424],\n",
       "        [ 0.01938209],\n",
       "        [ 0.2116929 ],\n",
       "        [ 0.09089378],\n",
       "        [ 0.21860892],\n",
       "        [-0.13980922],\n",
       "        [ 0.13103084],\n",
       "        [-0.1284826 ],\n",
       "        [ 0.10161945],\n",
       "        [-0.10440513],\n",
       "        [ 0.03061261],\n",
       "        [-0.07495629],\n",
       "        [-0.13401312],\n",
       "        [ 0.00757228],\n",
       "        [-0.18571427],\n",
       "        [-0.22038533],\n",
       "        [-0.06772581],\n",
       "        [-0.13423885],\n",
       "        [ 0.16838598],\n",
       "        [-0.19536674],\n",
       "        [-0.07153244],\n",
       "        [-0.21073766],\n",
       "        [ 0.00455107],\n",
       "        [-0.04436716],\n",
       "        [-0.18767092],\n",
       "        [ 0.11786806],\n",
       "        [ 0.13973896],\n",
       "        [-0.17796785],\n",
       "        [ 0.12903398],\n",
       "        [-0.06859124],\n",
       "        [-0.10590082],\n",
       "        [ 0.16217037],\n",
       "        [ 0.01282494],\n",
       "        [ 0.0095698 ],\n",
       "        [-0.00178477],\n",
       "        [ 0.12057543],\n",
       "        [ 0.15380225],\n",
       "        [-0.21406811],\n",
       "        [-0.07494263],\n",
       "        [-0.14168626],\n",
       "        [ 0.07269055],\n",
       "        [ 0.0162374 ],\n",
       "        [-0.10605794],\n",
       "        [-0.21374543],\n",
       "        [ 0.11038899],\n",
       "        [-0.2352982 ],\n",
       "        [-0.09953342],\n",
       "        [ 0.1228869 ],\n",
       "        [ 0.16573949],\n",
       "        [ 0.02673722],\n",
       "        [-0.1843465 ],\n",
       "        [-0.04793647],\n",
       "        [-0.22232142],\n",
       "        [ 0.13268729],\n",
       "        [ 0.04633215],\n",
       "        [-0.1356253 ],\n",
       "        [ 0.14802474],\n",
       "        [ 0.0021779 ],\n",
       "        [ 0.0523897 ],\n",
       "        [-0.0393163 ],\n",
       "        [ 0.2458623 ],\n",
       "        [-0.16168801],\n",
       "        [ 0.1926384 ],\n",
       "        [-0.14657512],\n",
       "        [ 0.2144982 ],\n",
       "        [-0.06850232],\n",
       "        [ 0.17877112],\n",
       "        [-0.04411238],\n",
       "        [-0.09258682],\n",
       "        [ 0.16119044],\n",
       "        [-0.14939651],\n",
       "        [-0.15641505],\n",
       "        [ 0.23324245],\n",
       "        [ 0.12222251],\n",
       "        [-0.06815768],\n",
       "        [ 0.05076071],\n",
       "        [-0.1288861 ],\n",
       "        [-0.14812304],\n",
       "        [-0.13350536],\n",
       "        [ 0.17576452],\n",
       "        [ 0.0097711 ],\n",
       "        [-0.23278892],\n",
       "        [ 0.13867813],\n",
       "        [-0.08118197],\n",
       "        [ 0.13521992],\n",
       "        [-0.23608017]], dtype=float32), array([0.02248421], dtype=float32)]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.model_weight_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f2c6f-dc9a-447e-a2d1-44e578ae8c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a8c779-613e-4d73-9778-8e44798d662b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4493c80b-15e6-4ec0-a64d-fd44ae849dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c0827-40a0-4568-b88a-0c11c7980285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecaa57d-0dde-4611-93af-5f278f3223ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9fba1d1-f569-49da-8b63-ee10c40520bd",
   "metadata": {},
   "source": [
    "### Temporary Issues - old implementation -> ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d92ab4-14f1-4294-9874-93728067cc5b",
   "metadata": {},
   "source": [
    "**Issue no 1.**\n",
    "\n",
    "Whrend des Trainings kann man einsehen, dass alle Modellparameter des neuronales Netztes vom gradient tape beobachtet werden. Problematisch ist alelrdings, dass man fr die erste Matrix von der Dim (784, 100) des ersten Layers immer 0 als Gradienten erhlt. Die restlichen Gradienten sind nicht 0.\n",
    "\n",
    "**Geklrt!!!** Ist beim neuen Modell nicht mehr so...\n",
    "\n",
    "Trotzdem gut zur Illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ab340e39-66d9-4cad-a46c-60f38cfc3205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.8142556>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=848.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=274.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.83850694>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.9414154>),\n",
       " ('Mean', <tf.Tensor: shape=(), dtype=float32, numpy=-0.24690153>),\n",
       " ('accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.80301964>)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net = lal.LusiModel(predicates=None, weight_matrix=weight_matrix)\n",
    "lusi_net.add_optimizer(tf.keras.optimizers.SGD())\n",
    "lusi_net.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "23c54504-cde3-4405-a68b-fbde8d063f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: -1.1264\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 1.2990\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: -0.6952\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.3608\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: -1.1882\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1167\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: -0.8993\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.2571\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: -0.6263\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1625\n",
      "Seen so far: 6464 samples\n"
     ]
    }
   ],
   "source": [
    "# Train custom model for 10 epochs\n",
    "lusi_net.train_debug(train_dataset, 5, train_metrics=eval_metrics,  batch_1_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2b12abf2-f0a8-4f45-92df-8052c84cbfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " ListWrapper([<tf.Variable 'hidden_layer_01/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       " array([[-0.0370429 ,  0.01856136,  0.01109488, ..., -0.00165075,\n",
       "         -0.04981851, -0.03788538],\n",
       "        [-0.08224574, -0.0169937 , -0.06788497, ..., -0.04744552,\n",
       "         -0.07561758, -0.00373816],\n",
       "        [-0.03309216, -0.0767751 ,  0.02286159, ...,  0.04550548,\n",
       "          0.01688451, -0.04940302],\n",
       "        ...,\n",
       "        [-0.01363045,  0.0018331 ,  0.00059545, ..., -0.05137364,\n",
       "          0.01653846,  0.01442146],\n",
       "        [-0.06955153,  0.06206992, -0.02738059, ...,  0.05478401,\n",
       "          0.02380726,  0.07367747],\n",
       "        [-0.0182959 , -0.0309881 , -0.06341801, ..., -0.08149514,\n",
       "          0.062833  , -0.03134453]], dtype=float32)>, <tf.Variable 'hidden_layer_01/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([ 1.1756525e-02,  1.1458894e-02,  5.1763508e-04,  1.1784678e-03,\n",
       "         2.3810772e-04, -7.2968501e-04,  1.9484211e-02,  6.7639253e-03,\n",
       "        -3.4178586e-03, -2.4401019e-03,  2.8623510e-04,  7.4204719e-03,\n",
       "         1.5536326e-03, -2.0258385e-03,  3.3529053e-04,  2.5974491e-03,\n",
       "        -1.4969126e-03,  1.6573455e-02, -4.5323982e-03,  2.9716271e-03,\n",
       "         4.8708572e-04,  5.5930507e-03, -3.5983135e-03, -1.0562759e-04,\n",
       "         1.9609993e-03,  1.8349327e-03, -2.5730746e-04, -1.4591473e-04,\n",
       "         1.3427201e-03,  5.0848392e-03,  4.2973898e-04, -3.5794675e-03,\n",
       "         3.5118675e-03, -6.2043848e-03, -2.5945613e-03,  5.1732082e-03,\n",
       "         1.7343981e-02,  1.1191043e-02, -2.6499380e-03,  2.8703185e-03,\n",
       "         8.5614342e-03,  3.5229509e-03,  2.6441544e-02, -3.6543347e-03,\n",
       "         2.4459134e-03, -8.7837095e-04,  8.4171846e-04,  6.0139145e-03,\n",
       "         1.0337580e-02, -9.7581424e-04, -1.7199465e-03,  1.4564581e-03,\n",
       "         2.7591756e-03, -7.7038730e-04, -1.1508797e-03,  6.5986286e-03,\n",
       "         6.7398086e-04, -2.2561791e-04, -1.7394340e-03, -1.3837367e-03,\n",
       "        -3.6953874e-03,  1.0374462e-02,  5.9525589e-03, -3.6646444e-03,\n",
       "        -5.0662941e-04, -5.6964490e-03,  2.4167445e-02,  1.4985907e-02,\n",
       "         5.2511133e-03,  4.2648148e-03, -4.6728351e-03,  4.0885637e-04,\n",
       "        -1.6384141e-03, -1.1912041e-03,  1.9252652e-03,  2.4418889e-03,\n",
       "         3.6490342e-04,  1.7552108e-02,  7.9137003e-03, -2.3449191e-03,\n",
       "         1.2359735e-04,  5.5874739e-04,  9.8368176e-04,  5.7364637e-03,\n",
       "        -3.2033779e-05, -1.2231348e-04, -5.5752171e-04,  4.1010650e-03,\n",
       "        -5.0808541e-03, -5.0244424e-03,  6.9714463e-03,  1.3205332e-03,\n",
       "         1.6519537e-02,  1.7806020e-03, -1.2588786e-04,  6.9039705e-04,\n",
       "        -2.7893786e-04,  1.4429733e-04,  2.6917439e-03,  2.9174674e-02],\n",
       "       dtype=float32)>, <tf.Variable 'output_layer/kernel:0' shape=(100, 1) dtype=float32, numpy=\n",
       " array([[-0.1443524 ],\n",
       "        [-0.22699061],\n",
       "        [ 0.21970055],\n",
       "        [ 0.14409913],\n",
       "        [-0.08568639],\n",
       "        [-0.05900043],\n",
       "        [-0.2391376 ],\n",
       "        [-0.09532768],\n",
       "        [ 0.1217924 ],\n",
       "        [ 0.14715287],\n",
       "        [ 0.18344085],\n",
       "        [-0.12719965],\n",
       "        [-0.08246374],\n",
       "        [ 0.19800913],\n",
       "        [-0.06979214],\n",
       "        [-0.14385992],\n",
       "        [ 0.05580479],\n",
       "        [-0.262104  ],\n",
       "        [ 0.05544109],\n",
       "        [-0.12371285],\n",
       "        [-0.02445921],\n",
       "        [-0.14215496],\n",
       "        [-0.23209569],\n",
       "        [ 0.10250475],\n",
       "        [-0.06761727],\n",
       "        [ 0.24072246],\n",
       "        [ 0.08288372],\n",
       "        [ 0.02470307],\n",
       "        [-0.1061181 ],\n",
       "        [-0.07267886],\n",
       "        [-0.01288329],\n",
       "        [ 0.06145913],\n",
       "        [-0.08510733],\n",
       "        [ 0.2036936 ],\n",
       "        [ 0.04893029],\n",
       "        [-0.1572463 ],\n",
       "        [-0.24819267],\n",
       "        [-0.16527952],\n",
       "        [-0.15228795],\n",
       "        [-0.15823072],\n",
       "        [-0.23234215],\n",
       "        [ 0.17411757],\n",
       "        [-0.3858018 ],\n",
       "        [ 0.23873602],\n",
       "        [-0.19189593],\n",
       "        [ 0.12776905],\n",
       "        [ 0.2904773 ],\n",
       "        [-0.14846587],\n",
       "        [ 0.18643467],\n",
       "        [ 0.18803091],\n",
       "        [ 0.05906401],\n",
       "        [ 0.2643301 ],\n",
       "        [-0.08028479],\n",
       "        [-0.03403502],\n",
       "        [ 0.17903088],\n",
       "        [ 0.20483057],\n",
       "        [-0.21663392],\n",
       "        [ 0.01739656],\n",
       "        [ 0.00869279],\n",
       "        [-0.03731922],\n",
       "        [ 0.20134187],\n",
       "        [-0.2613973 ],\n",
       "        [ 0.24559656],\n",
       "        [ 0.09046605],\n",
       "        [ 0.11585969],\n",
       "        [ 0.09013831],\n",
       "        [-0.31660527],\n",
       "        [-0.27972597],\n",
       "        [-0.10855892],\n",
       "        [-0.14872704],\n",
       "        [ 0.20137936],\n",
       "        [-0.04332716],\n",
       "        [-0.23831093],\n",
       "        [-0.17837265],\n",
       "        [ 0.18459024],\n",
       "        [ 0.30811912],\n",
       "        [-0.22187622],\n",
       "        [-0.1850531 ],\n",
       "        [-0.15652187],\n",
       "        [ 0.05161695],\n",
       "        [-0.02602001],\n",
       "        [ 0.11888383],\n",
       "        [ 0.10305119],\n",
       "        [ 0.1579868 ],\n",
       "        [ 0.01431876],\n",
       "        [-0.07761158],\n",
       "        [ 0.04689528],\n",
       "        [-0.07021749],\n",
       "        [ 0.20745775],\n",
       "        [ 0.11787716],\n",
       "        [ 0.19249137],\n",
       "        [ 0.08848771],\n",
       "        [-0.25766093],\n",
       "        [-0.09980828],\n",
       "        [ 0.2037708 ],\n",
       "        [ 0.2557336 ],\n",
       "        [-0.00174172],\n",
       "        [-0.0116796 ],\n",
       "        [ 0.11109   ],\n",
       "        [-0.34923473]], dtype=float32)>, <tf.Variable 'output_layer/bias:0' shape=(1,) dtype=float32, numpy=array([-0.05122198], dtype=float32)>]))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.model_weight_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3e24ae78-d1cb-4f4c-b227-8bdfcdd9eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_grad = (lusi_net.gradient_list[0][1][0] - lusi_net.gradient_list[50][1][0]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9ebe9e7f-838b-4eeb-b450-4c248207aca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.086509906"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(diff_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "64905252-f6c9-4a53-bf5c-9b4c06464018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.080651"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(diff_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b0d0a4a4-0bee-44ce-b4b8-899e646a42ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37018,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_grad[diff_grad != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "44fe4fb3-9a78-4eff-ba3f-051e5a1ae108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lusi_net.gradient_list[0][1][0]).numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ef4ef-03b5-41a6-aee1-435e511ccd6f",
   "metadata": {},
   "source": [
    "**Issue no 2.**\n",
    "\n",
    "Der Optimizer fhrt die Gradientenupdates nicht durch. Das Modell scheint aber ja, wie man sieht, dennoch angepasst zu werden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "66a279d6-5dbd-48b7-aae9-be64a4cc82b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for epoch 0 step 0: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'hidden_layer_01/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       "array([[-0.0370429 ,  0.01856136,  0.01109488, ..., -0.00165075,\n",
       "        -0.04981851, -0.03788538],\n",
       "       [-0.08224574, -0.0169937 , -0.06788497, ..., -0.04744552,\n",
       "        -0.07561758, -0.00373816],\n",
       "       [-0.03309216, -0.0767751 ,  0.02286159, ...,  0.04550548,\n",
       "         0.01688451, -0.04940302],\n",
       "       ...,\n",
       "       [-0.01363045,  0.0018331 ,  0.00059545, ..., -0.05137364,\n",
       "         0.01653846,  0.01442146],\n",
       "       [-0.06955153,  0.06206992, -0.02738059, ...,  0.05478401,\n",
       "         0.02380726,  0.07367747],\n",
       "       [-0.0182959 , -0.0309881 , -0.06341801, ..., -0.08149514,\n",
       "         0.062833  , -0.03134453]], dtype=float32)>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Weights for epoch {lusi_net.model_weight_list[1][0][0]} step {lusi_net.model_weight_list[1][0][1]}: \")\n",
    "lusi_net.model_weight_list[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "61e8f855-439e-445a-b4a2-30de30184bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for epoch 2 step 39: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.0370429 ,  0.01856136,  0.01109488, ..., -0.00165075,\n",
       "        -0.04981851, -0.03788538],\n",
       "       [-0.08224574, -0.0169937 , -0.06788497, ..., -0.04744552,\n",
       "        -0.07561758, -0.00373816],\n",
       "       [-0.03309216, -0.0767751 ,  0.02286159, ...,  0.04550548,\n",
       "         0.01688451, -0.04940302],\n",
       "       ...,\n",
       "       [-0.01363045,  0.0018331 ,  0.00059545, ..., -0.05137364,\n",
       "         0.01653846,  0.01442146],\n",
       "       [-0.06955153,  0.06206992, -0.02738059, ...,  0.05478401,\n",
       "         0.02380726,  0.07367747],\n",
       "       [-0.0182959 , -0.0309881 , -0.06341801, ..., -0.08149514,\n",
       "         0.062833  , -0.03134453]], dtype=float32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Weights for epoch {lusi_net.model_weight_list[400][0][0]} step {lusi_net.model_weight_list[40][0][1]}: \")\n",
    "lusi_net.model_weight_list[1][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd479e1-b57a-4306-af5d-31cfa0cd90b5",
   "metadata": {},
   "source": [
    "### Remarks and ToDos 07.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475bf65-f664-4cb4-84ab-a0c993355304",
   "metadata": {},
   "source": [
    "- in Periphery, do not take n_train, n_test as args. Expected to pass train and test set of desired size already\n",
    "- params should be: bs_1, bs_2, preds,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f814a3d-02d6-4cb1-9e1c-3b1c93798429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lusi",
   "language": "python",
   "name": "lusi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
