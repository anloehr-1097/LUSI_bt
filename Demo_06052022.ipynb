{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b2b655-7de3-446f-8784-c894435d97b1",
   "metadata": {},
   "source": [
    "# Demo version 06.05.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03aae76f-f48d-4e21-bf7b-200623da9bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ba554-3321-4077-b745-49eee6dece62",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b6ceea-b147-4310-a1b7-db6ab2e0572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lusi_Andreas_Loehr as lal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87d952d-1014-4b2a-996f-afff0ca9cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functinos into global namespace\n",
    "modify_metric = lal.modify_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4150b-bf8f-4e2d-aadc-6ab6c840153f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8e1d67-3966-488a-88d9-fa6058e3befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset, set batch size.\n",
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bede0435-77c5-464e-85df-063fe307c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep train dataset.\n",
    "eights = x_train[y_train == 8]/255\n",
    "sevens = x_train[y_train == 7]/255\n",
    "\n",
    "y_eights = np.ones(eights.shape[0])\n",
    "y_sevens = np.zeros(sevens.shape[0])\n",
    "\n",
    "# not needed as \n",
    "# eights_flat = np.reshape(eights, (-1, 784))\n",
    "# sevens_flat = np.reshape(sevens, (-1, 784))\n",
    "# x_train = np.concatenate([eights_flat, sevens_flat])\n",
    "\n",
    "x_train_2d = np.concatenate([eights, sevens])\n",
    "y_train = np.concatenate([y_eights, y_sevens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31b6406-d3d6-4274-beff-25aadb8cd2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'eights' data: (5851, 28, 28)\n",
      "Shape of 'sevens' data: (6265, 28, 28)\n",
      "Shape of entire training dataset: (12116, 28, 28)\n",
      "Shape of training dataset labels: (12116,)\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "print(f\"Shape of 'eights' data: {eights.shape}\")\n",
    "print(f\"Shape of 'sevens' data: {sevens.shape}\")\n",
    "print(f\"Shape of entire training dataset: {x_train_2d.shape}\")\n",
    "print(f\"Shape of training dataset labels: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483fe52f-e102-4646-8f9f-bca39dffd778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep test dataset.\n",
    "eights_test = x_test[y_test == 8]/255\n",
    "sevens_test = x_test[y_test == 7]/255\n",
    "\n",
    "y_eights_test = np.ones(eights_test.shape[0])\n",
    "y_sevens_test = np.zeros(sevens_test.shape[0])\n",
    "\n",
    "x_test = np.concatenate([eights_test, sevens_test])\n",
    "y_test = np.concatenate([y_eights_test, y_sevens_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e41debeb-3d32-4070-a804-5088afdb262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'eights' test data: (974, 28, 28)\n",
      "Shape of 'sevens' test data: (1028, 28, 28)\n",
      "Shape of entire test dataset: (2002, 28, 28)\n",
      "Shape of entire test dataset labels: (2002,)\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "print(f\"Shape of 'eights' test data: {eights_test.shape}\")\n",
    "print(f\"Shape of 'sevens' test data: {sevens_test.shape}\")\n",
    "print(f\"Shape of entire test dataset: {x_test.shape}\")\n",
    "print(f\"Shape of entire test dataset labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfb82304-2b07-42da-88ec-a851fedf76ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<function avg_pixel_intensity at 0x19ecb05e0>,\n",
       "       <function weighted_pixel_intesity at 0x19ecb0790>,\n",
       "       functools.partial(<function local_pixel_intensity_single at 0x19ecb0820>, patch=((10, 20), (10, 20)))],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load numpy array of predicate functions\n",
    "preds = lal.phi\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48ffb064-6892-49ea-8eab-a710cc8c2e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:59:53.474637: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predicates on training data\n",
    "pred_eval = lal.apply_predicates_on_data(preds, x_train_2d)\n",
    "pred_eval_test = lal.apply_predicates_on_data(preds, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bc58c7a-9bff-4965-9543-439282feb34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of pred_eval is: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "\n",
      "Shape of pred_eval is: (12116, 3). This is the result of applying 3 predicates on the training data.\n",
      "\n",
      "Shape of pred_eval_test is: (2002, 3). This is the result of applying 3 predicates on the test data.\n",
      "\n",
      "Shape of train dataset is: (12116, 28, 28)\n",
      "Shape of training labels is: (12116,)\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "print(f\"Type of pred_eval is: {type(pred_eval)}\\n\")\n",
    "print(f\"Shape of pred_eval is: {pred_eval.shape}. This is the result of applying {preds.shape[0]} predicates on the training data.\\n\")\n",
    "print(f\"Shape of pred_eval_test is: {pred_eval_test.shape}. This is the result of applying {preds.shape[0]} predicates on the test data.\\n\")\n",
    "print(f\"Shape of train dataset is: {x_train_2d.shape}\")\n",
    "print(f\"Shape of training labels is: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2cf02d6-ddfe-44c5-b3fd-b8844e415bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch training dataset and prepare for training with custom lusi loss.\n",
    "# Important: Set reminder to true, else B in custom training loop might greater than batch_size of last batch.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((pred_eval, x_train_2d, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf92c134-b80f-4358-ba44-b41ca30f493a",
   "metadata": {},
   "source": [
    "### Zipped train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4dd49ff4-8402-4502-aa2b-96191873b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((pred_eval, x_train_2d, y_train))\n",
    "\n",
    "\n",
    "train_dataset_b = train_dataset.shuffle(buffer_size=1024).batch(64, drop_remainder=True)\n",
    "train_dataset_b_prime = train_dataset.shuffle(buffer_size=1024).batch(54, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6d2145db-455b-4478-987a-eb337466b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LusiPeriphery:\n",
    "    def __init__(self, train_data, test_data, model=None, predicates=None, batch_size_1=32, batch_size_2=32) -> None:\n",
    "        \"\"\"\n",
    "        Train and test data in raw form\n",
    "        \"\"\"\n",
    "        \n",
    "    def generate_batch_data(self):\n",
    "        pass\n",
    "    \n",
    "    def set_model(self):\n",
    "        pass\n",
    "    \n",
    "    def set_batch_sizes(self):\n",
    "        pass\n",
    "    \n",
    "    def set_predicates(self):\n",
    "        pass\n",
    "    \n",
    "    def set_total_size(self):\n",
    "        pass    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d99ba949-63f6-4ec2-8c67-8e8de68d7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = tf.data.Dataset.zip((train_dataset_b, train_dataset_b_prime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1f7ad462-f2e2-4bd5-9605-e203a735473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch 1 dimensions for batch number 0: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Train batch 2 dimensions for batch number 0: (TensorShape([54, 3]), TensorShape([54, 28, 28]), TensorShape([54]))\n",
      "Train batch 1 dimensions for batch number 1: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Train batch 2 dimensions for batch number 1: (TensorShape([54, 3]), TensorShape([54, 28, 28]), TensorShape([54]))\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "i = 0\n",
    "for b, b_ in train_batch:\n",
    "    if i < 2:\n",
    "        print(f\"Train batch 1 dimensions for batch number {i}: {b[0].shape, b[1].shape, b[2].shape}\")\n",
    "        print(f\"Train batch 2 dimensions for batch number {i}: {b_[0].shape, b_[1].shape, b_[2].shape}\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6dbf8101-e76c-4064-afcd-0272892eef85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float64, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 2.],\n",
       "       [2., 2., 2.],\n",
       "       [2., 2., 2.],\n",
       "       [2., 2., 2.]])>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable(np.ones(shape=(2,3)))\n",
    "b = tf.Variable(2 * np.ones(shape=(4,3)))\n",
    "c = tf.concat([a,b], axis=0)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7e03f726-af18-46cb-afaa-ad236f6ed140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes for batches of step 0:\n",
      "Predicates batch 1 have shape (64, 3)\n",
      "Predicates batch 2 have shape (54, 3)\n",
      "x values batch 1 have shape (64, 28, 28)\n",
      "x values batch 2 have shape (54, 28, 28)\n",
      "y values batch 1 have shape (64,)\n",
      "y values batch 2 have shape (54,)\n",
      "\n",
      "Shapes for batches of step 1:\n",
      "Predicates batch 1 have shape (64, 3)\n",
      "Predicates batch 2 have shape (54, 3)\n",
      "x values batch 1 have shape (64, 28, 28)\n",
      "x values batch 2 have shape (54, 28, 28)\n",
      "y values batch 1 have shape (64,)\n",
      "y values batch 2 have shape (54,)\n"
     ]
    }
   ],
   "source": [
    "for step, ((pred_batch_1, x_batch_train_1, y_batch_train_1), (pred_batch_2, x_batch_train_2, y_batch_train_2))  in enumerate(train_batch):\n",
    "    if step <= 1:\n",
    "        print(f\"\\nShapes for batches of step {step}:\")\n",
    "        print(f\"Predicates batch 1 have shape {pred_batch_1.shape}\")\n",
    "        print(f\"Predicates batch 2 have shape {pred_batch_2.shape}\")\n",
    "        print(f\"x values batch 1 have shape {x_batch_train_1.shape}\")\n",
    "        print(f\"x values batch 2 have shape {x_batch_train_2.shape}\")\n",
    "        print(f\"y values batch 1 have shape {y_batch_train_1.shape}\")\n",
    "        print(f\"y values batch 2 have shape {y_batch_train_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "691cf7cd-7600-40ed-891a-4ef1803ef7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: (((64, 3), (64, 28, 28), (64,)), ((64, 3), (64, 28, 28), (64,))), types: ((tf.float32, tf.float64, tf.float64), (tf.float32, tf.float64, tf.float64))>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = zip(train_dataset, test_dataset)\n",
    "tf.data.Dataset.zip((train_dataset, test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c1f30c4-2445-4e23-8687-00f13d21aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch test dataset and prepare for evaluation with custom lusi loss.\n",
    "# Important: Set reminder to true, else B in custom training loop might greater than batch_size of last batch.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((pred_eval_test, x_test, y_test))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88246712-6dad-4bac-b2cf-d23192a3a068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch dimensions for batch number 0: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Test batch dimensions for batch number 0: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Train batch dimensions for batch number 1: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Test batch dimensions for batch number 1: (TensorShape([64, 3]), TensorShape([64, 28, 28]), TensorShape([64]))\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "i = 0\n",
    "for b, b_ in zip(train_dataset, test_dataset):\n",
    "    if i < 2:\n",
    "        print(f\"Train batch dimensions for batch number {i}: {b[0].shape, b[1].shape, b[2].shape}\")\n",
    "        print(f\"Test batch dimensions for batch number {i}: {b_[0].shape, b_[1].shape, b_[2].shape}\")\n",
    "        i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "977046a9-d7b3-4b28-adae-059e5cd0e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and testset for baseline model\n",
    "train_dataset_baseline = tf.data.Dataset.from_tensor_slices((x_train_2d, y_train))\n",
    "train_dataset_baseline = train_dataset_baseline.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset_baseline = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset_baseline = test_dataset_baseline.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b39cde-d74d-4c82-94a6-740389082662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch dimensions for batch number 0: (TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Test batch dimensions for batch number 0: (TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Train batch dimensions for batch number 1: (TensorShape([64, 28, 28]), TensorShape([64]))\n",
      "Test batch dimensions for batch number 1: (TensorShape([64, 28, 28]), TensorShape([64]))\n"
     ]
    }
   ],
   "source": [
    "# Dim checks.\n",
    "i = 0\n",
    "for b, b_ in zip(train_dataset_baseline, test_dataset_baseline):\n",
    "    if i < 2:\n",
    "        print(f\"Train batch dimensions for batch number {i}: {b[0].shape, b[1].shape}\")\n",
    "        print(f\"Test batch dimensions for batch number {i}: {b_[0].shape, b_[1].shape}\")\n",
    "        i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c7152-148d-4f09-919b-7223530e3d1b",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ed40f-8c58-490c-900f-db84d7517514",
   "metadata": {},
   "source": [
    "### Baseline model - standard neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5937f999-a1b1-4a34-b5c4-9930fbe452a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "baseline_bin_class = keras.Sequential(\n",
    "[\n",
    "    layers.Flatten(input_shape=(28,28)),\n",
    "    layers.Dense(200, activation=\"relu\", name=\"hidden_layer_1\"),\n",
    "    layers.Dense(500, activation=\"relu\", name=\"hidden_layer_2\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\") # interpret output as prob. for class 1\n",
    "    # layers.Dense(1, name=\"output_layer\", activation=\"relu\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "84aeb4ac-3c84-4820-b9e6-68ea3fb5c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_bin_class.compile(\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    # loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # loss=keras.losses.binary_crossentropy(),\n",
    "    loss = keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy(), \"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3aa98851-3b47-4886-98b0-dbe71d67924d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_26 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " hidden_layer_1 (Dense)      (None, 200)               157000    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 500)               100500    \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 258,001\n",
      "Trainable params: 258,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "baseline_bin_class.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a66dd41b-3aeb-47a4-bced-b63793329a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_extra_dim = tf.expand_dims(y_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "daa2ee3f-830b-4904-8e43-bf98585aaa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7426 - binary_accuracy: 0.4306 - accuracy: 0.4306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7425997257232666, 0.43056944012641907, 0.43056944012641907]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate baseline model on test set with no training.\n",
    "baseline_bin_class.evaluate(x_test, y_test, batch_size=2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "184e8d3b-80cc-42e9-b2cb-83f5940d81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = np.mean(np.round(baseline_bin_class(x_test)[0]) == y_test)\n",
    "temp = np.mean(tf.round(baseline_bin_class(x_test)[:, 0]) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "03f03bd9-f414-41fa-bcb4-1a8e5b0b3cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2002, 1), dtype=float32, numpy=\n",
       "array([[0.56550306],\n",
       "       [0.5742913 ],\n",
       "       [0.5326925 ],\n",
       "       ...,\n",
       "       [0.56120676],\n",
       "       [0.5863214 ],\n",
       "       [0.58924073]], dtype=float32)>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_bin_class(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "83ef3941-6d0f-4179-87c6-3862e9ef777f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2002, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.round(baseline_bin_class(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d17c71ee-1de2-434d-9b96-163e45ac9478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30, 1), dtype=float32, numpy=\n",
       "array([[0.43546903],\n",
       "       [0.43751648],\n",
       "       [0.44127113],\n",
       "       [0.38471434],\n",
       "       [0.41813466],\n",
       "       [0.4396029 ],\n",
       "       [0.41568694],\n",
       "       [0.42027074],\n",
       "       [0.4769171 ],\n",
       "       [0.43574268],\n",
       "       [0.46162042],\n",
       "       [0.46502927],\n",
       "       [0.4351541 ],\n",
       "       [0.45449367],\n",
       "       [0.37283695],\n",
       "       [0.37366986],\n",
       "       [0.38518393],\n",
       "       [0.3809013 ],\n",
       "       [0.4595251 ],\n",
       "       [0.36408085],\n",
       "       [0.40160948],\n",
       "       [0.3419546 ],\n",
       "       [0.4102245 ],\n",
       "       [0.47314692],\n",
       "       [0.45095986],\n",
       "       [0.3600729 ],\n",
       "       [0.44524252],\n",
       "       [0.4331096 ],\n",
       "       [0.41985098],\n",
       "       [0.43876576]], dtype=float32)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_bin_class(x_test)[20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9ab9aad1-b7d6-4644-aa82-195daebe1614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2002, 1])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(y_test, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6924aa31-f84f-4df7-a587-37cd50431736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "91e44afc-50bf-4bb5-8ae7-4b90e57e8086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5134865134865135"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf022a01-2542-454e-9a18-c20005070158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.3107 - binary_accuracy: 0.9185\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1163 - binary_accuracy: 0.9730\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.0820 - binary_accuracy: 0.9790\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.0665 - binary_accuracy: 0.9824\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.0574 - binary_accuracy: 0.9839\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.0511 - binary_accuracy: 0.9858\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.0467 - binary_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.0432 - binary_accuracy: 0.9878\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.0404 - binary_accuracy: 0.9878\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.0382 - binary_accuracy: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19ee13d90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train baseline model for 10 epochs.\n",
    "baseline_bin_class.fit(x_train_2d, y_train, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f5dbb2-451d-4fad-ba03-b7e94ea17f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0518 - binary_accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.051789674907922745, 0.9810189604759216]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate trained baseline model on test set.\n",
    "baseline_bin_class.evaluate(x_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa595e00-15da-4fba-99fd-b4305b1abe36",
   "metadata": {},
   "source": [
    "#### Remarks:\n",
    "One can recognize an improvement during training as well in the pre training evaluation score and the post training eval score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71df26-7325-4758-85da-0a98ef608f62",
   "metadata": {},
   "source": [
    "### Custom model - standard neural net with custom LUSI training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "10337808-0571-461c-9482-df81c1ccf421",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = tf.cast(tf.linalg.diag(np.ones(len(preds))), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c3e506f8-3c1e-437f-b242-dd18e5d9ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d215167b-ca4f-4fde-a6c4-c001b7b8518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The predicat evaluations are part of the dataset, thus predicates=None\n",
    "lusi_net = lal.LusiModel(m_inner_prod=weight_matrix)\n",
    "lusi_net.add_optimizer(tf.keras.optimizers.SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "84a88f79-9632-423e-93c4-c88361622e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_27 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " hidden_layer_01 (Dense)     (None, 100)               78500     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,601\n",
      "Trainable params: 78,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lusi_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "22df208f-040b-45f9-ba66-5f28abecd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify some evaluation metrics for custom model\n",
    "eval_metrics = [modify_metric(tf.keras.metrics.BinaryAccuracy(name=\"Binary Accuracy\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.FalsePositives(name=\"False Positives\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.FalseNegatives(name=\"False Negatives\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.Precision(name=\"Precision\"), \"pred_and_true\"), \n",
    "                modify_metric(tf.keras.metrics.Recall(name=\"Recall\"), \"pred_and_true\"),\n",
    "                modify_metric(tf.keras.metrics.Mean(name=\"Mean\"), \"loss\"),\n",
    "                modify_metric(tf.keras.metrics.Accuracy(), \"pred_and_true\")\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "63601413-c2c8-47d7-b53a-2be515bc6779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.46975806>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=1011.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=41.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.47724923>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.95746887>),\n",
       " ('Mean', <tf.Tensor: shape=(), dtype=float32, numpy=0.0>),\n",
       " ('accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.46975806>)]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre training evaluation on test dataset (Calculate scores for each batch and average over batches)\n",
    "# Caution: Evaluation for 'Mean' metric not yet implemented.\n",
    "lusi_net.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "babc204e-975d-41a0-ba27-83d7c2e3fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_temp = lusi_net.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c0f0321d-d643-4dfb-976b-1514ad880149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4865134865134865"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.round(y_pred_test_temp[0]) ==  y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "92046e91-c76e-4b34-af09-9982880fd0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: -1.1469\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.7085\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: -0.8841\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.4377\n",
      "Seen so far: 6464 samples\n"
     ]
    }
   ],
   "source": [
    "lusi_net.train_correct(train_batch, 2, train_metrics=eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "676d1b4b-e09d-43fb-a3ff-5ead78d12482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.7988911>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=21.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=378.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.9655738>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.6091003>),\n",
       " ('Mean', <tf.Tensor: shape=(), dtype=float32, numpy=0.0>),\n",
       " ('accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.7988911>)]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c0551b2-ede3-42ae-ba76-b1c52ac16c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: -1.2517\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 1.0112\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: -0.5914\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.2662\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: -1.1894\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.4151\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: -0.9961\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.2346\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: -0.9136\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1652\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: -0.6931\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1492\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: -0.3478\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1463\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: -0.3751\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1196\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: -0.4764\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1217\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: -0.2578\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.0274\n",
      "Seen so far: 6464 samples\n"
     ]
    }
   ],
   "source": [
    "# Train custom model for 10 epochs\n",
    "lusi_net.train(train_dataset, 10, train_metrics=eval_metrics,  batch_1_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "082fa42b-508e-4adf-8bb0-622ccd1a1a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch -1 -----\n",
      "Binary Accuracy: 0.39892578125\n",
      "False Positives: 595.0\n",
      "False Negatives: 636.0\n",
      "Precision: 0.3983822166919708\n",
      "Recall: 0.3825242817401886\n",
      "Mean: -0.03911680355668068\n",
      "----- Epoch 0 -----\n",
      "Binary Accuracy: 0.8213778138160706\n",
      "False Positives: 1780.0\n",
      "False Negatives: 735.0\n",
      "Precision: 0.7735944986343384\n",
      "Recall: 0.8921813368797302\n",
      "Mean: 0.012221643701195717\n",
      "----- Epoch 1 -----\n",
      "Binary Accuracy: 0.9293981194496155\n",
      "False Positives: 526.0\n",
      "False Negatives: 328.0\n",
      "Precision: 0.9130434989929199\n",
      "Recall: 0.9439412355422974\n",
      "Mean: -0.09358032792806625\n",
      "----- Epoch 2 -----\n",
      "Binary Accuracy: 0.9661871790885925\n",
      "False Positives: 314.0\n",
      "False Negatives: 95.0\n",
      "Precision: 0.9482702016830444\n",
      "Recall: 0.9837634563446045\n",
      "Mean: -0.10794055461883545\n",
      "----- Epoch 3 -----\n",
      "Binary Accuracy: 0.9685846567153931\n",
      "False Positives: 315.0\n",
      "False Negatives: 65.0\n",
      "Precision: 0.9483691453933716\n",
      "Recall: 0.9888907670974731\n",
      "Mean: -0.10906054824590683\n",
      "----- Epoch 4 -----\n",
      "Binary Accuracy: 0.9702380895614624\n",
      "False Positives: 301.0\n",
      "False Negatives: 59.0\n",
      "Precision: 0.9505990743637085\n",
      "Recall: 0.9899162650108337\n",
      "Mean: -0.10335201025009155\n",
      "----- Epoch 5 -----\n",
      "Binary Accuracy: 0.9705687761306763\n",
      "False Positives: 284.0\n",
      "False Negatives: 72.0\n",
      "Precision: 0.9531584978103638\n",
      "Recall: 0.9876943826675415\n",
      "Mean: -0.09729044139385223\n",
      "----- Epoch 6 -----\n",
      "Binary Accuracy: 0.9719741940498352\n",
      "False Positives: 271.0\n",
      "False Negatives: 68.0\n",
      "Precision: 0.9552361965179443\n",
      "Recall: 0.9883780479431152\n",
      "Mean: -0.09159856289625168\n",
      "----- Epoch 7 -----\n",
      "Binary Accuracy: 0.9707341194152832\n",
      "False Positives: 269.0\n",
      "False Negatives: 85.0\n",
      "Precision: 0.9554266929626465\n",
      "Recall: 0.985472559928894\n",
      "Mean: -0.09447960555553436\n",
      "----- Epoch 8 -----\n",
      "Binary Accuracy: 0.9718915224075317\n",
      "False Positives: 262.0\n",
      "False Negatives: 78.0\n",
      "Precision: 0.9565865993499756\n",
      "Recall: 0.9866689443588257\n",
      "Mean: -0.08183152228593826\n",
      "----- Epoch 9 -----\n",
      "Binary Accuracy: 0.9722222089767456\n",
      "False Positives: 256.0\n",
      "False Negatives: 80.0\n",
      "Precision: 0.9575244784355164\n",
      "Recall: 0.9863271117210388\n",
      "Mean: -0.08289733529090881\n"
     ]
    }
   ],
   "source": [
    "# Inspection of training progress\n",
    "# Epoch -1 is evaluation before first gradient update in epoch 0\n",
    "for j,e in enumerate(lusi_net.epoch_train_metrics_results):\n",
    "    print(f\"----- Epoch {j-1} -----\")\n",
    "    for i in e:\n",
    "        print(f\"{i[0]}: {i[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef45af87-534c-49e7-95d9-b4b2272a98f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.9627016>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=41.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=33.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.9580348>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.9659443>),\n",
       " ('Mean', <tf.Tensor: shape=(), dtype=float32, numpy=0.0>)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fba1d1-f569-49da-8b63-ee10c40520bd",
   "metadata": {},
   "source": [
    "### Temporary Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d92ab4-14f1-4294-9874-93728067cc5b",
   "metadata": {},
   "source": [
    "**Issue no 1.**\n",
    "\n",
    "Während des Trainings kann man einsehen, dass alle Modellparameter des neuronales Netztes vom gradient tape beobachtet werden. Problematisch ist alelrdings, dass man für die erste Matrix von der Dim (784, 100) des ersten Layers immer 0 als Gradienten erhält. Die restlichen Gradienten sind nicht 0.\n",
    "\n",
    "**Geklärt!!!** Ist beim neuen Modell nicht mehr so...\n",
    "\n",
    "Trotzdem gut zur Illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ab340e39-66d9-4cad-a46c-60f38cfc3205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Binary Accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.8142556>),\n",
       " ('False Positives', <tf.Tensor: shape=(), dtype=float32, numpy=848.0>),\n",
       " ('False Negatives', <tf.Tensor: shape=(), dtype=float32, numpy=274.0>),\n",
       " ('Precision', <tf.Tensor: shape=(), dtype=float32, numpy=0.83850694>),\n",
       " ('Recall', <tf.Tensor: shape=(), dtype=float32, numpy=0.9414154>),\n",
       " ('Mean', <tf.Tensor: shape=(), dtype=float32, numpy=-0.24690153>),\n",
       " ('accuracy', <tf.Tensor: shape=(), dtype=float32, numpy=0.80301964>)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net = lal.LusiModel(predicates=None, weight_matrix=weight_matrix)\n",
    "lusi_net.add_optimizer(tf.keras.optimizers.SGD())\n",
    "lusi_net.evaluate(test_dataset, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "23c54504-cde3-4405-a68b-fbde8d063f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: -1.1264\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 1.2990\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: -0.6952\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.3608\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: -1.1882\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1167\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: -0.8993\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.2571\n",
      "Seen so far: 6464 samples\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: -0.6263\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 100: 0.1625\n",
      "Seen so far: 6464 samples\n"
     ]
    }
   ],
   "source": [
    "# Train custom model for 10 epochs\n",
    "lusi_net.train_debug(train_dataset, 5, train_metrics=eval_metrics,  batch_1_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2b12abf2-f0a8-4f45-92df-8052c84cbfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " ListWrapper([<tf.Variable 'hidden_layer_01/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       " array([[-0.0370429 ,  0.01856136,  0.01109488, ..., -0.00165075,\n",
       "         -0.04981851, -0.03788538],\n",
       "        [-0.08224574, -0.0169937 , -0.06788497, ..., -0.04744552,\n",
       "         -0.07561758, -0.00373816],\n",
       "        [-0.03309216, -0.0767751 ,  0.02286159, ...,  0.04550548,\n",
       "          0.01688451, -0.04940302],\n",
       "        ...,\n",
       "        [-0.01363045,  0.0018331 ,  0.00059545, ..., -0.05137364,\n",
       "          0.01653846,  0.01442146],\n",
       "        [-0.06955153,  0.06206992, -0.02738059, ...,  0.05478401,\n",
       "          0.02380726,  0.07367747],\n",
       "        [-0.0182959 , -0.0309881 , -0.06341801, ..., -0.08149514,\n",
       "          0.062833  , -0.03134453]], dtype=float32)>, <tf.Variable 'hidden_layer_01/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([ 1.1756525e-02,  1.1458894e-02,  5.1763508e-04,  1.1784678e-03,\n",
       "         2.3810772e-04, -7.2968501e-04,  1.9484211e-02,  6.7639253e-03,\n",
       "        -3.4178586e-03, -2.4401019e-03,  2.8623510e-04,  7.4204719e-03,\n",
       "         1.5536326e-03, -2.0258385e-03,  3.3529053e-04,  2.5974491e-03,\n",
       "        -1.4969126e-03,  1.6573455e-02, -4.5323982e-03,  2.9716271e-03,\n",
       "         4.8708572e-04,  5.5930507e-03, -3.5983135e-03, -1.0562759e-04,\n",
       "         1.9609993e-03,  1.8349327e-03, -2.5730746e-04, -1.4591473e-04,\n",
       "         1.3427201e-03,  5.0848392e-03,  4.2973898e-04, -3.5794675e-03,\n",
       "         3.5118675e-03, -6.2043848e-03, -2.5945613e-03,  5.1732082e-03,\n",
       "         1.7343981e-02,  1.1191043e-02, -2.6499380e-03,  2.8703185e-03,\n",
       "         8.5614342e-03,  3.5229509e-03,  2.6441544e-02, -3.6543347e-03,\n",
       "         2.4459134e-03, -8.7837095e-04,  8.4171846e-04,  6.0139145e-03,\n",
       "         1.0337580e-02, -9.7581424e-04, -1.7199465e-03,  1.4564581e-03,\n",
       "         2.7591756e-03, -7.7038730e-04, -1.1508797e-03,  6.5986286e-03,\n",
       "         6.7398086e-04, -2.2561791e-04, -1.7394340e-03, -1.3837367e-03,\n",
       "        -3.6953874e-03,  1.0374462e-02,  5.9525589e-03, -3.6646444e-03,\n",
       "        -5.0662941e-04, -5.6964490e-03,  2.4167445e-02,  1.4985907e-02,\n",
       "         5.2511133e-03,  4.2648148e-03, -4.6728351e-03,  4.0885637e-04,\n",
       "        -1.6384141e-03, -1.1912041e-03,  1.9252652e-03,  2.4418889e-03,\n",
       "         3.6490342e-04,  1.7552108e-02,  7.9137003e-03, -2.3449191e-03,\n",
       "         1.2359735e-04,  5.5874739e-04,  9.8368176e-04,  5.7364637e-03,\n",
       "        -3.2033779e-05, -1.2231348e-04, -5.5752171e-04,  4.1010650e-03,\n",
       "        -5.0808541e-03, -5.0244424e-03,  6.9714463e-03,  1.3205332e-03,\n",
       "         1.6519537e-02,  1.7806020e-03, -1.2588786e-04,  6.9039705e-04,\n",
       "        -2.7893786e-04,  1.4429733e-04,  2.6917439e-03,  2.9174674e-02],\n",
       "       dtype=float32)>, <tf.Variable 'output_layer/kernel:0' shape=(100, 1) dtype=float32, numpy=\n",
       " array([[-0.1443524 ],\n",
       "        [-0.22699061],\n",
       "        [ 0.21970055],\n",
       "        [ 0.14409913],\n",
       "        [-0.08568639],\n",
       "        [-0.05900043],\n",
       "        [-0.2391376 ],\n",
       "        [-0.09532768],\n",
       "        [ 0.1217924 ],\n",
       "        [ 0.14715287],\n",
       "        [ 0.18344085],\n",
       "        [-0.12719965],\n",
       "        [-0.08246374],\n",
       "        [ 0.19800913],\n",
       "        [-0.06979214],\n",
       "        [-0.14385992],\n",
       "        [ 0.05580479],\n",
       "        [-0.262104  ],\n",
       "        [ 0.05544109],\n",
       "        [-0.12371285],\n",
       "        [-0.02445921],\n",
       "        [-0.14215496],\n",
       "        [-0.23209569],\n",
       "        [ 0.10250475],\n",
       "        [-0.06761727],\n",
       "        [ 0.24072246],\n",
       "        [ 0.08288372],\n",
       "        [ 0.02470307],\n",
       "        [-0.1061181 ],\n",
       "        [-0.07267886],\n",
       "        [-0.01288329],\n",
       "        [ 0.06145913],\n",
       "        [-0.08510733],\n",
       "        [ 0.2036936 ],\n",
       "        [ 0.04893029],\n",
       "        [-0.1572463 ],\n",
       "        [-0.24819267],\n",
       "        [-0.16527952],\n",
       "        [-0.15228795],\n",
       "        [-0.15823072],\n",
       "        [-0.23234215],\n",
       "        [ 0.17411757],\n",
       "        [-0.3858018 ],\n",
       "        [ 0.23873602],\n",
       "        [-0.19189593],\n",
       "        [ 0.12776905],\n",
       "        [ 0.2904773 ],\n",
       "        [-0.14846587],\n",
       "        [ 0.18643467],\n",
       "        [ 0.18803091],\n",
       "        [ 0.05906401],\n",
       "        [ 0.2643301 ],\n",
       "        [-0.08028479],\n",
       "        [-0.03403502],\n",
       "        [ 0.17903088],\n",
       "        [ 0.20483057],\n",
       "        [-0.21663392],\n",
       "        [ 0.01739656],\n",
       "        [ 0.00869279],\n",
       "        [-0.03731922],\n",
       "        [ 0.20134187],\n",
       "        [-0.2613973 ],\n",
       "        [ 0.24559656],\n",
       "        [ 0.09046605],\n",
       "        [ 0.11585969],\n",
       "        [ 0.09013831],\n",
       "        [-0.31660527],\n",
       "        [-0.27972597],\n",
       "        [-0.10855892],\n",
       "        [-0.14872704],\n",
       "        [ 0.20137936],\n",
       "        [-0.04332716],\n",
       "        [-0.23831093],\n",
       "        [-0.17837265],\n",
       "        [ 0.18459024],\n",
       "        [ 0.30811912],\n",
       "        [-0.22187622],\n",
       "        [-0.1850531 ],\n",
       "        [-0.15652187],\n",
       "        [ 0.05161695],\n",
       "        [-0.02602001],\n",
       "        [ 0.11888383],\n",
       "        [ 0.10305119],\n",
       "        [ 0.1579868 ],\n",
       "        [ 0.01431876],\n",
       "        [-0.07761158],\n",
       "        [ 0.04689528],\n",
       "        [-0.07021749],\n",
       "        [ 0.20745775],\n",
       "        [ 0.11787716],\n",
       "        [ 0.19249137],\n",
       "        [ 0.08848771],\n",
       "        [-0.25766093],\n",
       "        [-0.09980828],\n",
       "        [ 0.2037708 ],\n",
       "        [ 0.2557336 ],\n",
       "        [-0.00174172],\n",
       "        [-0.0116796 ],\n",
       "        [ 0.11109   ],\n",
       "        [-0.34923473]], dtype=float32)>, <tf.Variable 'output_layer/bias:0' shape=(1,) dtype=float32, numpy=array([-0.05122198], dtype=float32)>]))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lusi_net.model_weight_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3e24ae78-d1cb-4f4c-b227-8bdfcdd9eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_grad = (lusi_net.gradient_list[0][1][0] - lusi_net.gradient_list[50][1][0]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9ebe9e7f-838b-4eeb-b450-4c248207aca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.086509906"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(diff_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "64905252-f6c9-4a53-bf5c-9b4c06464018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.080651"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(diff_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b0d0a4a4-0bee-44ce-b4b8-899e646a42ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37018,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_grad[diff_grad != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "44fe4fb3-9a78-4eff-ba3f-051e5a1ae108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lusi_net.gradient_list[0][1][0]).numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ef4ef-03b5-41a6-aee1-435e511ccd6f",
   "metadata": {},
   "source": [
    "**Issue no 2.**\n",
    "\n",
    "Der Optimizer führt die Gradientenupdates nicht durch. Das Modell scheint aber ja, wie man sieht, dennoch angepasst zu werden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "66a279d6-5dbd-48b7-aae9-be64a4cc82b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for epoch 0 step 0: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'hidden_layer_01/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       "array([[-0.0370429 ,  0.01856136,  0.01109488, ..., -0.00165075,\n",
       "        -0.04981851, -0.03788538],\n",
       "       [-0.08224574, -0.0169937 , -0.06788497, ..., -0.04744552,\n",
       "        -0.07561758, -0.00373816],\n",
       "       [-0.03309216, -0.0767751 ,  0.02286159, ...,  0.04550548,\n",
       "         0.01688451, -0.04940302],\n",
       "       ...,\n",
       "       [-0.01363045,  0.0018331 ,  0.00059545, ..., -0.05137364,\n",
       "         0.01653846,  0.01442146],\n",
       "       [-0.06955153,  0.06206992, -0.02738059, ...,  0.05478401,\n",
       "         0.02380726,  0.07367747],\n",
       "       [-0.0182959 , -0.0309881 , -0.06341801, ..., -0.08149514,\n",
       "         0.062833  , -0.03134453]], dtype=float32)>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Weights for epoch {lusi_net.model_weight_list[1][0][0]} step {lusi_net.model_weight_list[1][0][1]}: \")\n",
    "lusi_net.model_weight_list[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "61e8f855-439e-445a-b4a2-30de30184bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for epoch 2 step 39: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.0370429 ,  0.01856136,  0.01109488, ..., -0.00165075,\n",
       "        -0.04981851, -0.03788538],\n",
       "       [-0.08224574, -0.0169937 , -0.06788497, ..., -0.04744552,\n",
       "        -0.07561758, -0.00373816],\n",
       "       [-0.03309216, -0.0767751 ,  0.02286159, ...,  0.04550548,\n",
       "         0.01688451, -0.04940302],\n",
       "       ...,\n",
       "       [-0.01363045,  0.0018331 ,  0.00059545, ..., -0.05137364,\n",
       "         0.01653846,  0.01442146],\n",
       "       [-0.06955153,  0.06206992, -0.02738059, ...,  0.05478401,\n",
       "         0.02380726,  0.07367747],\n",
       "       [-0.0182959 , -0.0309881 , -0.06341801, ..., -0.08149514,\n",
       "         0.062833  , -0.03134453]], dtype=float32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Weights for epoch {lusi_net.model_weight_list[400][0][0]} step {lusi_net.model_weight_list[40][0][1]}: \")\n",
    "lusi_net.model_weight_list[1][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "50cb1cb2-df12-4afc-a155-28e7dde279d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [247]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (lusi_net\u001b[38;5;241m.\u001b[39mmodel_weight_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[43mlusi_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_weight_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1800\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mall()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lusi/lib/python3.10/site-packages/tensorflow/python/training/tracking/data_structures.py:441\u001b[0m, in \u001b[0;36mList.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 441\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "(lusi_net.model_weight_list[0][1][0] == lusi_net.model_weight_list[1800][1][0]).numpy().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f99a6-bbb2-47ae-b61a-96f291d2d14c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lusi",
   "language": "python",
   "name": "lusi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
